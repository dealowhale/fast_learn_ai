# 5.1 æ™ºèƒ½å®¢æœç³»ç»Ÿ

## é¡¹ç›®æ¦‚è¿°

æ™ºèƒ½å®¢æœç³»ç»Ÿæ˜¯ç°ä»£ä¼ä¸šæ•°å­—åŒ–è½¬å‹çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æœ¬é¡¹ç›®å°†æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œé›†æˆè‡ªç„¶è¯­è¨€ç†è§£ã€çŸ¥è¯†åº“é—®ç­”ã€æƒ…æ„Ÿåˆ†æç­‰æ ¸å¿ƒæŠ€æœ¯ï¼Œå®ç°7Ã—24å°æ—¶çš„æ™ºèƒ½å®¢æˆ·æœåŠ¡ã€‚

### ğŸ¯ é¡¹ç›®ç›®æ ‡
- æ„å»ºä¼ä¸šçº§æ™ºèƒ½å®¢æœç³»ç»Ÿ
- å®ç°å¤šè½®å¯¹è¯ç†è§£å’Œä¸Šä¸‹æ–‡ç®¡ç†
- é›†æˆçŸ¥è¯†åº“è¿›è¡Œæ™ºèƒ½é—®ç­”
- æä¾›æƒ…æ„Ÿåˆ†æå’Œä¸ªæ€§åŒ–æœåŠ¡
- æ”¯æŒäººå·¥å®¢æœæ— ç¼è½¬æ¥

### ğŸ“Š é¢„æœŸæ•ˆæœ
- **å“åº”é€Ÿåº¦**: < 2ç§’
- **é—®é¢˜è§£å†³ç‡**: > 80%
- **ç”¨æˆ·æ»¡æ„åº¦**: > 4.5/5
- **å¹¶å‘æ”¯æŒ**: 1000+ç”¨æˆ·

## 5.1.1 éœ€æ±‚åˆ†æå’Œç³»ç»Ÿè®¾è®¡

### ä¸šåŠ¡éœ€æ±‚åˆ†æ

**æ ¸å¿ƒä¸šåŠ¡åœºæ™¯**:
1. **å¸¸è§é—®é¢˜å’¨è¯¢**: äº§å“ä¿¡æ¯ã€æœåŠ¡æµç¨‹ã€æ”¿ç­–è§£ç­”
2. **æŠ€æœ¯æ”¯æŒ**: æ•…éšœæ’æŸ¥ã€ä½¿ç”¨æŒ‡å¯¼ã€é—®é¢˜è¯Šæ–­
3. **è®¢å•æŸ¥è¯¢**: è®¢å•çŠ¶æ€ã€ç‰©æµä¿¡æ¯ã€é€€æ¢è´§æµç¨‹
4. **æŠ•è¯‰å»ºè®®**: é—®é¢˜åé¦ˆã€æœåŠ¡è¯„ä»·ã€æ”¹è¿›å»ºè®®

**ç”¨æˆ·è§’è‰²å®šä¹‰**:
- **ç»ˆç«¯ç”¨æˆ·**: å¯»æ±‚å¸®åŠ©çš„å®¢æˆ·
- **å®¢æœä»£è¡¨**: å¤„ç†å¤æ‚é—®é¢˜çš„äººå·¥å®¢æœ
- **ç³»ç»Ÿç®¡ç†å‘˜**: ç»´æŠ¤çŸ¥è¯†åº“å’Œç³»ç»Ÿé…ç½®
- **ä¸šåŠ¡åˆ†æå¸ˆ**: åˆ†æå®¢æœæ•°æ®å’Œä¼˜åŒ–ç­–ç•¥

### ç³»ç»Ÿæ¶æ„è®¾è®¡

```mermaid
graph TB
    A[ç”¨æˆ·ç•Œé¢] --> B[APIç½‘å…³]
    B --> C[å¯¹è¯ç®¡ç†æœåŠ¡]
    C --> D[NLUæœåŠ¡]
    C --> E[çŸ¥è¯†åº“æœåŠ¡]
    C --> F[æƒ…æ„Ÿåˆ†ææœåŠ¡]
    D --> G[æ„å›¾è¯†åˆ«]
    D --> H[å®ä½“æŠ½å–]
    E --> I[å‘é‡æ£€ç´¢]
    E --> J[çŸ¥è¯†å›¾è°±]
    F --> K[æƒ…æ„Ÿåˆ†ç±»]
    C --> L[å¯¹è¯çŠ¶æ€ç®¡ç†]
    L --> M[Redisç¼“å­˜]
    I --> N[Elasticsearch]
    J --> O[Neo4j]
    C --> P[äººå·¥è½¬æ¥æœåŠ¡]
```

**æ ¸å¿ƒæ¨¡å—è¯´æ˜**:
- **å¯¹è¯ç®¡ç†**: ç»Ÿä¸€çš„å¯¹è¯æµç¨‹æ§åˆ¶å’ŒçŠ¶æ€ç®¡ç†
- **NLUæœåŠ¡**: è‡ªç„¶è¯­è¨€ç†è§£ï¼ŒåŒ…æ‹¬æ„å›¾è¯†åˆ«å’Œå®ä½“æŠ½å–
- **çŸ¥è¯†åº“æœåŠ¡**: åŸºäºå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”
- **æƒ…æ„Ÿåˆ†æ**: è¯†åˆ«ç”¨æˆ·æƒ…æ„ŸçŠ¶æ€ï¼Œæä¾›ä¸ªæ€§åŒ–æœåŠ¡
- **è½¬æ¥æœåŠ¡**: æ™ºèƒ½åˆ¤æ–­è½¬æ¥æ—¶æœºï¼Œå®ç°äººæœºåä½œ

### æŠ€æœ¯é€‰å‹

**åç«¯æŠ€æœ¯æ ˆ**:
- **æ¡†æ¶**: FastAPI (é«˜æ€§èƒ½å¼‚æ­¥API)
- **NLPæ¨¡å‹**: BERT, RoBERTa, GPT-3.5
- **å‘é‡æ•°æ®åº“**: Pinecone, Weaviate
- **å›¾æ•°æ®åº“**: Neo4j
- **ç¼“å­˜**: Redis
- **æœç´¢å¼•æ“**: Elasticsearch

**å‰ç«¯æŠ€æœ¯æ ˆ**:
- **æ¡†æ¶**: Streamlit (å¿«é€ŸåŸå‹)
- **UIç»„ä»¶**: Streamlit-chat
- **å¯è§†åŒ–**: Plotly, Altair

## 5.1.2 æ ¸å¿ƒåŠŸèƒ½å®ç°

### å¯¹è¯ç®¡ç†æ ¸å¿ƒç±»

```python
# conversation_manager.py
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import uuid
import redis
import json

@dataclass
class Message:
    """æ¶ˆæ¯æ•°æ®ç»“æ„"""
    id: str
    user_id: str
    content: str
    message_type: str  # 'user', 'bot', 'system'
    timestamp: datetime
    metadata: Dict[str, Any] = None

@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡"""
    user_id: str
    session_id: str
    current_intent: Optional[str] = None
    entities: Dict[str, Any] = None
    conversation_state: str = 'active'  # active, waiting, transferred
    emotion_state: Optional[str] = None
    satisfaction_score: Optional[float] = None
    messages: List[Message] = None
    
    def __post_init__(self):
        if self.entities is None:
            self.entities = {}
        if self.messages is None:
            self.messages = []

class ConversationManager:
    """å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis_client = redis_client
        self.session_timeout = 3600  # 1å°æ—¶è¶…æ—¶
    
    def create_session(self, user_id: str) -> str:
        """åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯"""
        session_id = str(uuid.uuid4())
        context = ConversationContext(
            user_id=user_id,
            session_id=session_id
        )
        
        # å­˜å‚¨åˆ°Redis
        self._save_context(context)
        return session_id
    
    def get_context(self, session_id: str) -> Optional[ConversationContext]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            data = self.redis_client.get(f"session:{session_id}")
            if data:
                context_dict = json.loads(data)
                return self._dict_to_context(context_dict)
            return None
        except Exception as e:
            print(f"è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None
    
    def update_context(self, session_id: str, **kwargs) -> bool:
        """æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡"""
        context = self.get_context(session_id)
        if not context:
            return False
        
        # æ›´æ–°å­—æ®µ
        for key, value in kwargs.items():
            if hasattr(context, key):
                setattr(context, key, value)
        
        self._save_context(context)
        return True
    
    def add_message(self, session_id: str, content: str, 
                   message_type: str, metadata: Dict = None) -> bool:
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        context = self.get_context(session_id)
        if not context:
            return False
        
        message = Message(
            id=str(uuid.uuid4()),
            user_id=context.user_id,
            content=content,
            message_type=message_type,
            timestamp=datetime.now(),
            metadata=metadata or {}
        )
        
        context.messages.append(message)
        
        # é™åˆ¶æ¶ˆæ¯å†å²é•¿åº¦
        if len(context.messages) > 50:
            context.messages = context.messages[-50:]
        
        self._save_context(context)
        return True
    
    def get_conversation_history(self, session_id: str, 
                               limit: int = 10) -> List[Message]:
        """è·å–å¯¹è¯å†å²"""
        context = self.get_context(session_id)
        if not context:
            return []
        
        return context.messages[-limit:] if context.messages else []
    
    def _save_context(self, context: ConversationContext):
        """ä¿å­˜ä¸Šä¸‹æ–‡åˆ°Redis"""
        context_dict = self._context_to_dict(context)
        self.redis_client.setex(
            f"session:{context.session_id}",
            self.session_timeout,
            json.dumps(context_dict, default=str)
        )
    
    def _context_to_dict(self, context: ConversationContext) -> Dict:
        """è½¬æ¢ä¸Šä¸‹æ–‡ä¸ºå­—å…¸"""
        return {
            'user_id': context.user_id,
            'session_id': context.session_id,
            'current_intent': context.current_intent,
            'entities': context.entities,
            'conversation_state': context.conversation_state,
            'emotion_state': context.emotion_state,
            'satisfaction_score': context.satisfaction_score,
            'messages': [
                {
                    'id': msg.id,
                    'user_id': msg.user_id,
                    'content': msg.content,
                    'message_type': msg.message_type,
                    'timestamp': msg.timestamp.isoformat(),
                    'metadata': msg.metadata
                }
                for msg in context.messages
            ]
        }
    
    def _dict_to_context(self, data: Dict) -> ConversationContext:
        """ä»å­—å…¸è½¬æ¢ä¸ºä¸Šä¸‹æ–‡å¯¹è±¡"""
        messages = [
            Message(
                id=msg['id'],
                user_id=msg['user_id'],
                content=msg['content'],
                message_type=msg['message_type'],
                timestamp=datetime.fromisoformat(msg['timestamp']),
                metadata=msg.get('metadata', {})
            )
            for msg in data.get('messages', [])
        ]
        
        return ConversationContext(
            user_id=data['user_id'],
            session_id=data['session_id'],
            current_intent=data.get('current_intent'),
            entities=data.get('entities', {}),
            conversation_state=data.get('conversation_state', 'active'),
            emotion_state=data.get('emotion_state'),
            satisfaction_score=data.get('satisfaction_score'),
            messages=messages
        )
```

### NLUæœåŠ¡å®ç°

```python
# nlu_service.py
from typing import Dict, List, Tuple, Optional
import torch
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    AutoModelForTokenClassification, pipeline
)
import numpy as np
from dataclasses import dataclass

@dataclass
class IntentResult:
    """æ„å›¾è¯†åˆ«ç»“æœ"""
    intent: str
    confidence: float
    alternatives: List[Tuple[str, float]]

@dataclass
class EntityResult:
    """å®ä½“æŠ½å–ç»“æœ"""
    entities: List[Dict[str, Any]]
    
class NLUService:
    """è‡ªç„¶è¯­è¨€ç†è§£æœåŠ¡"""
    
    def __init__(self, model_config: Dict[str, str]):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æ„å›¾è¯†åˆ«æ¨¡å‹
        self.intent_tokenizer = AutoTokenizer.from_pretrained(
            model_config['intent_model']
        )
        self.intent_model = AutoModelForSequenceClassification.from_pretrained(
            model_config['intent_model']
        ).to(self.device)
        
        # åŠ è½½å®ä½“è¯†åˆ«æ¨¡å‹
        self.ner_pipeline = pipeline(
            "ner",
            model=model_config['ner_model'],
            tokenizer=model_config['ner_model'],
            aggregation_strategy="simple",
            device=0 if torch.cuda.is_available() else -1
        )
        
        # æ„å›¾æ ‡ç­¾æ˜ å°„
        self.intent_labels = {
            0: "greeting",
            1: "product_inquiry", 
            2: "order_status",
            3: "technical_support",
            4: "complaint",
            5: "goodbye",
            6: "other"
        }
    
    def predict_intent(self, text: str) -> IntentResult:
        """é¢„æµ‹ç”¨æˆ·æ„å›¾"""
        # æ–‡æœ¬é¢„å¤„ç†
        inputs = self.intent_tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        ).to(self.device)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            outputs = self.intent_model(**inputs)
            probabilities = torch.softmax(outputs.logits, dim=-1)
            
        # è·å–é¢„æµ‹ç»“æœ
        probs = probabilities.cpu().numpy()[0]
        predicted_idx = np.argmax(probs)
        confidence = float(probs[predicted_idx])
        
        # è·å–å¤‡é€‰æ„å›¾
        alternatives = []
        for idx, prob in enumerate(probs):
            if idx != predicted_idx and prob > 0.1:
                alternatives.append((self.intent_labels[idx], float(prob)))
        
        alternatives.sort(key=lambda x: x[1], reverse=True)
        
        return IntentResult(
            intent=self.intent_labels[predicted_idx],
            confidence=confidence,
            alternatives=alternatives[:3]
        )
    
    def extract_entities(self, text: str) -> EntityResult:
        """æŠ½å–å‘½åå®ä½“"""
        # ä½¿ç”¨pipelineè¿›è¡Œå®ä½“è¯†åˆ«
        ner_results = self.ner_pipeline(text)
        
        # å¤„ç†ç»“æœ
        entities = []
        for entity in ner_results:
            entities.append({
                'text': entity['word'],
                'label': entity['entity_group'],
                'confidence': entity['score'],
                'start': entity['start'],
                'end': entity['end']
            })
        
        return EntityResult(entities=entities)
    
    def analyze_text(self, text: str) -> Dict[str, Any]:
        """ç»¼åˆæ–‡æœ¬åˆ†æ"""
        intent_result = self.predict_intent(text)
        entity_result = self.extract_entities(text)
        
        return {
            'intent': {
                'predicted': intent_result.intent,
                'confidence': intent_result.confidence,
                'alternatives': intent_result.alternatives
            },
            'entities': entity_result.entities,
            'text_length': len(text),
            'word_count': len(text.split())
        }
```

### çŸ¥è¯†åº“æœåŠ¡å®ç°

```python
# knowledge_base.py
from typing import List, Dict, Optional, Any
import numpy as np
from sentence_transformers import SentenceTransformer
import pinecone
from dataclasses import dataclass
import json

@dataclass
class KnowledgeItem:
    """çŸ¥è¯†åº“æ¡ç›®"""
    id: str
    question: str
    answer: str
    category: str
    tags: List[str]
    confidence: float = 0.0
    metadata: Dict[str, Any] = None

class KnowledgeBaseService:
    """çŸ¥è¯†åº“æœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        # åˆå§‹åŒ–å‘é‡æ¨¡å‹
        self.encoder = SentenceTransformer(config['embedding_model'])
        
        # åˆå§‹åŒ–Pinecone
        pinecone.init(
            api_key=config['pinecone_api_key'],
            environment=config['pinecone_environment']
        )
        
        self.index_name = config['index_name']
        self.index = pinecone.Index(self.index_name)
        
        # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.similarity_threshold = config.get('similarity_threshold', 0.7)
    
    def add_knowledge(self, items: List[KnowledgeItem]) -> bool:
        """æ·»åŠ çŸ¥è¯†åˆ°å‘é‡æ•°æ®åº“"""
        try:
            vectors_to_upsert = []
            
            for item in items:
                # ç”Ÿæˆé—®é¢˜å‘é‡
                question_vector = self.encoder.encode(item.question).tolist()
                
                # å‡†å¤‡å…ƒæ•°æ®
                metadata = {
                    'question': item.question,
                    'answer': item.answer,
                    'category': item.category,
                    'tags': item.tags
                }
                if item.metadata:
                    metadata.update(item.metadata)
                
                vectors_to_upsert.append({
                    'id': item.id,
                    'values': question_vector,
                    'metadata': metadata
                })
            
            # æ‰¹é‡ä¸Šä¼ åˆ°Pinecone
            self.index.upsert(vectors=vectors_to_upsert)
            return True
            
        except Exception as e:
            print(f"æ·»åŠ çŸ¥è¯†å¤±è´¥: {e}")
            return False
    
    def search_knowledge(self, query: str, top_k: int = 5, 
                        category_filter: Optional[str] = None) -> List[KnowledgeItem]:
        """æœç´¢ç›¸å…³çŸ¥è¯†"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vector = self.encoder.encode(query).tolist()
            
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            filter_dict = {}
            if category_filter:
                filter_dict['category'] = category_filter
            
            # å‘é‡æœç´¢
            search_results = self.index.query(
                vector=query_vector,
                top_k=top_k,
                include_metadata=True,
                filter=filter_dict if filter_dict else None
            )
            
            # å¤„ç†æœç´¢ç»“æœ
            knowledge_items = []
            for match in search_results['matches']:
                if match['score'] >= self.similarity_threshold:
                    metadata = match['metadata']
                    item = KnowledgeItem(
                        id=match['id'],
                        question=metadata['question'],
                        answer=metadata['answer'],
                        category=metadata['category'],
                        tags=metadata.get('tags', []),
                        confidence=match['score'],
                        metadata=metadata
                    )
                    knowledge_items.append(item)
            
            return knowledge_items
            
        except Exception as e:
            print(f"æœç´¢çŸ¥è¯†å¤±è´¥: {e}")
            return []
    
    def get_answer(self, query: str, context: Optional[Dict] = None) -> Optional[str]:
        """è·å–é—®é¢˜ç­”æ¡ˆ"""
        # æœç´¢ç›¸å…³çŸ¥è¯†
        category_filter = None
        if context and 'current_intent' in context:
            category_filter = self._intent_to_category(context['current_intent'])
        
        knowledge_items = self.search_knowledge(
            query, 
            top_k=3, 
            category_filter=category_filter
        )
        
        if not knowledge_items:
            return None
        
        # è¿”å›æœ€ç›¸å…³çš„ç­”æ¡ˆ
        best_match = knowledge_items[0]
        if best_match.confidence >= self.similarity_threshold:
            return best_match.answer
        
        return None
    
    def _intent_to_category(self, intent: str) -> Optional[str]:
        """æ„å›¾åˆ°ç±»åˆ«çš„æ˜ å°„"""
        intent_category_map = {
            'product_inquiry': 'product',
            'order_status': 'order',
            'technical_support': 'technical',
            'complaint': 'service'
        }
        return intent_category_map.get(intent)
    
    def update_knowledge(self, item_id: str, updated_item: KnowledgeItem) -> bool:
        """æ›´æ–°çŸ¥è¯†æ¡ç›®"""
        try:
            # åˆ é™¤æ—§æ¡ç›®
            self.index.delete(ids=[item_id])
            
            # æ·»åŠ æ–°æ¡ç›®
            return self.add_knowledge([updated_item])
            
        except Exception as e:
            print(f"æ›´æ–°çŸ¥è¯†å¤±è´¥: {e}")
            return False
    
    def delete_knowledge(self, item_ids: List[str]) -> bool:
        """åˆ é™¤çŸ¥è¯†æ¡ç›®"""
        try:
            self.index.delete(ids=item_ids)
            return True
        except Exception as e:
            print(f"åˆ é™¤çŸ¥è¯†å¤±è´¥: {e}")
            return False
```

### æƒ…æ„Ÿåˆ†ææœåŠ¡

```python
# emotion_analysis.py
from typing import Dict, List, Optional
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
from dataclasses import dataclass

@dataclass
class EmotionResult:
    """æƒ…æ„Ÿåˆ†æç»“æœ"""
    emotion: str
    confidence: float
    valence: float  # æƒ…æ„Ÿæ•ˆä»· (-1åˆ°1)
    arousal: float  # æƒ…æ„Ÿå”¤é†’åº¦ (0åˆ°1)
    emotions_distribution: Dict[str, float]

class EmotionAnalysisService:
    """æƒ…æ„Ÿåˆ†ææœåŠ¡"""
    
    def __init__(self, model_path: str):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æƒ…æ„Ÿåˆ†ææ¨¡å‹
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_path
        ).to(self.device)
        
        # æƒ…æ„Ÿæ ‡ç­¾
        self.emotion_labels = {
            0: "anger",      # æ„¤æ€’
            1: "disgust",    # åŒæ¶
            2: "fear",       # ææƒ§
            3: "joy",        # å–œæ‚¦
            4: "neutral",    # ä¸­æ€§
            5: "sadness",    # æ‚²ä¼¤
            6: "surprise"    # æƒŠè®¶
        }
        
        # æƒ…æ„Ÿæ•ˆä»·å’Œå”¤é†’åº¦æ˜ å°„
        self.emotion_dimensions = {
            "anger": {"valence": -0.8, "arousal": 0.9},
            "disgust": {"valence": -0.7, "arousal": 0.6},
            "fear": {"valence": -0.6, "arousal": 0.8},
            "joy": {"valence": 0.8, "arousal": 0.7},
            "neutral": {"valence": 0.0, "arousal": 0.3},
            "sadness": {"valence": -0.7, "arousal": 0.4},
            "surprise": {"valence": 0.2, "arousal": 0.8}
        }
    
    def analyze_emotion(self, text: str) -> EmotionResult:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        # æ–‡æœ¬é¢„å¤„ç†
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        ).to(self.device)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.softmax(outputs.logits, dim=-1)
        
        # è·å–é¢„æµ‹ç»“æœ
        probs = probabilities.cpu().numpy()[0]
        predicted_idx = np.argmax(probs)
        predicted_emotion = self.emotion_labels[predicted_idx]
        confidence = float(probs[predicted_idx])
        
        # è®¡ç®—æƒ…æ„Ÿåˆ†å¸ƒ
        emotions_distribution = {
            self.emotion_labels[i]: float(prob) 
            for i, prob in enumerate(probs)
        }
        
        # è·å–æƒ…æ„Ÿç»´åº¦
        dimensions = self.emotion_dimensions[predicted_emotion]
        
        return EmotionResult(
            emotion=predicted_emotion,
            confidence=confidence,
            valence=dimensions["valence"],
            arousal=dimensions["arousal"],
            emotions_distribution=emotions_distribution
        )
    
    def get_response_strategy(self, emotion_result: EmotionResult) -> Dict[str, Any]:
        """æ ¹æ®æƒ…æ„Ÿåˆ†æç»“æœè·å–å›å¤ç­–ç•¥"""
        emotion = emotion_result.emotion
        confidence = emotion_result.confidence
        
        strategies = {
            "anger": {
                "tone": "calm_and_understanding",
                "priority": "high",
                "escalation": True,
                "response_template": "æˆ‘ç†è§£æ‚¨çš„ä¸æ»¡ï¼Œè®©æˆ‘æ¥å¸®åŠ©æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚",
                "suggested_actions": ["apologize", "offer_solution", "escalate_if_needed"]
            },
            "sadness": {
                "tone": "empathetic_and_supportive",
                "priority": "medium",
                "escalation": False,
                "response_template": "æˆ‘å¾ˆæŠ±æ­‰å¬åˆ°è¿™ä¸ªæƒ…å†µï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨ã€‚",
                "suggested_actions": ["show_empathy", "provide_support", "offer_alternatives"]
            },
            "joy": {
                "tone": "positive_and_engaging",
                "priority": "normal",
                "escalation": False,
                "response_template": "å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼è®©æˆ‘æ¥å¸®åŠ©æ‚¨ã€‚",
                "suggested_actions": ["maintain_positivity", "be_helpful", "encourage_feedback"]
            },
            "fear": {
                "tone": "reassuring_and_clear",
                "priority": "medium",
                "escalation": False,
                "response_template": "è¯·ä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘ä¼šè¯¦ç»†ä¸ºæ‚¨è§£é‡Šå¹¶æä¾›å¸®åŠ©ã€‚",
                "suggested_actions": ["provide_reassurance", "explain_clearly", "offer_step_by_step_help"]
            },
            "neutral": {
                "tone": "professional_and_helpful",
                "priority": "normal",
                "escalation": False,
                "response_template": "æˆ‘æ¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
                "suggested_actions": ["be_direct", "provide_information", "ask_clarifying_questions"]
            }
        }
        
        strategy = strategies.get(emotion, strategies["neutral"])
        strategy["confidence"] = confidence
        
        # å¦‚æœæƒ…æ„Ÿè¯†åˆ«ç½®ä¿¡åº¦ä½ï¼Œä½¿ç”¨ä¸­æ€§ç­–ç•¥
        if confidence < 0.6:
            strategy = strategies["neutral"]
            strategy["confidence"] = confidence
            strategy["note"] = "Low confidence emotion detection, using neutral strategy"
        
        return strategy
    
    def analyze_conversation_emotion_trend(self, messages: List[str]) -> Dict[str, Any]:
        """åˆ†æå¯¹è¯ä¸­çš„æƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿"""
        if not messages:
            return {"trend": "neutral", "emotions": [], "summary": "No messages to analyze"}
        
        emotions = []
        valences = []
        arousals = []
        
        for message in messages:
            result = self.analyze_emotion(message)
            emotions.append({
                "emotion": result.emotion,
                "confidence": result.confidence,
                "valence": result.valence,
                "arousal": result.arousal
            })
            valences.append(result.valence)
            arousals.append(result.arousal)
        
        # è®¡ç®—è¶‹åŠ¿
        avg_valence = np.mean(valences)
        avg_arousal = np.mean(arousals)
        valence_trend = "improving" if valences[-1] > valences[0] else "declining" if valences[-1] < valences[0] else "stable"
        
        return {
            "emotions": emotions,
            "average_valence": avg_valence,
            "average_arousal": avg_arousal,
            "valence_trend": valence_trend,
            "latest_emotion": emotions[-1]["emotion"],
            "summary": self._generate_emotion_summary(avg_valence, avg_arousal, valence_trend)
        }
    
    def _generate_emotion_summary(self, avg_valence: float, avg_arousal: float, trend: str) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿåˆ†ææ‘˜è¦"""
        if avg_valence > 0.3:
            valence_desc = "ç§¯æ"
        elif avg_valence < -0.3:
            valence_desc = "æ¶ˆæ"
        else:
            valence_desc = "ä¸­æ€§"
        
        if avg_arousal > 0.6:
            arousal_desc = "é«˜æ¿€æ´»"
        elif avg_arousal < 0.4:
            arousal_desc = "ä½æ¿€æ´»"
        else:
            arousal_desc = "ä¸­ç­‰æ¿€æ´»"
        
        trend_desc = {
            "improving": "æƒ…æ„Ÿè¶‹å‘å¥½è½¬",
            "declining": "æƒ…æ„Ÿè¶‹å‘æ¶åŒ–", 
            "stable": "æƒ…æ„Ÿä¿æŒç¨³å®š"
        }[trend]
        
        return f"ç”¨æˆ·æƒ…æ„Ÿæ•´ä½“å‘ˆç°{valence_desc}ã€{arousal_desc}çŠ¶æ€ï¼Œ{trend_desc}"
```

## 5.1.3 ç³»ç»Ÿé›†æˆå’ŒAPIè®¾è®¡

### FastAPIä¸»æœåŠ¡

```python
# main.py
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import redis
import os
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from conversation_manager import ConversationManager
from nlu_service import NLUService
from knowledge_base import KnowledgeBaseService
from emotion_analysis import EmotionAnalysisService

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ™ºèƒ½å®¢æœç³»ç»ŸAPI",
    description="åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å®¢æœç³»ç»Ÿ",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚/å“åº”æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    user_id: str
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str
    intent: Optional[str] = None
    emotion: Optional[str] = None
    confidence: float
    suggestions: List[str] = []
    need_human_transfer: bool = False

class SessionRequest(BaseModel):
    user_id: str

class SessionResponse(BaseModel):
    session_id: str
    status: str

# å…¨å±€æœåŠ¡å®ä¾‹
redis_client = None
conversation_manager = None
nlu_service = None
knowledge_base = None
emotion_service = None

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æœåŠ¡"""
    global redis_client, conversation_manager, nlu_service, knowledge_base, emotion_service
    
    # åˆå§‹åŒ–Redis
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        db=0,
        decode_responses=True
    )
    
    # åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨
    conversation_manager = ConversationManager(redis_client)
    
    # åˆå§‹åŒ–NLUæœåŠ¡
    nlu_config = {
        'intent_model': 'bert-base-chinese',
        'ner_model': 'ckiplab/bert-base-chinese-ner'
    }
    nlu_service = NLUService(nlu_config)
    
    # åˆå§‹åŒ–çŸ¥è¯†åº“æœåŠ¡
    kb_config = {
        'embedding_model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'pinecone_api_key': os.getenv('PINECONE_API_KEY'),
        'pinecone_environment': os.getenv('PINECONE_ENVIRONMENT'),
        'index_name': 'customer-service-kb',
        'similarity_threshold': 0.7
    }
    knowledge_base = KnowledgeBaseService(kb_config)
    
    # åˆå§‹åŒ–æƒ…æ„Ÿåˆ†ææœåŠ¡
    emotion_service = EmotionAnalysisService('j-hartmann/emotion-english-distilroberta-base')

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """å¤„ç†èŠå¤©è¯·æ±‚"""
    try:
        # è·å–æˆ–åˆ›å»ºä¼šè¯
        session_id = request.session_id
        if not session_id:
            session_id = conversation_manager.create_session(request.user_id)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        conversation_manager.add_message(
            session_id, 
            request.message, 
            "user"
        )
        
        # NLUåˆ†æ
        nlu_result = nlu_service.analyze_text(request.message)
        intent = nlu_result['intent']['predicted']
        intent_confidence = nlu_result['intent']['confidence']
        
        # æƒ…æ„Ÿåˆ†æ
        emotion_result = emotion_service.analyze_emotion(request.message)
        
        # æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡
        conversation_manager.update_context(
            session_id,
            current_intent=intent,
            entities=nlu_result['entities'],
            emotion_state=emotion_result.emotion
        )
        
        # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        context = conversation_manager.get_context(session_id)
        
        # çŸ¥è¯†åº“æŸ¥è¯¢
        answer = knowledge_base.get_answer(
            request.message,
            context={'current_intent': intent}
        )
        
        # ç”Ÿæˆå›å¤
        if answer:
            response_text = answer
            confidence = intent_confidence
        else:
            response_text = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è®©æˆ‘ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœã€‚"
            confidence = 0.0
        
        # æ ¹æ®æƒ…æ„Ÿè°ƒæ•´å›å¤ç­–ç•¥
        emotion_strategy = emotion_service.get_response_strategy(emotion_result)
        if emotion_strategy['tone'] == 'calm_and_understanding':
            response_text = f"{emotion_strategy['response_template']} {response_text}"
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥è½¬æ¥
        need_transfer = (
            confidence < 0.5 or 
            emotion_result.emotion in ['anger', 'sadness'] or
            intent == 'complaint'
        )
        
        # æ·»åŠ æœºå™¨äººå›å¤åˆ°å¯¹è¯å†å²
        conversation_manager.add_message(
            session_id,
            response_text,
            "bot",
            metadata={
                'intent': intent,
                'confidence': confidence,
                'emotion': emotion_result.emotion
            }
        )
        
        # ç”Ÿæˆå»ºè®®å›å¤
        suggestions = _generate_suggestions(intent, context)
        
        return ChatResponse(
            response=response_text,
            session_id=session_id,
            intent=intent,
            emotion=emotion_result.emotion,
            confidence=confidence,
            suggestions=suggestions,
            need_human_transfer=need_transfer
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")

@app.post("/api/session", response_model=SessionResponse)
async def create_session(request: SessionRequest):
    """åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯"""
    try:
        session_id = conversation_manager.create_session(request.user_id)
        return SessionResponse(
            session_id=session_id,
            status="created"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")

@app.get("/api/session/{session_id}/history")
async def get_conversation_history(session_id: str, limit: int = 10):
    """è·å–å¯¹è¯å†å²"""
    try:
        messages = conversation_manager.get_conversation_history(session_id, limit)
        return {
            "session_id": session_id,
            "messages": [
                {
                    "content": msg.content,
                    "type": msg.message_type,
                    "timestamp": msg.timestamp.isoformat(),
                    "metadata": msg.metadata
                }
                for msg in messages
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}")

@app.post("/api/session/{session_id}/transfer")
async def transfer_to_human(session_id: str):
    """è½¬æ¥äººå·¥å®¢æœ"""
    try:
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        success = conversation_manager.update_context(
            session_id,
            conversation_state="transferred"
        )
        
        if success:
            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
            conversation_manager.add_message(
                session_id,
                "å·²ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨å€™...",
                "system"
            )
            
            return {"status": "transferred", "message": "å·²æˆåŠŸè½¬æ¥äººå·¥å®¢æœ"}
        else:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è½¬æ¥å¤±è´¥: {str(e)}")

@app.get("/api/analytics/emotion/{session_id}")
async def get_emotion_analysis(session_id: str):
    """è·å–å¯¹è¯æƒ…æ„Ÿåˆ†æ"""
    try:
        # è·å–å¯¹è¯å†å²
        messages = conversation_manager.get_conversation_history(session_id, 20)
        user_messages = [msg.content for msg in messages if msg.message_type == "user"]
        
        if not user_messages:
            return {"error": "æ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯å¯åˆ†æ"}
        
        # åˆ†ææƒ…æ„Ÿè¶‹åŠ¿
        emotion_trend = emotion_service.analyze_conversation_emotion_trend(user_messages)
        
        return {
            "session_id": session_id,
            "emotion_analysis": emotion_trend
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")

def _generate_suggestions(intent: str, context) -> List[str]:
    """æ ¹æ®æ„å›¾ç”Ÿæˆå»ºè®®å›å¤"""
    suggestions_map = {
        "product_inquiry": [
            "æŸ¥çœ‹äº§å“è¯¦æƒ…",
            "æ¯”è¾ƒä¸åŒäº§å“",
            "è”ç³»é”€å”®é¡¾é—®"
        ],
        "order_status": [
            "æŸ¥è¯¢ç‰©æµä¿¡æ¯",
            "ä¿®æ”¹æ”¶è´§åœ°å€",
            "ç”³è¯·é€€æ¢è´§"
        ],
        "technical_support": [
            "æŸ¥çœ‹ä½¿ç”¨æ‰‹å†Œ",
            "è§‚çœ‹è§†é¢‘æ•™ç¨‹",
            "é¢„çº¦æŠ€æœ¯æ”¯æŒ"
        ],
        "complaint": [
            "æäº¤è¯¦ç»†åé¦ˆ",
            "ç”³è¯·é€€æ¬¾",
            "è”ç³»å®¢æœä¸»ç®¡"
        ]
    }
    
    return suggestions_map.get(intent, ["æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£", "è”ç³»äººå·¥å®¢æœ"])

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

è¿™ä¸ªæ™ºèƒ½å®¢æœç³»ç»Ÿçš„æ ¸å¿ƒå®ç°åŒ…æ‹¬äº†å¯¹è¯ç®¡ç†ã€è‡ªç„¶è¯­è¨€ç†è§£ã€çŸ¥è¯†åº“æ£€ç´¢ã€æƒ…æ„Ÿåˆ†æç­‰å…³é”®åŠŸèƒ½ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†ç»§ç»­å®Œå–„å‰ç«¯ç•Œé¢å’Œéƒ¨ç½²é…ç½®ã€‚