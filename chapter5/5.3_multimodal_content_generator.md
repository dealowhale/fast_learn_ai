# 5.3 å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨

## 5.3.1 é¡¹ç›®æ¦‚è¿°

### é¡¹ç›®ç›®æ ‡

å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨æ˜¯ä¸€ä¸ªé›†æˆäº†æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç”Ÿæˆèƒ½åŠ›çš„AIåº”ç”¨ç³»ç»Ÿã€‚è¯¥é¡¹ç›®æ—¨åœ¨å±•ç¤ºå¦‚ä½•å°†å¤šç§ç”Ÿæˆå¼AIæ¨¡å‹æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°ä¸­ï¼Œä¸ºç”¨æˆ·æä¾›ä¸°å¯Œçš„å†…å®¹åˆ›ä½œå·¥å…·ã€‚

**æ ¸å¿ƒåŠŸèƒ½**:
- ğŸ“ æ™ºèƒ½æ–‡æœ¬ç”Ÿæˆï¼ˆæ–‡ç« ã€æ•…äº‹ã€è¯—æ­Œç­‰ï¼‰
- ğŸ¨ AIå›¾åƒç”Ÿæˆï¼ˆåŸºäºæ–‡æœ¬æè¿°ï¼‰
- ğŸµ éŸ³é¢‘å†…å®¹ç”Ÿæˆï¼ˆè¯­éŸ³åˆæˆã€éŸ³ä¹ç”Ÿæˆï¼‰
- ğŸ”„ è·¨æ¨¡æ€è½¬æ¢ï¼ˆæ–‡æœ¬è½¬å›¾åƒã€å›¾åƒè½¬æ–‡æœ¬ç­‰ï¼‰
- ğŸ“Š å†…å®¹è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–å»ºè®®

**é¢„æœŸæ•ˆæœ**:
- æä¾›ä¸€ç«™å¼å†…å®¹åˆ›ä½œè§£å†³æ–¹æ¡ˆ
- æ”¯æŒå¤šç§åˆ›ä½œåœºæ™¯å’Œç”¨æˆ·éœ€æ±‚
- å®ç°é«˜è´¨é‡çš„å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ
- æä¾›ç›´è§‚æ˜“ç”¨çš„ç”¨æˆ·ç•Œé¢

### ä¸šåŠ¡åœºæ™¯åˆ†æ

**ç›®æ ‡ç”¨æˆ·**:
- å†…å®¹åˆ›ä½œè€…ï¼ˆåšä¸»ã€ä½œå®¶ã€è®¾è®¡å¸ˆï¼‰
- è¥é”€äººå‘˜ï¼ˆå¹¿å‘Šæ–‡æ¡ˆã€è§†è§‰è®¾è®¡ï¼‰
- æ•™è‚²å·¥ä½œè€…ï¼ˆè¯¾ä»¶åˆ¶ä½œã€æ•™å­¦èµ„æºï¼‰
- ä¼ä¸šç”¨æˆ·ï¼ˆå“ç‰Œå®£ä¼ ã€äº§å“ä»‹ç»ï¼‰

**åº”ç”¨åœºæ™¯**:
1. **åˆ›æ„å†™ä½œ**: å°è¯´ã€è¯—æ­Œã€å‰§æœ¬åˆ›ä½œè¾…åŠ©
2. **è¥é”€å†…å®¹**: å¹¿å‘Šæ–‡æ¡ˆã€äº§å“æè¿°ã€å®£ä¼ æµ·æŠ¥
3. **æ•™è‚²èµ„æº**: æ•™å­¦ææ–™ã€è¯¾ä»¶æ’å›¾ã€è§£è¯´éŸ³é¢‘
4. **ç¤¾äº¤åª’ä½“**: å¸–å­é…å›¾ã€çŸ­è§†é¢‘è„šæœ¬ã€èƒŒæ™¯éŸ³ä¹
5. **ä¼ä¸šåº”ç”¨**: æŠ¥å‘Šé…å›¾ã€æ¼”ç¤ºæ–‡ç¨¿ã€åŸ¹è®­ææ–™

## 5.3.2 ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "ç”¨æˆ·ç•Œé¢å±‚"
        A[Webå‰ç«¯ç•Œé¢]
        B[ç§»åŠ¨ç«¯åº”ç”¨]
        C[APIæ¥å£]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚"
        D[å†…å®¹ç”ŸæˆæœåŠ¡]
        E[æ¨¡æ€è½¬æ¢æœåŠ¡]
        F[è´¨é‡è¯„ä¼°æœåŠ¡]
        G[ç”¨æˆ·ç®¡ç†æœåŠ¡]
    end
    
    subgraph "AIæ¨¡å‹å±‚"
        H[æ–‡æœ¬ç”Ÿæˆæ¨¡å‹]
        I[å›¾åƒç”Ÿæˆæ¨¡å‹]
        J[éŸ³é¢‘ç”Ÿæˆæ¨¡å‹]
        K[å¤šæ¨¡æ€ç†è§£æ¨¡å‹]
    end
    
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        L[ç”¨æˆ·æ•°æ®åº“]
        M[å†…å®¹å­˜å‚¨]
        N[æ¨¡å‹ç¼“å­˜]
        O[é…ç½®ç®¡ç†]
    end
    
    subgraph "åŸºç¡€è®¾æ–½å±‚"
        P[è´Ÿè½½å‡è¡¡]
        Q[æ¶ˆæ¯é˜Ÿåˆ—]
        R[ç›‘æ§å‘Šè­¦]
        S[æ—¥å¿—ç³»ç»Ÿ]
    end
    
    A --> D
    B --> D
    C --> D
    
    D --> H
    D --> I
    D --> J
    E --> K
    F --> K
    
    D --> L
    D --> M
    H --> N
    I --> N
    J --> N
    
    D --> Q
    Q --> R
    R --> S
```

### æ ¸å¿ƒæ¨¡å—è¯´æ˜

**1. å†…å®¹ç”ŸæˆæœåŠ¡**
- ç»Ÿä¸€çš„å†…å®¹ç”Ÿæˆæ¥å£
- æ”¯æŒå¤šç§ç”Ÿæˆæ¨¡å¼å’Œå‚æ•°é…ç½®
- å¼‚æ­¥å¤„ç†å’Œä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- ç”Ÿæˆç»“æœçš„åå¤„ç†å’Œä¼˜åŒ–

**2. æ¨¡æ€è½¬æ¢æœåŠ¡**
- æ–‡æœ¬åˆ°å›¾åƒçš„è½¬æ¢
- å›¾åƒåˆ°æ–‡æœ¬çš„æè¿°ç”Ÿæˆ
- æ–‡æœ¬åˆ°è¯­éŸ³çš„åˆæˆ
- è·¨æ¨¡æ€å†…å®¹ç†è§£å’Œåˆ†æ

**3. è´¨é‡è¯„ä¼°æœåŠ¡**
- ç”Ÿæˆå†…å®¹çš„è´¨é‡è¯„åˆ†
- å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
- æ”¹è¿›å»ºè®®å’Œä¼˜åŒ–æ–¹æ¡ˆ
- ç”¨æˆ·åé¦ˆæ”¶é›†å’Œåˆ†æ

### æŠ€æœ¯é€‰å‹

**åç«¯æŠ€æœ¯æ ˆ**:
- **æ¡†æ¶**: FastAPI + Python 3.9+
- **AIæ¨¡å‹**: Transformers, Diffusers, TTS
- **æ•°æ®åº“**: PostgreSQL + Redis
- **æ¶ˆæ¯é˜Ÿåˆ—**: Celery + Redis
- **æ–‡ä»¶å­˜å‚¨**: MinIO/AWS S3
- **ç›‘æ§**: Prometheus + Grafana

**å‰ç«¯æŠ€æœ¯æ ˆ**:
- **æ¡†æ¶**: React 18 + TypeScript
- **UIç»„ä»¶**: Ant Design
- **çŠ¶æ€ç®¡ç†**: Redux Toolkit
- **æ–‡ä»¶ä¸Šä¼ **: React Dropzone
- **å›¾è¡¨å¯è§†åŒ–**: ECharts

**AIæ¨¡å‹é›†æˆ**:
- **æ–‡æœ¬ç”Ÿæˆ**: GPT-3.5/4, Claude, LLaMA
- **å›¾åƒç”Ÿæˆ**: DALL-E, Stable Diffusion, Midjourney API
- **è¯­éŸ³åˆæˆ**: Azure Speech, Google TTS, ElevenLabs
- **å¤šæ¨¡æ€**: CLIP, BLIP, GPT-4V

## 5.3.3 æ ¸å¿ƒåŠŸèƒ½å®ç°

### æ–‡æœ¬ç”ŸæˆæœåŠ¡

```python
# text_generation_service.py
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import openai
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch
from datetime import datetime
import asyncio
import json

class TextGenerationType(Enum):
    """æ–‡æœ¬ç”Ÿæˆç±»å‹"""
    ARTICLE = "article"
    STORY = "story"
    POEM = "poem"
    SCRIPT = "script"
    SUMMARY = "summary"
    TRANSLATION = "translation"
    CODE = "code"
    EMAIL = "email"

@dataclass
class TextGenerationRequest:
    """æ–‡æœ¬ç”Ÿæˆè¯·æ±‚"""
    prompt: str
    generation_type: TextGenerationType
    max_length: int = 1000
    temperature: float = 0.7
    top_p: float = 0.9
    language: str = "zh-CN"
    style: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

@dataclass
class TextGenerationResult:
    """æ–‡æœ¬ç”Ÿæˆç»“æœ"""
    generated_text: str
    prompt: str
    generation_type: TextGenerationType
    quality_score: float
    word_count: int
    processing_time: float
    model_used: str
    suggestions: List[str]
    timestamp: datetime

class TextGenerationService:
    """æ–‡æœ¬ç”ŸæˆæœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.openai_client = openai.OpenAI(api_key=config.get('openai_api_key'))
        
        # åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        self.local_models = {}
        if config.get('use_local_models', False):
            self._load_local_models()
        
        # ç”Ÿæˆæ¨¡æ¿
        self.generation_templates = {
            TextGenerationType.ARTICLE: {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ç« å†™ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æ–‡ç« ã€‚',
                'user_template': 'è¯·æ ¹æ®ä»¥ä¸‹ä¸»é¢˜å†™ä¸€ç¯‡æ–‡ç« ï¼š{prompt}\n\nè¦æ±‚ï¼š\n- ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º\n- å†…å®¹ä¸°å¯Œï¼Œæœ‰æ·±åº¦\n- è¯­è¨€æµç•…ï¼Œæ˜“äºç†è§£\n- å­—æ•°æ§åˆ¶åœ¨{max_length}å­—ä»¥å†…'
            },
            TextGenerationType.STORY: {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰æƒ³è±¡åŠ›çš„æ•…äº‹åˆ›ä½œè€…ï¼Œæ“…é•¿ç¼–å†™å¼•äººå…¥èƒœçš„æ•…äº‹ã€‚',
                'user_template': 'è¯·æ ¹æ®ä»¥ä¸‹æç¤ºåˆ›ä½œä¸€ä¸ªæ•…äº‹ï¼š{prompt}\n\nè¦æ±‚ï¼š\n- æƒ…èŠ‚ç”ŸåŠ¨æœ‰è¶£\n- äººç‰©å½¢è±¡é²œæ˜\n- è¯­è¨€ç”ŸåŠ¨å½¢è±¡\n- å­—æ•°æ§åˆ¶åœ¨{max_length}å­—ä»¥å†…'
            },
            TextGenerationType.POEM: {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªè¯—æ­Œåˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿åˆ›ä½œå„ç§é£æ ¼çš„è¯—æ­Œã€‚',
                'user_template': 'è¯·æ ¹æ®ä»¥ä¸‹ä¸»é¢˜åˆ›ä½œä¸€é¦–è¯—ï¼š{prompt}\n\nè¦æ±‚ï¼š\n- æ„å¢ƒä¼˜ç¾ï¼Œæƒ…æ„ŸçœŸæŒš\n- éŸµå¾‹å’Œè°ï¼Œæœ—æœ—ä¸Šå£\n- è¯­è¨€ç²¾ç»ƒï¼Œå¯Œæœ‰è¯—æ„\n- é•¿åº¦é€‚ä¸­'
            },
            TextGenerationType.SCRIPT: {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªå‰§æœ¬åˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿ç¼–å†™å„ç§ç±»å‹çš„å‰§æœ¬ã€‚',
                'user_template': 'è¯·æ ¹æ®ä»¥ä¸‹æƒ…èŠ‚åˆ›ä½œä¸€ä¸ªå‰§æœ¬ç‰‡æ®µï¼š{prompt}\n\nè¦æ±‚ï¼š\n- å¯¹è¯è‡ªç„¶æµç•…\n- åœºæ™¯æè¿°ç”ŸåŠ¨\n- äººç‰©æ€§æ ¼é²œæ˜\n- åŒ…å«èˆå°æŒ‡å¯¼'
            }
        }
    
    def _load_local_models(self):
        """åŠ è½½æœ¬åœ°æ¨¡å‹"""
        try:
            # åŠ è½½ä¸­æ–‡æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
            model_name = "THUDM/chatglm3-6b"
            self.local_models['chatglm'] = {
                'tokenizer': AutoTokenizer.from_pretrained(model_name, trust_remote_code=True),
                'model': AutoModelForCausalLM.from_pretrained(
                    model_name, 
                    trust_remote_code=True,
                    torch_dtype=torch.float16,
                    device_map="auto"
                )
            }
            print("æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    async def generate_text(self, request: TextGenerationRequest) -> TextGenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        start_time = datetime.now()
        
        try:
            # é€‰æ‹©ç”Ÿæˆç­–ç•¥
            if self.config.get('prefer_openai', True):
                generated_text = await self._generate_with_openai(request)
                model_used = "OpenAI GPT"
            else:
                generated_text = await self._generate_with_local_model(request)
                model_used = "Local Model"
            
            # åå¤„ç†
            processed_text = self._post_process_text(generated_text, request)
            
            # è´¨é‡è¯„ä¼°
            quality_score = await self._evaluate_text_quality(processed_text, request)
            
            # ç”Ÿæˆå»ºè®®
            suggestions = await self._generate_suggestions(processed_text, request)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return TextGenerationResult(
                generated_text=processed_text,
                prompt=request.prompt,
                generation_type=request.generation_type,
                quality_score=quality_score,
                word_count=len(processed_text),
                processing_time=processing_time,
                model_used=model_used,
                suggestions=suggestions,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            print(f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def _generate_with_openai(self, request: TextGenerationRequest) -> str:
        """ä½¿ç”¨OpenAI APIç”Ÿæˆæ–‡æœ¬"""
        template = self.generation_templates.get(request.generation_type)
        if not template:
            template = {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œåŠ©æ‰‹ã€‚',
                'user_template': '{prompt}'
            }
        
        messages = [
            {"role": "system", "content": template['system_prompt']},
            {"role": "user", "content": template['user_template'].format(
                prompt=request.prompt,
                max_length=request.max_length
            )}
        ]
        
        response = await asyncio.to_thread(
            self.openai_client.chat.completions.create,
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=min(request.max_length * 2, 4000),
            temperature=request.temperature,
            top_p=request.top_p
        )
        
        return response.choices[0].message.content
    
    async def _generate_with_local_model(self, request: TextGenerationRequest) -> str:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ–‡æœ¬"""
        if 'chatglm' not in self.local_models:
            raise ValueError("æœ¬åœ°æ¨¡å‹æœªåŠ è½½")
        
        model_info = self.local_models['chatglm']
        tokenizer = model_info['tokenizer']
        model = model_info['model']
        
        # æ„å»ºæç¤º
        template = self.generation_templates.get(request.generation_type, {})
        system_prompt = template.get('system_prompt', 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œåŠ©æ‰‹ã€‚')
        user_prompt = template.get('user_template', '{prompt}').format(
            prompt=request.prompt,
            max_length=request.max_length
        )
        
        full_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        # ç”Ÿæˆæ–‡æœ¬
        def generate():
            inputs = tokenizer.encode(full_prompt, return_tensors="pt")
            with torch.no_grad():
                outputs = model.generate(
                    inputs,
                    max_length=len(inputs[0]) + request.max_length,
                    temperature=request.temperature,
                    top_p=request.top_p,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            # ç§»é™¤åŸå§‹æç¤ºéƒ¨åˆ†
            return generated_text[len(full_prompt):].strip()
        
        return await asyncio.to_thread(generate)
    
    def _post_process_text(self, text: str, request: TextGenerationRequest) -> str:
        """æ–‡æœ¬åå¤„ç†"""
        # æ¸…ç†æ–‡æœ¬
        text = text.strip()
        
        # æ ¹æ®ç”Ÿæˆç±»å‹è¿›è¡Œç‰¹å®šå¤„ç†
        if request.generation_type == TextGenerationType.POEM:
            # è¯—æ­Œæ ¼å¼åŒ–
            lines = text.split('\n')
            formatted_lines = [line.strip() for line in lines if line.strip()]
            text = '\n'.join(formatted_lines)
        
        elif request.generation_type == TextGenerationType.SCRIPT:
            # å‰§æœ¬æ ¼å¼åŒ–
            text = self._format_script(text)
        
        # é•¿åº¦æ§åˆ¶
        if len(text) > request.max_length:
            # æ™ºèƒ½æˆªæ–­ï¼Œä¿æŒå®Œæ•´æ€§
            text = self._smart_truncate(text, request.max_length)
        
        return text
    
    def _format_script(self, text: str) -> str:
        """æ ¼å¼åŒ–å‰§æœ¬"""
        lines = text.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # è¯†åˆ«å¯¹è¯å’Œèˆå°æŒ‡å¯¼
            if line.startswith('(') and line.endswith(')'):
                # èˆå°æŒ‡å¯¼
                formatted_lines.append(f"    {line}")
            elif ':' in line:
                # å¯¹è¯
                parts = line.split(':', 1)
                character = parts[0].strip()
                dialogue = parts[1].strip()
                formatted_lines.append(f"{character.upper()}: {dialogue}")
            else:
                formatted_lines.append(line)
        
        return '\n'.join(formatted_lines)
    
    def _smart_truncate(self, text: str, max_length: int) -> str:
        """æ™ºèƒ½æˆªæ–­æ–‡æœ¬"""
        if len(text) <= max_length:
            return text
        
        # å°è¯•åœ¨å¥å·å¤„æˆªæ–­
        truncated = text[:max_length]
        last_period = truncated.rfind('ã€‚')
        
        if last_period > max_length * 0.8:  # å¦‚æœå¥å·ä½ç½®åˆç†
            return text[:last_period + 1]
        
        # å¦åˆ™åœ¨æœ€åä¸€ä¸ªå®Œæ•´è¯å¤„æˆªæ–­
        last_space = truncated.rfind(' ')
        if last_space > max_length * 0.9:
            return text[:last_space] + '...'
        
        return text[:max_length - 3] + '...'
    
    async def _evaluate_text_quality(self, text: str, request: TextGenerationRequest) -> float:
        """è¯„ä¼°æ–‡æœ¬è´¨é‡"""
        quality_score = 0.0
        
        # åŸºç¡€æŒ‡æ ‡
        if len(text) > 50:  # é•¿åº¦åˆç†
            quality_score += 0.2
        
        if len(text.split()) > 10:  # è¯æ±‡ä¸°å¯Œåº¦
            quality_score += 0.2
        
        # ç»“æ„å®Œæ•´æ€§
        if request.generation_type == TextGenerationType.ARTICLE:
            if '\n' in text:  # æœ‰æ®µè½ç»“æ„
                quality_score += 0.2
        
        elif request.generation_type == TextGenerationType.POEM:
            lines = text.split('\n')
            if len(lines) >= 4:  # è¯—æ­Œè¡Œæ•°åˆç†
                quality_score += 0.2
        
        # è¯­è¨€æµç•…åº¦ï¼ˆç®€åŒ–è¯„ä¼°ï¼‰
        sentences = text.split('ã€‚')
        if len(sentences) >= 3:  # å¥å­æ•°é‡åˆç†
            quality_score += 0.2
        
        # å†…å®¹ç›¸å…³æ€§ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
        prompt_keywords = set(request.prompt.split())
        text_keywords = set(text.split())
        relevance = len(prompt_keywords & text_keywords) / len(prompt_keywords) if prompt_keywords else 0
        quality_score += relevance * 0.2
        
        return min(quality_score, 1.0)
    
    async def _generate_suggestions(self, text: str, request: TextGenerationRequest) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # é•¿åº¦å»ºè®®
        if len(text) < request.max_length * 0.5:
            suggestions.append("å†…å®¹å¯ä»¥æ›´åŠ ä¸°å¯Œè¯¦ç»†")
        elif len(text) > request.max_length * 0.9:
            suggestions.append("å†…å®¹è¾ƒé•¿ï¼Œå¯ä»¥é€‚å½“ç²¾ç®€")
        
        # ç»“æ„å»ºè®®
        if request.generation_type == TextGenerationType.ARTICLE:
            if text.count('\n') < 2:
                suggestions.append("å»ºè®®å¢åŠ æ®µè½ç»“æ„ï¼Œæé«˜å¯è¯»æ€§")
        
        # è¯­è¨€å»ºè®®
        if text.count('ï¼Œ') / len(text) > 0.05:
            suggestions.append("å¥å­å¯ä»¥æ›´åŠ ç®€æ´æ˜äº†")
        
        # å†…å®¹å»ºè®®
        if request.generation_type == TextGenerationType.STORY:
            if 'å¯¹è¯' not in text and '"' not in text:
                suggestions.append("å¯ä»¥å¢åŠ äººç‰©å¯¹è¯ï¼Œä½¿æ•…äº‹æ›´ç”ŸåŠ¨")
        
        return suggestions[:3]  # æœ€å¤šè¿”å›3ä¸ªå»ºè®®
    
    async def batch_generate(self, requests: List[TextGenerationRequest]) -> List[TextGenerationResult]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬"""
        tasks = [self.generate_text(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"æ‰¹é‡ç”Ÿæˆç¬¬{i+1}ä¸ªè¯·æ±‚å¤±è´¥: {result}")
                # åˆ›å»ºé”™è¯¯ç»“æœ
                error_result = TextGenerationResult(
                    generated_text=f"ç”Ÿæˆå¤±è´¥: {str(result)}",
                    prompt=requests[i].prompt,
                    generation_type=requests[i].generation_type,
                    quality_score=0.0,
                    word_count=0,
                    processing_time=0.0,
                    model_used="Error",
                    suggestions=["è¯·æ£€æŸ¥è¾“å…¥å‚æ•°æˆ–ç¨åé‡è¯•"],
                    timestamp=datetime.now()
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        return processed_results
```

### éŸ³é¢‘ç”ŸæˆæœåŠ¡

```python
# audio_generation_service.py
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import requests
import base64
from datetime import datetime
import asyncio
import aiohttp
import io
import wave
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize
import torch
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan
from datasets import load_dataset

class AudioType(Enum):
    """éŸ³é¢‘ç±»å‹"""
    SPEECH = "speech"
    MUSIC = "music"
    SOUND_EFFECT = "sound_effect"
    NARRATION = "narration"
    PODCAST = "podcast"

class VoiceStyle(Enum):
    """è¯­éŸ³é£æ ¼"""
    NATURAL = "natural"
    PROFESSIONAL = "professional"
    CASUAL = "casual"
    DRAMATIC = "dramatic"
    CHEERFUL = "cheerful"
    CALM = "calm"
    ENERGETIC = "energetic"

@dataclass
class AudioGenerationRequest:
    """éŸ³é¢‘ç”Ÿæˆè¯·æ±‚"""
    text: str
    audio_type: AudioType = AudioType.SPEECH
    voice_style: VoiceStyle = VoiceStyle.NATURAL
    language: str = "zh-CN"
    speed: float = 1.0  # è¯­é€Ÿå€ç‡
    pitch: float = 1.0  # éŸ³è°ƒå€ç‡
    volume: float = 1.0  # éŸ³é‡å€ç‡
    background_music: Optional[str] = None
    output_format: str = "mp3"
    sample_rate: int = 22050

@dataclass
class AudioGenerationResult:
    """éŸ³é¢‘ç”Ÿæˆç»“æœ"""
    audio_data: bytes
    text: str
    audio_type: AudioType
    voice_style: VoiceStyle
    duration: float  # éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    file_size: int  # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    generation_time: float
    model_used: str
    quality_score: float
    suggestions: List[str]
    timestamp: datetime

class AudioGenerationService:
    """éŸ³é¢‘ç”ŸæˆæœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # APIé…ç½®
        self.azure_speech_key = config.get('azure_speech_key')
        self.azure_region = config.get('azure_region', 'eastus')
        self.elevenlabs_api_key = config.get('elevenlabs_api_key')
        
        # æœ¬åœ°TTSæ¨¡å‹
        self.local_tts_model = None
        self.local_processor = None
        self.local_vocoder = None
        
        if config.get('use_local_tts', False):
            self._load_local_tts_model()
        
        # è¯­éŸ³é£æ ¼é…ç½®
        self.voice_configs = {
            VoiceStyle.NATURAL: {
                'azure_voice': 'zh-CN-XiaoxiaoNeural',
                'elevenlabs_voice': 'Bella',
                'speed': 1.0,
                'pitch': 1.0
            },
            VoiceStyle.PROFESSIONAL: {
                'azure_voice': 'zh-CN-YunxiNeural',
                'elevenlabs_voice': 'Josh',
                'speed': 0.9,
                'pitch': 0.95
            },
            VoiceStyle.CASUAL: {
                'azure_voice': 'zh-CN-XiaoyiNeural',
                'elevenlabs_voice': 'Antoni',
                'speed': 1.1,
                'pitch': 1.05
            },
            VoiceStyle.DRAMATIC: {
                'azure_voice': 'zh-CN-YunyangNeural',
                'elevenlabs_voice': 'Arnold',
                'speed': 0.8,
                'pitch': 0.9
            }
        }
    
    def _load_local_tts_model(self):
        """åŠ è½½æœ¬åœ°TTSæ¨¡å‹"""
        try:
            # ä½¿ç”¨SpeechT5æ¨¡å‹
            model_name = "microsoft/speecht5_tts"
            
            self.local_processor = SpeechT5Processor.from_pretrained(model_name)
            self.local_tts_model = SpeechT5ForTextToSpeech.from_pretrained(model_name)
            self.local_vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
            
            # åŠ è½½è¯´è¯äººåµŒå…¥
            embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
            self.speaker_embeddings = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)
            
            print("æœ¬åœ°TTSæ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"æœ¬åœ°TTSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.local_tts_model = None
    
    async def generate_audio(self, request: AudioGenerationRequest) -> AudioGenerationResult:
        """ç”ŸæˆéŸ³é¢‘"""
        start_time = datetime.now()
        
        try:
            # é€‰æ‹©ç”Ÿæˆæ–¹æ³•
            if request.audio_type == AudioType.SPEECH:
                if self.elevenlabs_api_key and self.config.get('prefer_elevenlabs', False):
                    audio_data = await self._generate_with_elevenlabs(request)
                    model_used = "ElevenLabs"
                elif self.azure_speech_key:
                    audio_data = await self._generate_with_azure(request)
                    model_used = "Azure Speech"
                elif self.local_tts_model:
                    audio_data = await self._generate_with_local_tts(request)
                    model_used = "Local SpeechT5"
                else:
                    raise ValueError("æ²¡æœ‰å¯ç”¨çš„è¯­éŸ³åˆæˆæœåŠ¡")
            
            elif request.audio_type == AudioType.MUSIC:
                audio_data = await self._generate_music(request)
                model_used = "Music Generation"
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘ç±»å‹: {request.audio_type}")
            
            # åå¤„ç†éŸ³é¢‘
            processed_audio = self._post_process_audio(audio_data, request)
            
            # è®¡ç®—éŸ³é¢‘ä¿¡æ¯
            duration = self._get_audio_duration(processed_audio)
            file_size = len(processed_audio)
            
            # è´¨é‡è¯„ä¼°
            quality_score = await self._evaluate_audio_quality(processed_audio, request)
            
            # ç”Ÿæˆå»ºè®®
            suggestions = await self._generate_audio_suggestions(request, quality_score)
            
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return AudioGenerationResult(
                audio_data=processed_audio,
                text=request.text,
                audio_type=request.audio_type,
                voice_style=request.voice_style,
                duration=duration,
                file_size=file_size,
                generation_time=generation_time,
                model_used=model_used,
                quality_score=quality_score,
                suggestions=suggestions,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            print(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            raise
```

### ç³»ç»Ÿé›†æˆä¸APIè®¾è®¡

```python
# main.py - å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨ä¸»æœåŠ¡
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import io
import json
from datetime import datetime
import uuid

# å¯¼å…¥æœåŠ¡
from .text_generation_service import (
    TextGenerationService, TextGenerationRequest, TextGenerationType
)
from .image_generation_service import (
    ImageGenerationService, ImageGenerationRequest, ImageStyle, ImageSize
)
from .audio_generation_service import (
    AudioGenerationService, AudioGenerationRequest, AudioType, VoiceStyle
)
from .multimodal_conversion_service import (
    MultimodalConversionService, ConversionRequest, ConversionType
)

app = FastAPI(
    title="å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨",
    description="é›†æˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç”Ÿæˆå’Œè·¨æ¨¡æ€è½¬æ¢çš„AIå†…å®¹åˆ›ä½œå¹³å°",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€é…ç½®
config = {
    'openai_api_key': 'your-openai-key',
    'stability_api_key': 'your-stability-key',
    'azure_speech_key': 'your-azure-key',
    'azure_region': 'eastus',
    'elevenlabs_api_key': 'your-elevenlabs-key',
    'use_local_models': True,
    'prefer_openai': True,
    'prefer_elevenlabs': False
}

# åˆå§‹åŒ–æœåŠ¡
text_service = TextGenerationService(config)
image_service = ImageGenerationService(config)
audio_service = AudioGenerationService(config)
conversion_service = MultimodalConversionService(config)

# è¯·æ±‚æ¨¡å‹
class TextGenerationRequestModel(BaseModel):
    prompt: str
    generation_type: str = "article"
    max_length: int = 1000
    temperature: float = 0.7
    language: str = "zh-CN"
    style: Optional[str] = None

class ImageGenerationRequestModel(BaseModel):
    prompt: str
    negative_prompt: Optional[str] = None
    style: str = "realistic"
    size: str = "square_512"
    num_images: int = 1
    guidance_scale: float = 7.5
    num_inference_steps: int = 50

class AudioGenerationRequestModel(BaseModel):
    text: str
    audio_type: str = "speech"
    voice_style: str = "natural"
    language: str = "zh-CN"
    speed: float = 1.0
    pitch: float = 1.0
    volume: float = 1.0

class ConversionRequestModel(BaseModel):
    conversion_type: str
    target_language: str = "zh-CN"
    quality_level: str = "high"

# ä»»åŠ¡ç®¡ç†
active_tasks = {}

@app.get("/")
async def root():
    return {
        "message": "å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨API",
        "version": "1.0.0",
        "services": ["æ–‡æœ¬ç”Ÿæˆ", "å›¾åƒç”Ÿæˆ", "éŸ³é¢‘ç”Ÿæˆ", "æ¨¡æ€è½¬æ¢"]
    }

# æ–‡æœ¬ç”Ÿæˆæ¥å£
@app.post("/api/generate/text")
async def generate_text(request: TextGenerationRequestModel):
    """ç”Ÿæˆæ–‡æœ¬å†…å®¹"""
    try:
        # è½¬æ¢è¯·æ±‚
        gen_request = TextGenerationRequest(
            prompt=request.prompt,
            generation_type=TextGenerationType(request.generation_type),
            max_length=request.max_length,
            temperature=request.temperature,
            language=request.language,
            style=request.style
        )
        
        # ç”Ÿæˆæ–‡æœ¬
        result = await text_service.generate_text(gen_request)
        
        return {
            "success": True,
            "data": {
                "generated_text": result.generated_text,
                "quality_score": result.quality_score,
                "word_count": result.word_count,
                "processing_time": result.processing_time,
                "model_used": result.model_used,
                "suggestions": result.suggestions
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# å›¾åƒç”Ÿæˆæ¥å£
@app.post("/api/generate/image")
async def generate_image(request: ImageGenerationRequestModel):
    """ç”Ÿæˆå›¾åƒå†…å®¹"""
    try:
        # è½¬æ¢è¯·æ±‚
        gen_request = ImageGenerationRequest(
            prompt=request.prompt,
            negative_prompt=request.negative_prompt,
            style=ImageStyle(request.style),
            size=ImageSize[request.size.upper()],
            num_images=request.num_images,
            guidance_scale=request.guidance_scale,
            num_inference_steps=request.num_inference_steps
        )
        
        # ç”Ÿæˆå›¾åƒ
        result = await image_service.generate_images(gen_request)
        
        # è½¬æ¢ä¸ºbase64
        import base64
        images_b64 = [base64.b64encode(img).decode('utf-8') for img in result.images]
        
        return {
            "success": True,
            "data": {
                "images": images_b64,
                "enhanced_prompt": result.enhanced_prompt,
                "quality_score": result.quality_score,
                "generation_time": result.generation_time,
                "model_used": result.model_used,
                "suggestions": result.suggestions
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# éŸ³é¢‘ç”Ÿæˆæ¥å£
@app.post("/api/generate/audio")
async def generate_audio(request: AudioGenerationRequestModel):
    """ç”ŸæˆéŸ³é¢‘å†…å®¹"""
    try:
        # è½¬æ¢è¯·æ±‚
        gen_request = AudioGenerationRequest(
            text=request.text,
            audio_type=AudioType(request.audio_type),
            voice_style=VoiceStyle(request.voice_style),
            language=request.language,
            speed=request.speed,
            pitch=request.pitch,
            volume=request.volume
        )
        
        # ç”ŸæˆéŸ³é¢‘
        result = await audio_service.generate_audio(gen_request)
        
        # è¿”å›éŸ³é¢‘æµ
        def generate_audio_stream():
            yield result.audio_data
        
        return StreamingResponse(
            io.BytesIO(result.audio_data),
            media_type="audio/mpeg",
            headers={
                "Content-Disposition": "attachment; filename=generated_audio.mp3",
                "X-Duration": str(result.duration),
                "X-Quality-Score": str(result.quality_score),
                "X-Model-Used": result.model_used
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ¨¡æ€è½¬æ¢æ¥å£
@app.post("/api/convert/{conversion_type}")
async def convert_content(
    conversion_type: str,
    request: ConversionRequestModel,
    file: Optional[UploadFile] = File(None),
    text: Optional[str] = Form(None)
):
    """è·¨æ¨¡æ€å†…å®¹è½¬æ¢"""
    try:
        # å‡†å¤‡æºæ•°æ®
        if file:
            source_data = await file.read()
        elif text:
            source_data = text
        else:
            raise HTTPException(status_code=400, detail="éœ€è¦æä¾›æ–‡ä»¶æˆ–æ–‡æœ¬æ•°æ®")
        
        # è½¬æ¢è¯·æ±‚
        conv_request = ConversionRequest(
            conversion_type=ConversionType(conversion_type),
            source_data=source_data,
            target_language=request.target_language,
            quality_level=request.quality_level
        )
        
        # æ‰§è¡Œè½¬æ¢
        result = await conversion_service.convert(conv_request)
        
        # æ ¹æ®è½¬æ¢ç±»å‹è¿”å›ç»“æœ
        if conversion_type.endswith('_to_text'):
            return {
                "success": True,
                "data": {
                    "text": result.target_data,
                    "confidence_score": result.confidence_score,
                    "processing_time": result.processing_time,
                    "model_used": result.model_used,
                    "metadata": result.metadata
                }
            }
        
        elif conversion_type.endswith('_to_image'):
            import base64
            image_b64 = base64.b64encode(result.target_data).decode('utf-8')
            return {
                "success": True,
                "data": {
                    "image": image_b64,
                    "confidence_score": result.confidence_score,
                    "processing_time": result.processing_time,
                    "model_used": result.model_used,
                    "metadata": result.metadata
                }
            }
        
        elif conversion_type.endswith('_to_audio'):
            return StreamingResponse(
                io.BytesIO(result.target_data),
                media_type="audio/mpeg",
                headers={
                    "Content-Disposition": "attachment; filename=converted_audio.mp3",
                    "X-Confidence-Score": str(result.confidence_score),
                    "X-Model-Used": result.model_used
                }
            )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ‰¹é‡å¤„ç†æ¥å£
@app.post("/api/batch/text")
async def batch_generate_text(requests: List[TextGenerationRequestModel]):
    """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬"""
    try:
        # è½¬æ¢è¯·æ±‚
        gen_requests = [
            TextGenerationRequest(
                prompt=req.prompt,
                generation_type=TextGenerationType(req.generation_type),
                max_length=req.max_length,
                temperature=req.temperature,
                language=req.language,
                style=req.style
            )
            for req in requests
        ]
        
        # æ‰¹é‡ç”Ÿæˆ
        results = await text_service.batch_generate(gen_requests)
        
        return {
            "success": True,
            "data": [
                {
                    "generated_text": result.generated_text,
                    "quality_score": result.quality_score,
                    "word_count": result.word_count,
                    "processing_time": result.processing_time,
                    "model_used": result.model_used,
                    "suggestions": result.suggestions
                }
                for result in results
            ]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
@app.get("/api/task/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return active_tasks[task_id]

# å¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "text_generation": "active",
            "image_generation": "active",
            "audio_generation": "active",
            "multimodal_conversion": "active"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## Trae AIå®è·µæŒ‡å—

### ç¯å¢ƒå‡†å¤‡

åœ¨Traeä¸­åˆ›å»ºå¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨é¡¹ç›®ï¼š

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir multimodal_content_generator
cd multimodal_content_generator

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install fastapi uvicorn
pip install openai stability-sdk
pip install azure-cognitiveservices-speech
pip install elevenlabs
pip install torch torchvision torchaudio
pip install transformers datasets
pip install pillow opencv-python
pip install pydub numpy
pip install streamlit
pip install aiohttp requests
```

### é¡¹ç›®ç»“æ„

```
multimodal_content_generator/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ text_generation_service.py
â”‚   â”œâ”€â”€ image_generation_service.py
â”‚   â”œâ”€â”€ audio_generation_service.py
â”‚   â””â”€â”€ multimodal_conversion_service.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_models.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ static/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### åœ¨Traeä¸­è¿è¡Œé¡¹ç›®

1. **é…ç½®APIå¯†é’¥**ï¼š
```python
# config.py
import os
from typing import Dict, Any

def get_config() -> Dict[str, Any]:
    return {
        'openai_api_key': os.getenv('OPENAI_API_KEY'),
        'stability_api_key': os.getenv('STABILITY_API_KEY'),
        'azure_speech_key': os.getenv('AZURE_SPEECH_KEY'),
        'azure_region': os.getenv('AZURE_REGION', 'eastus'),
        'elevenlabs_api_key': os.getenv('ELEVENLABS_API_KEY'),
        'use_local_models': True,
        'prefer_openai': True,
        'prefer_elevenlabs': False
    }
```

2. **å¯åŠ¨FastAPIæœåŠ¡**ï¼š
```bash
# åœ¨Traeç»ˆç«¯ä¸­è¿è¡Œ
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

3. **å¯åŠ¨Streamlitç•Œé¢**ï¼š
```bash
# æ–°å¼€ç»ˆç«¯è¿è¡Œ
streamlit run web/streamlit_app.py --server.port 8501
```

### Streamlitç”¨æˆ·ç•Œé¢

```python
# web/streamlit_app.py
import streamlit as st
import requests
import base64
import io
from PIL import Image
import json

st.set_page_config(
    page_title="å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨",
    page_icon="ğŸ¨",
    layout="wide"
)

st.title("ğŸ¨ å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨")
st.markdown("é›†æˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç”Ÿæˆå’Œè·¨æ¨¡æ€è½¬æ¢çš„AIå†…å®¹åˆ›ä½œå¹³å°")

# ä¾§è¾¹æ é…ç½®
st.sidebar.title("âš™ï¸ é…ç½®")
api_base_url = st.sidebar.text_input("APIåœ°å€", "http://localhost:8000")

# ä¸»ç•Œé¢é€‰é¡¹å¡
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ æ–‡æœ¬ç”Ÿæˆ", "ğŸ–¼ï¸ å›¾åƒç”Ÿæˆ", "ğŸµ éŸ³é¢‘ç”Ÿæˆ", "ğŸ”„ æ¨¡æ€è½¬æ¢"])

# æ–‡æœ¬ç”Ÿæˆé€‰é¡¹å¡
with tab1:
    st.header("ğŸ“ æ–‡æœ¬å†…å®¹ç”Ÿæˆ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        text_prompt = st.text_area("è¾“å…¥æç¤ºè¯", height=100, placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹æè¿°...")
        
    with col2:
        generation_type = st.selectbox(
            "ç”Ÿæˆç±»å‹",
            ["article", "story", "poem", "dialogue", "summary", "email", "code"]
        )
        max_length = st.slider("æœ€å¤§é•¿åº¦", 100, 2000, 1000)
        temperature = st.slider("åˆ›é€ æ€§", 0.1, 1.0, 0.7)
        language = st.selectbox("è¯­è¨€", ["zh-CN", "en-US", "ja-JP"])
    
    if st.button("ğŸš€ ç”Ÿæˆæ–‡æœ¬", type="primary"):
        if text_prompt:
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡æœ¬..."):
                try:
                    response = requests.post(
                        f"{api_base_url}/api/generate/text",
                        json={
                            "prompt": text_prompt,
                            "generation_type": generation_type,
                            "max_length": max_length,
                            "temperature": temperature,
                            "language": language
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        data = result["data"]
                        
                        st.success("âœ… æ–‡æœ¬ç”Ÿæˆå®Œæˆï¼")
                        
                        # æ˜¾ç¤ºç”Ÿæˆç»“æœ
                        st.subheader("ç”Ÿæˆç»“æœ")
                        st.write(data["generated_text"])
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("è´¨é‡è¯„åˆ†", f"{data['quality_score']:.2f}")
                        with col2:
                            st.metric("å­—æ•°", data["word_count"])
                        with col3:
                            st.metric("å¤„ç†æ—¶é—´", f"{data['processing_time']:.2f}s")
                        with col4:
                            st.metric("ä½¿ç”¨æ¨¡å‹", data["model_used"])
                        
                        # æ˜¾ç¤ºå»ºè®®
                        if data["suggestions"]:
                            st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
                            for suggestion in data["suggestions"]:
                                st.info(suggestion)
                    
                    else:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        else:
            st.warning("è¯·è¾“å…¥æç¤ºè¯")

# å›¾åƒç”Ÿæˆé€‰é¡¹å¡
with tab2:
    st.header("ğŸ–¼ï¸ å›¾åƒå†…å®¹ç”Ÿæˆ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        image_prompt = st.text_area("å›¾åƒæè¿°", height=100, placeholder="è¯·æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„å›¾åƒ...")
        negative_prompt = st.text_input("è´Ÿé¢æç¤ºè¯", placeholder="ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹...")
        
    with col2:
        image_style = st.selectbox(
            "å›¾åƒé£æ ¼",
            ["realistic", "artistic", "cartoon", "abstract", "photographic"]
        )
        image_size = st.selectbox(
            "å›¾åƒå°ºå¯¸",
            ["square_512", "portrait_768", "landscape_768", "square_1024"]
        )
        num_images = st.slider("ç”Ÿæˆæ•°é‡", 1, 4, 1)
        guidance_scale = st.slider("å¼•å¯¼å¼ºåº¦", 1.0, 20.0, 7.5)
    
    if st.button("ğŸ¨ ç”Ÿæˆå›¾åƒ", type="primary"):
        if image_prompt:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾åƒ..."):
                try:
                    response = requests.post(
                        f"{api_base_url}/api/generate/image",
                        json={
                            "prompt": image_prompt,
                            "negative_prompt": negative_prompt,
                            "style": image_style,
                            "size": image_size,
                            "num_images": num_images,
                            "guidance_scale": guidance_scale
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        data = result["data"]
                        
                        st.success("âœ… å›¾åƒç”Ÿæˆå®Œæˆï¼")
                        
                        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
                        st.subheader("ç”Ÿæˆç»“æœ")
                        
                        cols = st.columns(min(num_images, 3))
                        for i, image_b64 in enumerate(data["images"]):
                            image_data = base64.b64decode(image_b64)
                            image = Image.open(io.BytesIO(image_data))
                            
                            with cols[i % 3]:
                                st.image(image, caption=f"å›¾åƒ {i+1}", use_column_width=True)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    label=f"ä¸‹è½½å›¾åƒ {i+1}",
                                    data=image_data,
                                    file_name=f"generated_image_{i+1}.png",
                                    mime="image/png"
                                )
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("è´¨é‡è¯„åˆ†", f"{data['quality_score']:.2f}")
                        with col2:
                            st.metric("ç”Ÿæˆæ—¶é—´", f"{data['generation_time']:.2f}s")
                        with col3:
                            st.metric("ä½¿ç”¨æ¨¡å‹", data["model_used"])
                        
                        # æ˜¾ç¤ºå¢å¼ºæç¤ºè¯
                        st.subheader("ğŸ”§ å¢å¼ºæç¤ºè¯")
                        st.code(data["enhanced_prompt"])
                        
                        # æ˜¾ç¤ºå»ºè®®
                        if data["suggestions"]:
                            st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
                            for suggestion in data["suggestions"]:
                                st.info(suggestion)
                    
                    else:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        else:
            st.warning("è¯·è¾“å…¥å›¾åƒæè¿°")

# éŸ³é¢‘ç”Ÿæˆé€‰é¡¹å¡
with tab3:
    st.header("ğŸµ éŸ³é¢‘å†…å®¹ç”Ÿæˆ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        audio_text = st.text_area("æ–‡æœ¬å†…å®¹", height=150, placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬...")
        
    with col2:
        audio_type = st.selectbox(
            "éŸ³é¢‘ç±»å‹",
            ["speech", "narration", "podcast"]
        )
        voice_style = st.selectbox(
            "è¯­éŸ³é£æ ¼",
            ["natural", "professional", "casual", "dramatic", "cheerful"]
        )
        audio_language = st.selectbox("è¯­è¨€", ["zh-CN", "en-US", "ja-JP"])
        speed = st.slider("è¯­é€Ÿ", 0.5, 2.0, 1.0)
        pitch = st.slider("éŸ³è°ƒ", 0.5, 2.0, 1.0)
    
    if st.button("ğŸ¤ ç”ŸæˆéŸ³é¢‘", type="primary"):
        if audio_text:
            with st.spinner("æ­£åœ¨ç”ŸæˆéŸ³é¢‘..."):
                try:
                    response = requests.post(
                        f"{api_base_url}/api/generate/audio",
                        json={
                            "text": audio_text,
                            "audio_type": audio_type,
                            "voice_style": voice_style,
                            "language": audio_language,
                            "speed": speed,
                            "pitch": pitch
                        }
                    )
                    
                    if response.status_code == 200:
                        st.success("âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼")
                        
                        # æ’­æ”¾éŸ³é¢‘
                        st.subheader("ç”Ÿæˆç»“æœ")
                        st.audio(response.content, format="audio/mp3")
                        
                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½éŸ³é¢‘",
                            data=response.content,
                            file_name="generated_audio.mp3",
                            mime="audio/mp3"
                        )
                        
                        # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
                        headers = response.headers
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            if 'X-Duration' in headers:
                                st.metric("æ—¶é•¿", f"{float(headers['X-Duration']):.1f}s")
                        with col2:
                            if 'X-Quality-Score' in headers:
                                st.metric("è´¨é‡è¯„åˆ†", f"{float(headers['X-Quality-Score']):.2f}")
                        with col3:
                            if 'X-Model-Used' in headers:
                                st.metric("ä½¿ç”¨æ¨¡å‹", headers['X-Model-Used'])
                    
                    else:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        else:
            st.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹")

# æ¨¡æ€è½¬æ¢é€‰é¡¹å¡
with tab4:
    st.header("ğŸ”„ è·¨æ¨¡æ€å†…å®¹è½¬æ¢")
    
    conversion_type = st.selectbox(
        "è½¬æ¢ç±»å‹",
        [
            "text_to_image", "image_to_text",
            "text_to_audio", "audio_to_text",
            "image_to_audio", "audio_to_image"
        ]
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if conversion_type.startswith('text_'):
            source_text = st.text_area("æºæ–‡æœ¬", height=150, placeholder="è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬...")
            source_file = None
        else:
            source_text = None
            file_types = {
                'image_': ['png', 'jpg', 'jpeg', 'gif'],
                'audio_': ['mp3', 'wav', 'ogg', 'm4a']
            }
            
            file_type = next(k for k in file_types.keys() if conversion_type.startswith(k))
            source_file = st.file_uploader(
                "ä¸Šä¼ æ–‡ä»¶",
                type=file_types[file_type]
            )
    
    with col2:
        target_language = st.selectbox("ç›®æ ‡è¯­è¨€", ["zh-CN", "en-US", "ja-JP"])
        quality_level = st.selectbox("è´¨é‡çº§åˆ«", ["high", "medium", "low"])
    
    if st.button("ğŸ”„ å¼€å§‹è½¬æ¢", type="primary"):
        if (source_text and conversion_type.startswith('text_')) or (source_file and not conversion_type.startswith('text_')):
            with st.spinner("æ­£åœ¨è½¬æ¢..."):
                try:
                    # å‡†å¤‡è¯·æ±‚æ•°æ®
                    files = {}
                    data = {
                        "target_language": target_language,
                        "quality_level": quality_level
                    }
                    
                    if source_file:
                        files["file"] = source_file
                    if source_text:
                        data["text"] = source_text
                    
                    response = requests.post(
                        f"{api_base_url}/api/convert/{conversion_type}",
                        files=files if files else None,
                        data=data
                    )
                    
                    if response.status_code == 200:
                        st.success("âœ… è½¬æ¢å®Œæˆï¼")
                        
                        # æ ¹æ®è½¬æ¢ç±»å‹æ˜¾ç¤ºç»“æœ
                        if conversion_type.endswith('_to_text'):
                            result = response.json()
                            data = result["data"]
                            
                            st.subheader("è½¬æ¢ç»“æœ")
                            st.write(data["text"])
                            
                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ç½®ä¿¡åº¦", f"{data['confidence_score']:.2f}")
                            with col2:
                                st.metric("å¤„ç†æ—¶é—´", f"{data['processing_time']:.2f}s")
                            with col3:
                                st.metric("ä½¿ç”¨æ¨¡å‹", data["model_used"])
                        
                        elif conversion_type.endswith('_to_image'):
                            result = response.json()
                            data = result["data"]
                            
                            # æ˜¾ç¤ºå›¾åƒ
                            image_data = base64.b64decode(data["image"])
                            image = Image.open(io.BytesIO(image_data))
                            
                            st.subheader("è½¬æ¢ç»“æœ")
                            st.image(image, use_column_width=True)
                            
                            # ä¸‹è½½æŒ‰é’®
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½å›¾åƒ",
                                data=image_data,
                                file_name="converted_image.png",
                                mime="image/png"
                            )
                        
                        elif conversion_type.endswith('_to_audio'):
                            st.subheader("è½¬æ¢ç»“æœ")
                            st.audio(response.content, format="audio/mp3")
                            
                            # ä¸‹è½½æŒ‰é’®
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½éŸ³é¢‘",
                                data=response.content,
                                file_name="converted_audio.mp3",
                                mime="audio/mp3"
                            )
                    
                    else:
                        st.error(f"è½¬æ¢å¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        else:
            st.warning("è¯·æä¾›æºå†…å®¹")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ¨ å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨ | åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIå†…å®¹åˆ›ä½œå¹³å°</p>
        <p>æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç”Ÿæˆå’Œè·¨æ¨¡æ€è½¬æ¢</p>
    </div>
    """,
    unsafe_allow_html=True
)
```

### æµ‹è¯•å’Œè°ƒè¯•

åœ¨Traeä¸­è¿›è¡Œé¡¹ç›®æµ‹è¯•ï¼š

```python
# test_services.py
import asyncio
import pytest
from services.text_generation_service import TextGenerationService, TextGenerationRequest, TextGenerationType
from services.image_generation_service import ImageGenerationService, ImageGenerationRequest, ImageStyle
from services.audio_generation_service import AudioGenerationService, AudioGenerationRequest, AudioType

@pytest.fixture
def config():
    return {
        'openai_api_key': 'test-key',
        'use_local_models': True,
        'prefer_openai': False
    }

@pytest.mark.asyncio
async def test_text_generation(config):
    service = TextGenerationService(config)
    request = TextGenerationRequest(
        prompt="å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ",
        generation_type=TextGenerationType.ARTICLE,
        max_length=500
    )
    
    result = await service.generate_text(request)
    assert result.generated_text
    assert result.quality_score > 0
    assert result.word_count > 0

@pytest.mark.asyncio
async def test_image_generation(config):
    service = ImageGenerationService(config)
    request = ImageGenerationRequest(
        prompt="ä¸€åªå¯çˆ±çš„å°çŒ«",
        style=ImageStyle.REALISTIC,
        num_images=1
    )
    
    result = await service.generate_images(request)
    assert len(result.images) == 1
    assert result.quality_score > 0

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    pytest.main(["-v", "test_services.py"])
```

### æ€§èƒ½ç›‘æ§

```python
# monitoring.py
import time
import psutil
import logging
from typing import Dict, Any
from datetime import datetime

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'requests_count': 0,
            'total_processing_time': 0.0,
            'average_processing_time': 0.0,
            'memory_usage': 0.0,
            'cpu_usage': 0.0
        }
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('performance.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def start_request(self) -> float:
        """å¼€å§‹è¯·æ±‚è®¡æ—¶"""
        return time.time()
    
    def end_request(self, start_time: float, request_type: str):
        """ç»“æŸè¯·æ±‚è®¡æ—¶å¹¶è®°å½•æŒ‡æ ‡"""
        processing_time = time.time() - start_time
        
        self.metrics['requests_count'] += 1
        self.metrics['total_processing_time'] += processing_time
        self.metrics['average_processing_time'] = (
            self.metrics['total_processing_time'] / self.metrics['requests_count']
        )
        
        # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        self.metrics['memory_usage'] = psutil.virtual_memory().percent
        self.metrics['cpu_usage'] = psutil.cpu_percent()
        
        # è®°å½•æ—¥å¿—
        self.logger.info(
            f"Request completed - Type: {request_type}, "
            f"Time: {processing_time:.2f}s, "
            f"Memory: {self.metrics['memory_usage']:.1f}%, "
            f"CPU: {self.metrics['cpu_usage']:.1f}%"
        )
    
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            **self.metrics,
            'timestamp': datetime.now().isoformat()
        }
    
    def reset_metrics(self):
        """é‡ç½®æŒ‡æ ‡"""
        self.metrics = {
            'requests_count': 0,
            'total_processing_time': 0.0,
            'average_processing_time': 0.0,
            'memory_usage': 0.0,
            'cpu_usage': 0.0
        }

# å…¨å±€ç›‘æ§å™¨å®ä¾‹
monitor = PerformanceMonitor()
```

## é¡¹ç›®æ€»ç»“

### æ ¸å¿ƒåŠŸèƒ½

å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆå™¨é¡¹ç›®å®ç°äº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

1. **æ–‡æœ¬ç”ŸæˆæœåŠ¡**ï¼š
   - æ”¯æŒå¤šç§æ–‡æœ¬ç±»å‹ï¼ˆæ–‡ç« ã€æ•…äº‹ã€è¯—æ­Œã€å¯¹è¯ç­‰ï¼‰
   - é›†æˆOpenAI GPTå’Œæœ¬åœ°Transformersæ¨¡å‹
   - æä¾›è´¨é‡è¯„ä¼°å’Œæ”¹è¿›å»ºè®®
   - æ”¯æŒæ‰¹é‡ç”Ÿæˆå’Œå¤šè¯­è¨€

2. **å›¾åƒç”ŸæˆæœåŠ¡**ï¼š
   - æ”¯æŒå¤šç§è‰ºæœ¯é£æ ¼å’Œå°ºå¯¸
   - é›†æˆStability AIã€DALL-Eå’Œæœ¬åœ°Stable Diffusion
   - æä¾›æç¤ºè¯å¢å¼ºå’Œå›¾åƒåå¤„ç†
   - æ”¯æŒå›¾åƒåˆ°å›¾åƒè½¬æ¢

3. **éŸ³é¢‘ç”ŸæˆæœåŠ¡**ï¼š
   - æ”¯æŒå¤šç§éŸ³é¢‘ç±»å‹å’Œè¯­éŸ³é£æ ¼
   - é›†æˆElevenLabsã€Azure Speechå’Œæœ¬åœ°TTSæ¨¡å‹
   - æä¾›éŸ³é¢‘åå¤„ç†å’Œè´¨é‡ä¼˜åŒ–
   - æ”¯æŒèƒŒæ™¯éŸ³ä¹å’ŒéŸ³æ•ˆåˆæˆ

4. **è·¨æ¨¡æ€è½¬æ¢æœåŠ¡**ï¼š
   - æ–‡æœ¬â†”å›¾åƒã€æ–‡æœ¬â†”éŸ³é¢‘ã€å›¾åƒâ†”éŸ³é¢‘è½¬æ¢
   - é›†æˆBLIPã€CLIPã€Wav2Vec2ç­‰å¤šæ¨¡æ€æ¨¡å‹
   - æä¾›ç½®ä¿¡åº¦è¯„ä¼°å’Œå…ƒæ•°æ®æå–

### æŠ€æœ¯ç‰¹ç‚¹

1. **æ¨¡å—åŒ–æ¶æ„**ï¼š
   - æœåŠ¡è§£è€¦ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
   - ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹å’Œæ¥å£è®¾è®¡
   - æ”¯æŒå¤šç§AIæœåŠ¡æä¾›å•†

2. **å¼‚æ­¥å¤„ç†**ï¼š
   - åŸºäºasyncioçš„å¼‚æ­¥æ¶æ„
   - æ”¯æŒå¹¶å‘è¯·æ±‚å’Œæ‰¹é‡å¤„ç†
   - ä¼˜åŒ–çš„èµ„æºåˆ©ç”¨å’Œå“åº”æ—¶é—´

3. **è´¨é‡ä¿è¯**ï¼š
   - å†…ç½®è´¨é‡è¯„ä¼°æœºåˆ¶
   - æ™ºèƒ½å»ºè®®å’Œä¼˜åŒ–æç¤º
   - é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥

4. **ç”¨æˆ·å‹å¥½**ï¼š
   - ç›´è§‚çš„Streamlit Webç•Œé¢
   - RESTful APIè®¾è®¡
   - è¯¦ç»†çš„æ–‡æ¡£å’Œç¤ºä¾‹

### ä¸šåŠ¡ä»·å€¼

1. **å†…å®¹åˆ›ä½œæ•ˆç‡**ï¼šæ˜¾è‘—æå‡æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å†…å®¹çš„åˆ›ä½œæ•ˆç‡
2. **åˆ›æ„æ¿€å‘**ï¼šé€šè¿‡AIè¾…åŠ©æ¿€å‘åˆ›ä½œçµæ„Ÿå’Œæƒ³æ³•
3. **æˆæœ¬èŠ‚çº¦**ï¼šå‡å°‘äººå·¥åˆ›ä½œæˆæœ¬ï¼Œæé«˜å†…å®¹äº§å‡ºè´¨é‡
4. **æŠ€æœ¯æ•´åˆ**ï¼šç»Ÿä¸€å¤šæ¨¡æ€AIèƒ½åŠ›ï¼Œç®€åŒ–æŠ€æœ¯é›†æˆå¤æ‚åº¦

### Traeå®è·µè¦ç‚¹

1. **ç¯å¢ƒé…ç½®**ï¼šæ­£ç¡®é…ç½®APIå¯†é’¥å’Œä¾èµ–ç¯å¢ƒ
2. **æœåŠ¡å¯åŠ¨**ï¼šåˆç†ä½¿ç”¨ç»ˆç«¯ç®¡ç†å¤šä¸ªæœåŠ¡è¿›ç¨‹
3. **è°ƒè¯•æŠ€å·§**ï¼šåˆ©ç”¨Traeçš„è°ƒè¯•åŠŸèƒ½å¿«é€Ÿå®šä½é—®é¢˜
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šç›‘æ§èµ„æºä½¿ç”¨ï¼Œä¼˜åŒ–æ¨¡å‹åŠ è½½å’Œæ¨ç†
5. **ç”¨æˆ·ä½“éªŒ**ï¼šé€šè¿‡Streamlitæä¾›ç›´è§‚çš„äº¤äº’ç•Œé¢

é€šè¿‡è¿™ä¸ªç»¼åˆé¡¹ç›®ï¼Œå­¦ä¹ è€…å¯ä»¥æŒæ¡å¤šæ¨¡æ€AIåº”ç”¨çš„å®Œæ•´å¼€å‘æµç¨‹ï¼Œç†è§£ä¸åŒæ¨¡æ€ä¹‹é—´çš„è½¬æ¢åŸç†ï¼Œå¹¶è·å¾—å®é™…çš„é¡¹ç›®å¼€å‘ç»éªŒã€‚é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•åœ¨Trae AIç¯å¢ƒä¸­é«˜æ•ˆå¼€å‘å’Œéƒ¨ç½²å¤æ‚çš„AIåº”ç”¨ç³»ç»Ÿã€‚