# æ•°æ®å¯è§†åŒ–ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›äº†æ•™ç¨‹ä¸­å„ç§æ•°æ®å¯è§†åŒ–çš„ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µï¼Œå¸®åŠ©è¯»è€…åˆ›å»ºä¸“ä¸šçš„æ•°æ®å›¾è¡¨å’Œåˆ†ææŠ¥å‘Šã€‚

## ğŸ“Š åŸºç¡€æ•°æ®å¯è§†åŒ–

### 1. æ•°æ®åˆ†å¸ƒå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from scipy import stats

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

class DataVisualization:
    """æ•°æ®å¯è§†åŒ–å·¥å…·ç±»"""
    
    def __init__(self, figsize=(12, 8)):
        self.figsize = figsize
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    
    def plot_distribution(self, data, title="æ•°æ®åˆ†å¸ƒå›¾"):
        """ç»˜åˆ¶æ•°æ®åˆ†å¸ƒå›¾"""
        fig, axes = plt.subplots(2, 2, figsize=self.figsize)
        fig.suptitle(title, fontsize=16)
        
        # ç›´æ–¹å›¾
        axes[0, 0].hist(data, bins=30, alpha=0.7, color=self.colors[0])
        axes[0, 0].set_title('ç›´æ–¹å›¾')
        axes[0, 0].set_xlabel('æ•°å€¼')
        axes[0, 0].set_ylabel('é¢‘æ¬¡')
        
        # å¯†åº¦å›¾
        axes[0, 1].hist(data, bins=30, density=True, alpha=0.7, color=self.colors[1])
        x = np.linspace(data.min(), data.max(), 100)
        axes[0, 1].plot(x, stats.norm.pdf(x, data.mean(), data.std()), 
                       'r-', linewidth=2, label='æ­£æ€åˆ†å¸ƒæ‹Ÿåˆ')
        axes[0, 1].set_title('å¯†åº¦å›¾')
        axes[0, 1].legend()
        
        # ç®±çº¿å›¾
        axes[1, 0].boxplot(data)
        axes[1, 0].set_title('ç®±çº¿å›¾')
        axes[1, 0].set_ylabel('æ•°å€¼')
        
        # Q-Qå›¾
        stats.probplot(data, dist="norm", plot=axes[1, 1])
        axes[1, 1].set_title('Q-Qå›¾')
        
        plt.tight_layout()
        return fig
    
    def plot_correlation_matrix(self, df, title="ç›¸å…³æ€§çŸ©é˜µ"):
        """ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µçƒ­åŠ›å›¾"""
        plt.figure(figsize=self.figsize)
        correlation_matrix = df.corr()
        
        # åˆ›å»ºé®ç½©ï¼Œåªæ˜¾ç¤ºä¸‹ä¸‰è§’
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        
        sns.heatmap(correlation_matrix, mask=mask, annot=True, 
                   cmap='coolwarm', center=0, square=True,
                   linewidths=0.5, cbar_kws={"shrink": .8})
        plt.title(title)
        plt.tight_layout()
        return plt.gcf()
    
    def plot_time_series(self, dates, values, title="æ—¶é—´åºåˆ—å›¾"):
        """ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾"""
        fig, axes = plt.subplots(2, 1, figsize=self.figsize)
        
        # åŸå§‹æ—¶é—´åºåˆ—
        axes[0].plot(dates, values, color=self.colors[0], linewidth=2)
        axes[0].set_title(f'{title} - åŸå§‹æ•°æ®')
        axes[0].set_ylabel('æ•°å€¼')
        axes[0].grid(True, alpha=0.3)
        
        # ç§»åŠ¨å¹³å‡
        window = min(30, len(values) // 10)
        if window > 1:
            moving_avg = pd.Series(values).rolling(window=window).mean()
            axes[1].plot(dates, values, alpha=0.3, color=self.colors[0], label='åŸå§‹æ•°æ®')
            axes[1].plot(dates, moving_avg, color=self.colors[1], linewidth=2, 
                        label=f'{window}æœŸç§»åŠ¨å¹³å‡')
            axes[1].set_title(f'{title} - è¶‹åŠ¿åˆ†æ')
            axes[1].set_ylabel('æ•°å€¼')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    data = np.random.normal(100, 15, 1000)
    
    # åˆ›å»ºå¯è§†åŒ–å¯¹è±¡
    viz = DataVisualization()
    
    # ç»˜åˆ¶åˆ†å¸ƒå›¾
    fig1 = viz.plot_distribution(data, "æ ·æœ¬æ•°æ®åˆ†å¸ƒåˆ†æ")
    plt.show()
    
    # åˆ›å»ºç¤ºä¾‹DataFrame
    df = pd.DataFrame({
        'ç‰¹å¾1': np.random.normal(0, 1, 100),
        'ç‰¹å¾2': np.random.normal(0, 1, 100),
        'ç‰¹å¾3': np.random.normal(0, 1, 100),
        'ç‰¹å¾4': np.random.normal(0, 1, 100)
    })
    df['ç‰¹å¾5'] = df['ç‰¹å¾1'] * 0.8 + np.random.normal(0, 0.2, 100)
    
    # ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µ
    fig2 = viz.plot_correlation_matrix(df, "ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
    plt.show()
```

### 2. æœºå™¨å­¦ä¹ ç»“æœå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.model_selection import learning_curve
import numpy as np

class MLVisualization:
    """æœºå™¨å­¦ä¹ ç»“æœå¯è§†åŒ–"""
    
    def __init__(self, figsize=(12, 8)):
        self.figsize = figsize
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    
    def plot_confusion_matrix(self, y_true, y_pred, labels=None, title="æ··æ·†çŸ©é˜µ"):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=labels, yticklabels=labels)
        plt.title(title)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        
        # æ·»åŠ å‡†ç¡®ç‡ä¿¡æ¯
        accuracy = np.trace(cm) / np.sum(cm)
        plt.figtext(0.15, 0.02, f'æ€»ä½“å‡†ç¡®ç‡: {accuracy:.3f}', fontsize=12)
        
        plt.tight_layout()
        return plt.gcf()
    
    def plot_roc_curves(self, y_true_list, y_scores_list, labels, title="ROCæ›²çº¿å¯¹æ¯”"):
        """ç»˜åˆ¶å¤šä¸ªæ¨¡å‹çš„ROCæ›²çº¿"""
        plt.figure(figsize=self.figsize)
        
        for i, (y_true, y_scores, label) in enumerate(zip(y_true_list, y_scores_list, labels)):
            fpr, tpr, _ = roc_curve(y_true, y_scores)
            roc_auc = auc(fpr, tpr)
            
            plt.plot(fpr, tpr, color=self.colors[i % len(self.colors)],
                    linewidth=2, label=f'{label} (AUC = {roc_auc:.3f})')
        
        plt.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å‡æ­£ç‡ (FPR)')
        plt.ylabel('çœŸæ­£ç‡ (TPR)')
        plt.title(title)
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)
        
        return plt.gcf()
    
    def plot_learning_curves(self, estimator, X, y, title="å­¦ä¹ æ›²çº¿"):
        """ç»˜åˆ¶å­¦ä¹ æ›²çº¿"""
        train_sizes, train_scores, val_scores = learning_curve(
            estimator, X, y, cv=5, n_jobs=-1,
            train_sizes=np.linspace(0.1, 1.0, 10))
        
        train_mean = np.mean(train_scores, axis=1)
        train_std = np.std(train_scores, axis=1)
        val_mean = np.mean(val_scores, axis=1)
        val_std = np.std(val_scores, axis=1)
        
        plt.figure(figsize=self.figsize)
        
        plt.plot(train_sizes, train_mean, 'o-', color=self.colors[0],
                label='è®­ç»ƒåˆ†æ•°', linewidth=2)
        plt.fill_between(train_sizes, train_mean - train_std,
                        train_mean + train_std, alpha=0.1, color=self.colors[0])
        
        plt.plot(train_sizes, val_mean, 'o-', color=self.colors[1],
                label='éªŒè¯åˆ†æ•°', linewidth=2)
        plt.fill_between(train_sizes, val_mean - val_std,
                        val_mean + val_std, alpha=0.1, color=self.colors[1])
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ•°')
        plt.ylabel('åˆ†æ•°')
        plt.title(title)
        plt.legend(loc='best')
        plt.grid(True, alpha=0.3)
        
        return plt.gcf()
    
    def plot_feature_importance(self, feature_names, importance_scores, 
                              title="ç‰¹å¾é‡è¦æ€§", top_k=20):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        # æ’åºå¹¶é€‰æ‹©top_kä¸ªç‰¹å¾
        indices = np.argsort(importance_scores)[::-1][:top_k]
        sorted_features = [feature_names[i] for i in indices]
        sorted_scores = importance_scores[indices]
        
        plt.figure(figsize=(10, max(6, len(sorted_features) * 0.3)))
        
        # æ°´å¹³æ¡å½¢å›¾
        y_pos = np.arange(len(sorted_features))
        plt.barh(y_pos, sorted_scores, color=self.colors[0], alpha=0.7)
        
        plt.yticks(y_pos, sorted_features)
        plt.xlabel('é‡è¦æ€§åˆ†æ•°')
        plt.title(title)
        plt.gca().invert_yaxis()  # æœ€é‡è¦çš„ç‰¹å¾åœ¨é¡¶éƒ¨
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, score in enumerate(sorted_scores):
            plt.text(score + 0.01 * max(sorted_scores), i, f'{score:.3f}',
                    va='center', fontsize=9)
        
        plt.tight_layout()
        return plt.gcf()
    
    def plot_model_comparison(self, model_names, metrics_dict, title="æ¨¡å‹æ€§èƒ½å¯¹æ¯”"):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾"""
        metrics = list(metrics_dict.keys())
        n_metrics = len(metrics)
        n_models = len(model_names)
        
        fig, axes = plt.subplots(1, n_metrics, figsize=(4 * n_metrics, 6))
        if n_metrics == 1:
            axes = [axes]
        
        for i, metric in enumerate(metrics):
            values = metrics_dict[metric]
            x_pos = np.arange(n_models)
            
            bars = axes[i].bar(x_pos, values, color=self.colors[:n_models], alpha=0.7)
            axes[i].set_xlabel('æ¨¡å‹')
            axes[i].set_ylabel(metric)
            axes[i].set_title(f'{metric}å¯¹æ¯”')
            axes[i].set_xticks(x_pos)
            axes[i].set_xticklabels(model_names, rotation=45)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{value:.3f}', ha='center', va='bottom')
        
        plt.suptitle(title, fontsize=16)
        plt.tight_layout()
        return fig

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.linear_model import LogisticRegression
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    X, y = make_classification(n_samples=1000, n_features=20, n_informative=10,
                             n_redundant=10, n_clusters_per_class=1, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # è®­ç»ƒæ¨¡å‹
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    lr = LogisticRegression(random_state=42)
    
    rf.fit(X_train, y_train)
    lr.fit(X_train, y_train)
    
    # é¢„æµ‹
    rf_pred = rf.predict(X_test)
    lr_pred = lr.predict(X_test)
    rf_proba = rf.predict_proba(X_test)[:, 1]
    lr_proba = lr.predict_proba(X_test)[:, 1]
    
    # åˆ›å»ºå¯è§†åŒ–å¯¹è±¡
    ml_viz = MLVisualization()
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    fig1 = ml_viz.plot_confusion_matrix(y_test, rf_pred, 
                                       labels=['ç±»åˆ«0', 'ç±»åˆ«1'], 
                                       title="éšæœºæ£®æ—æ··æ·†çŸ©é˜µ")
    plt.show()
    
    # ç»˜åˆ¶ROCæ›²çº¿å¯¹æ¯”
    fig2 = ml_viz.plot_roc_curves([y_test, y_test], [rf_proba, lr_proba],
                                 ['éšæœºæ£®æ—', 'é€»è¾‘å›å½’'], "æ¨¡å‹ROCæ›²çº¿å¯¹æ¯”")
    plt.show()
    
    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
    feature_names = [f'ç‰¹å¾_{i}' for i in range(X.shape[1])]
    fig3 = ml_viz.plot_feature_importance(feature_names, rf.feature_importances_,
                                         "éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§")
    plt.show()
```

### 3. æ·±åº¦å­¦ä¹ è®­ç»ƒå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict

class DeepLearningVisualization:
    """æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–"""
    
    def __init__(self, figsize=(12, 8)):
        self.figsize = figsize
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        self.training_history = defaultdict(list)
    
    def log_metrics(self, epoch, **metrics):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        self.training_history['epoch'].append(epoch)
        for key, value in metrics.items():
            self.training_history[key].append(value)
    
    def plot_training_history(self, title="è®­ç»ƒå†å²"):
        """ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿"""
        if not self.training_history:
            print("æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®")
            return None
        
        epochs = self.training_history['epoch']
        metrics = {k: v for k, v in self.training_history.items() if k != 'epoch'}
        
        # åˆ†ç¦»è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡
        train_metrics = {k: v for k, v in metrics.items() if not k.startswith('val_')}
        val_metrics = {k.replace('val_', ''): v for k, v in metrics.items() if k.startswith('val_')}
        
        n_metrics = len(train_metrics)
        fig, axes = plt.subplots(1, n_metrics, figsize=(4 * n_metrics, 6))
        if n_metrics == 1:
            axes = [axes]
        
        for i, (metric_name, train_values) in enumerate(train_metrics.items()):
            axes[i].plot(epochs, train_values, 'o-', color=self.colors[0],
                        label=f'è®­ç»ƒ{metric_name}', linewidth=2)
            
            if metric_name in val_metrics:
                val_values = val_metrics[metric_name]
                axes[i].plot(epochs, val_values, 'o-', color=self.colors[1],
                           label=f'éªŒè¯{metric_name}', linewidth=2)
            
            axes[i].set_xlabel('Epoch')
            axes[i].set_ylabel(metric_name)
            axes[i].set_title(f'{metric_name}å˜åŒ–æ›²çº¿')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        
        plt.suptitle(title, fontsize=16)
        plt.tight_layout()
        return fig
    
    def plot_loss_landscape(self, loss_surface, title="æŸå¤±å‡½æ•°åœ°å½¢å›¾"):
        """ç»˜åˆ¶æŸå¤±å‡½æ•°åœ°å½¢å›¾"""
        fig = plt.figure(figsize=self.figsize)
        ax = fig.add_subplot(111, projection='3d')
        
        x = np.linspace(-2, 2, loss_surface.shape[0])
        y = np.linspace(-2, 2, loss_surface.shape[1])
        X, Y = np.meshgrid(x, y)
        
        surf = ax.plot_surface(X, Y, loss_surface, cmap='viridis', alpha=0.8)
        ax.set_xlabel('å‚æ•°1')
        ax.set_ylabel('å‚æ•°2')
        ax.set_zlabel('æŸå¤±å€¼')
        ax.set_title(title)
        
        fig.colorbar(surf, shrink=0.5, aspect=5)
        return fig
    
    def plot_gradient_flow(self, named_parameters, title="æ¢¯åº¦æµåŠ¨å›¾"):
        """ç»˜åˆ¶æ¢¯åº¦æµåŠ¨å›¾"""
        ave_grads = []
        max_grads = []
        layers = []
        
        for name, param in named_parameters:
            if param.grad is not None and "bias" not in name:
                layers.append(name.replace('.weight', ''))
                ave_grads.append(param.grad.abs().mean().cpu().item())
                max_grads.append(param.grad.abs().max().cpu().item())
        
        plt.figure(figsize=self.figsize)
        plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.5, 
                color=self.colors[0], label="æœ€å¤§æ¢¯åº¦")
        plt.bar(np.arange(len(ave_grads)), ave_grads, alpha=0.5,
                color=self.colors[1], label="å¹³å‡æ¢¯åº¦")
        
        plt.hlines(0, 0, len(ave_grads) + 1, linewidth=1, color="k")
        plt.xticks(range(0, len(ave_grads), 1), layers, rotation="vertical")
        plt.xlim(left=0, right=len(ave_grads))
        plt.ylim(bottom=-0.001, top=max(max_grads) * 1.1)
        plt.xlabel("å±‚")
        plt.ylabel("æ¢¯åº¦å€¼")
        plt.title(title)
        plt.legend()
        plt.tight_layout()
        
        return plt.gcf()
    
    def plot_attention_weights(self, attention_weights, input_tokens, output_tokens,
                             title="æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–"):
        """ç»˜åˆ¶æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾"""
        plt.figure(figsize=(max(8, len(input_tokens) * 0.5), 
                           max(6, len(output_tokens) * 0.5)))
        
        sns.heatmap(attention_weights, 
                   xticklabels=input_tokens,
                   yticklabels=output_tokens,
                   cmap='Blues', annot=True, fmt='.2f')
        
        plt.xlabel('è¾“å…¥è¯æ±‡')
        plt.ylabel('è¾“å‡ºè¯æ±‡')
        plt.title(title)
        plt.tight_layout()
        
        return plt.gcf()
    
    def plot_model_architecture(self, layer_info, title="æ¨¡å‹æ¶æ„å›¾"):
        """ç»˜åˆ¶æ¨¡å‹æ¶æ„å›¾"""
        fig, ax = plt.subplots(figsize=(12, max(8, len(layer_info) * 0.8)))
        
        y_positions = np.arange(len(layer_info))
        layer_names = [info['name'] for info in layer_info]
        layer_params = [info['params'] for info in layer_info]
        
        # ç»˜åˆ¶å±‚çº§ç»“æ„
        for i, (y_pos, name, params) in enumerate(zip(y_positions, layer_names, layer_params)):
            # ç»˜åˆ¶çŸ©å½¢è¡¨ç¤ºå±‚
            rect_width = np.log10(params + 1) * 0.5  # æ ¹æ®å‚æ•°æ•°é‡è°ƒæ•´å®½åº¦
            rect = plt.Rectangle((0, y_pos - 0.3), rect_width, 0.6, 
                               facecolor=self.colors[i % len(self.colors)], 
                               alpha=0.7, edgecolor='black')
            ax.add_patch(rect)
            
            # æ·»åŠ å±‚åç§°å’Œå‚æ•°æ•°é‡
            ax.text(rect_width + 0.1, y_pos, f'{name}\n({params:,} å‚æ•°)', 
                   va='center', fontsize=10)
            
            # ç»˜åˆ¶è¿æ¥çº¿
            if i < len(layer_info) - 1:
                ax.arrow(rect_width/2, y_pos + 0.3, 0, 0.4, 
                        head_width=0.1, head_length=0.1, fc='black', ec='black')
        
        ax.set_xlim(-0.5, max([np.log10(info['params'] + 1) * 0.5 for info in layer_info]) + 3)
        ax.set_ylim(-0.5, len(layer_info) - 0.5)
        ax.set_yticks([])
        ax.set_xticks([])
        ax.set_title(title, fontsize=16)
        
        # æ·»åŠ æ€»å‚æ•°æ•°é‡
        total_params = sum(info['params'] for info in layer_info)
        ax.text(0.02, 0.98, f'æ€»å‚æ•°æ•°é‡: {total_params:,}', 
               transform=ax.transAxes, va='top', fontsize=12,
               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        return fig

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # åˆ›å»ºæ·±åº¦å­¦ä¹ å¯è§†åŒ–å¯¹è±¡
    dl_viz = DeepLearningVisualization()
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 51):
        # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
        train_loss = 2.0 * np.exp(-epoch * 0.1) + 0.1 * np.random.random()
        val_loss = 2.2 * np.exp(-epoch * 0.08) + 0.15 * np.random.random()
        train_acc = 1 - np.exp(-epoch * 0.15) + 0.05 * np.random.random()
        val_acc = 1 - np.exp(-epoch * 0.12) + 0.08 * np.random.random()
        
        dl_viz.log_metrics(epoch, 
                          loss=train_loss, 
                          accuracy=train_acc,
                          val_loss=val_loss, 
                          val_accuracy=val_acc)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    fig1 = dl_viz.plot_training_history("æ¨¡å‹è®­ç»ƒè¿‡ç¨‹")
    plt.show()
    
    # ç”Ÿæˆç¤ºä¾‹æŸå¤±åœ°å½¢å›¾
    x = np.linspace(-2, 2, 50)
    y = np.linspace(-2, 2, 50)
    X, Y = np.meshgrid(x, y)
    Z = (X**2 + Y**2) * np.exp(-(X**2 + Y**2)/2) + 0.1 * np.random.random((50, 50))
    
    fig2 = dl_viz.plot_loss_landscape(Z, "æŸå¤±å‡½æ•°åœ°å½¢å›¾")
    plt.show()
    
    # ç¤ºä¾‹æ¨¡å‹æ¶æ„
    layer_info = [
        {'name': 'è¾“å…¥å±‚', 'params': 0},
        {'name': 'åµŒå…¥å±‚', 'params': 50000},
        {'name': 'LSTMå±‚1', 'params': 200000},
        {'name': 'LSTMå±‚2', 'params': 150000},
        {'name': 'å…¨è¿æ¥å±‚', 'params': 10000},
        {'name': 'è¾“å‡ºå±‚', 'params': 1000}
    ]
    
    fig3 = dl_viz.plot_model_architecture(layer_info, "LSTMæ¨¡å‹æ¶æ„")
    plt.show()
    
    # ç¤ºä¾‹æ³¨æ„åŠ›æƒé‡
    input_tokens = ['æˆ‘', 'å–œæ¬¢', 'æœºå™¨', 'å­¦ä¹ ']
    output_tokens = ['I', 'like', 'machine', 'learning']
    attention_weights = np.random.random((4, 4))
    attention_weights = attention_weights / attention_weights.sum(axis=1, keepdims=True)
    
    fig4 = dl_viz.plot_attention_weights(attention_weights, input_tokens, output_tokens,
                                        "ä¸­è‹±ç¿»è¯‘æ³¨æ„åŠ›æƒé‡")
    plt.show()
```

### 4. ä¸šåŠ¡æŒ‡æ ‡å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

class BusinessMetricsVisualization:
    """ä¸šåŠ¡æŒ‡æ ‡å¯è§†åŒ–"""
    
    def __init__(self, figsize=(12, 8)):
        self.figsize = figsize
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    
    def plot_kpi_dashboard(self, metrics_data, title="KPIä»ªè¡¨æ¿"):
        """ç»˜åˆ¶KPIä»ªè¡¨æ¿"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(title, fontsize=16)
        
        # ç”¨æˆ·å¢é•¿è¶‹åŠ¿
        axes[0, 0].plot(metrics_data['dates'], metrics_data['daily_users'], 
                       color=self.colors[0], linewidth=2)
        axes[0, 0].set_title('æ—¥æ´»ç”¨æˆ·æ•°')
        axes[0, 0].set_ylabel('ç”¨æˆ·æ•°')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ”¶å…¥è¶‹åŠ¿
        axes[0, 1].bar(range(len(metrics_data['monthly_revenue'])), 
                      metrics_data['monthly_revenue'], 
                      color=self.colors[1], alpha=0.7)
        axes[0, 1].set_title('æœˆåº¦æ”¶å…¥')
        axes[0, 1].set_ylabel('æ”¶å…¥ (ä¸‡å…ƒ)')
        axes[0, 1].set_xticks(range(len(metrics_data['monthly_revenue'])))
        axes[0, 1].set_xticklabels([f'{i+1}æœˆ' for i in range(len(metrics_data['monthly_revenue']))])
        
        # è½¬åŒ–æ¼æ–—
        funnel_data = metrics_data['conversion_funnel']
        funnel_labels = list(funnel_data.keys())
        funnel_values = list(funnel_data.values())
        
        y_pos = np.arange(len(funnel_labels))
        axes[0, 2].barh(y_pos, funnel_values, color=self.colors[2], alpha=0.7)
        axes[0, 2].set_yticks(y_pos)
        axes[0, 2].set_yticklabels(funnel_labels)
        axes[0, 2].set_title('è½¬åŒ–æ¼æ–—')
        axes[0, 2].set_xlabel('ç”¨æˆ·æ•°')
        
        # ç”¨æˆ·ç•™å­˜ç‡
        retention_data = metrics_data['retention_rates']
        days = list(retention_data.keys())
        rates = list(retention_data.values())
        
        axes[1, 0].plot(days, rates, 'o-', color=self.colors[3], linewidth=2)
        axes[1, 0].set_title('ç”¨æˆ·ç•™å­˜ç‡')
        axes[1, 0].set_xlabel('å¤©æ•°')
        axes[1, 0].set_ylabel('ç•™å­˜ç‡ (%)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # ç”¨æˆ·è¡Œä¸ºåˆ†å¸ƒ
        behavior_data = metrics_data['user_behavior']
        axes[1, 1].pie(behavior_data.values(), labels=behavior_data.keys(), 
                      autopct='%1.1f%%', colors=self.colors[:len(behavior_data)])
        axes[1, 1].set_title('ç”¨æˆ·è¡Œä¸ºåˆ†å¸ƒ')
        
        # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        model_metrics = metrics_data['model_performance']
        metric_names = list(model_metrics.keys())
        metric_values = list(model_metrics.values())
        
        bars = axes[1, 2].bar(metric_names, metric_values, 
                             color=self.colors[4], alpha=0.7)
        axes[1, 2].set_title('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡')
        axes[1, 2].set_ylabel('åˆ†æ•°')
        axes[1, 2].set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, metric_values):
            axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{value:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        return fig
    
    def plot_ab_test_results(self, control_data, treatment_data, metric_name, 
                           title="A/Bæµ‹è¯•ç»“æœ"):
        """ç»˜åˆ¶A/Bæµ‹è¯•ç»“æœ"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åˆ†å¸ƒå¯¹æ¯”
        axes[0].hist(control_data, bins=30, alpha=0.7, 
                    color=self.colors[0], label='å¯¹ç…§ç»„')
        axes[0].hist(treatment_data, bins=30, alpha=0.7, 
                    color=self.colors[1], label='å®éªŒç»„')
        axes[0].set_xlabel(metric_name)
        axes[0].set_ylabel('é¢‘æ¬¡')
        axes[0].set_title('åˆ†å¸ƒå¯¹æ¯”')
        axes[0].legend()
        
        # ç®±çº¿å›¾å¯¹æ¯”
        axes[1].boxplot([control_data, treatment_data], 
                       labels=['å¯¹ç…§ç»„', 'å®éªŒç»„'])
        axes[1].set_ylabel(metric_name)
        axes[1].set_title('ç®±çº¿å›¾å¯¹æ¯”')
        
        # ç»Ÿè®¡æ‘˜è¦
        control_mean = np.mean(control_data)
        treatment_mean = np.mean(treatment_data)
        improvement = (treatment_mean - control_mean) / control_mean * 100
        
        summary_text = f"""
        å¯¹ç…§ç»„å‡å€¼: {control_mean:.3f}
        å®éªŒç»„å‡å€¼: {treatment_mean:.3f}
        æå‡å¹…åº¦: {improvement:.2f}%
        
        å¯¹ç…§ç»„æ ‡å‡†å·®: {np.std(control_data):.3f}
        å®éªŒç»„æ ‡å‡†å·®: {np.std(treatment_data):.3f}
        """
        
        axes[2].text(0.1, 0.5, summary_text, transform=axes[2].transAxes,
                    fontsize=12, verticalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        axes[2].set_xlim(0, 1)
        axes[2].set_ylim(0, 1)
        axes[2].axis('off')
        axes[2].set_title('ç»Ÿè®¡æ‘˜è¦')
        
        plt.suptitle(title, fontsize=16)
        plt.tight_layout()
        return fig
    
    def plot_cohort_analysis(self, cohort_data, title="é˜Ÿåˆ—åˆ†æ"):
        """ç»˜åˆ¶é˜Ÿåˆ—åˆ†æçƒ­åŠ›å›¾"""
        plt.figure(figsize=self.figsize)
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(cohort_data, annot=True, fmt='.1%', cmap='YlOrRd',
                   cbar_kws={'label': 'ç•™å­˜ç‡'})
        
        plt.title(title)
        plt.xlabel('å‘¨æœŸ')
        plt.ylabel('é˜Ÿåˆ—')
        plt.tight_layout()
        
        return plt.gcf()
    
    def plot_feature_impact(self, feature_names, impact_scores, 
                          confidence_intervals, title="ç‰¹å¾å½±å“åˆ†æ"):
        """ç»˜åˆ¶ç‰¹å¾å½±å“åˆ†æå›¾"""
        plt.figure(figsize=(10, max(6, len(feature_names) * 0.4)))
        
        y_pos = np.arange(len(feature_names))
        
        # ç»˜åˆ¶å½±å“åˆ†æ•°
        plt.barh(y_pos, impact_scores, color=self.colors[0], alpha=0.7)
        
        # æ·»åŠ ç½®ä¿¡åŒºé—´
        plt.errorbar(impact_scores, y_pos, 
                    xerr=[confidence_intervals[:, 0], confidence_intervals[:, 1]],
                    fmt='none', color='black', capsize=3)
        
        plt.yticks(y_pos, feature_names)
        plt.xlabel('å½±å“åˆ†æ•°')
        plt.title(title)
        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, score in enumerate(impact_scores):
            plt.text(score + 0.01 * max(abs(impact_scores)), i, f'{score:.3f}',
                    va='center', fontsize=9)
        
        plt.tight_layout()
        return plt.gcf()

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹ä¸šåŠ¡æ•°æ®
    dates = pd.date_range('2024-01-01', periods=30, freq='D')
    
    metrics_data = {
        'dates': dates,
        'daily_users': np.random.poisson(10000, 30) + np.arange(30) * 100,
        'monthly_revenue': [120, 135, 142, 158, 167, 180, 195, 210, 225, 240, 255, 270],
        'conversion_funnel': {
            'è®¿é—®': 10000,
            'æ³¨å†Œ': 3000,
            'æ¿€æ´»': 2000,
            'ä»˜è´¹': 500,
            'ç•™å­˜': 300
        },
        'retention_rates': {1: 85, 7: 65, 14: 45, 30: 25, 60: 15, 90: 10},
        'user_behavior': {
            'æµè§ˆ': 40,
            'æœç´¢': 25,
            'è´­ä¹°': 20,
            'åˆ†äº«': 10,
            'å…¶ä»–': 5
        },
        'model_performance': {
            'å‡†ç¡®ç‡': 0.85,
            'ç²¾ç¡®ç‡': 0.82,
            'å¬å›ç‡': 0.78,
            'F1åˆ†æ•°': 0.80,
            'AUC': 0.88
        }
    }
    
    # åˆ›å»ºä¸šåŠ¡æŒ‡æ ‡å¯è§†åŒ–å¯¹è±¡
    biz_viz = BusinessMetricsVisualization()
    
    # ç»˜åˆ¶KPIä»ªè¡¨æ¿
    fig1 = biz_viz.plot_kpi_dashboard(metrics_data, "ä¸šåŠ¡KPIä»ªè¡¨æ¿")
    plt.show()
    
    # ç”ŸæˆA/Bæµ‹è¯•æ•°æ®
    np.random.seed(42)
    control_data = np.random.normal(0.15, 0.05, 1000)  # å¯¹ç…§ç»„è½¬åŒ–ç‡
    treatment_data = np.random.normal(0.18, 0.05, 1000)  # å®éªŒç»„è½¬åŒ–ç‡
    
    fig2 = biz_viz.plot_ab_test_results(control_data, treatment_data, 
                                       "è½¬åŒ–ç‡", "è½¬åŒ–ç‡A/Bæµ‹è¯•")
    plt.show()
    
    # ç”Ÿæˆé˜Ÿåˆ—åˆ†ææ•°æ®
    cohort_data = pd.DataFrame({
        'ç¬¬1å‘¨': [100, 85, 70, 60, 50],
        'ç¬¬2å‘¨': [80, 68, 55, 45, 38],
        'ç¬¬3å‘¨': [65, 52, 42, 35, 28],
        'ç¬¬4å‘¨': [50, 40, 32, 26, 20]
    }, index=['1æœˆé˜Ÿåˆ—', '2æœˆé˜Ÿåˆ—', '3æœˆé˜Ÿåˆ—', '4æœˆé˜Ÿåˆ—', '5æœˆé˜Ÿåˆ—'])
    cohort_data = cohort_data / 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    
    fig3 = biz_viz.plot_cohort_analysis(cohort_data, "ç”¨æˆ·ç•™å­˜é˜Ÿåˆ—åˆ†æ")
    plt.show()
```

## ğŸ“ˆ äº¤äº’å¼å¯è§†åŒ–

### ä½¿ç”¨Plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨

```python
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np

class InteractiveVisualization:
    """äº¤äº’å¼å¯è§†åŒ–å·¥å…·"""
    
    def __init__(self):
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    
    def create_interactive_dashboard(self, data):
        """åˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿"""
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('æ—¶é—´åºåˆ—', 'åˆ†å¸ƒå›¾', 'æ•£ç‚¹å›¾', 'çƒ­åŠ›å›¾'),
            specs=[[{"secondary_y": True}, {}],
                   [{}, {"type": "heatmap"}]]
        )
        
        # æ—¶é—´åºåˆ—å›¾
        fig.add_trace(
            go.Scatter(x=data['dates'], y=data['values1'], 
                      name='æŒ‡æ ‡1', line=dict(color=self.colors[0])),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Scatter(x=data['dates'], y=data['values2'], 
                      name='æŒ‡æ ‡2', line=dict(color=self.colors[1]),
                      yaxis='y2'),
            row=1, col=1, secondary_y=True
        )
        
        # åˆ†å¸ƒå›¾
        fig.add_trace(
            go.Histogram(x=data['distribution'], name='åˆ†å¸ƒ',
                        marker_color=self.colors[2], opacity=0.7),
            row=1, col=2
        )
        
        # æ•£ç‚¹å›¾
        fig.add_trace(
            go.Scatter(x=data['x_scatter'], y=data['y_scatter'],
                      mode='markers', name='æ•£ç‚¹',
                      marker=dict(color=data['colors'], 
                                 colorscale='Viridis',
                                 showscale=True)),
            row=2, col=1
        )
        
        # çƒ­åŠ›å›¾
        fig.add_trace(
            go.Heatmap(z=data['heatmap_data'], 
                      colorscale='RdYlBu_r',
                      showscale=False),
            row=2, col=2
        )
        
        fig.update_layout(
            title_text="äº¤äº’å¼æ•°æ®åˆ†æä»ªè¡¨æ¿",
            showlegend=True,
            height=600
        )
        
        return fig
    
    def create_3d_scatter(self, x, y, z, color, title="3Dæ•£ç‚¹å›¾"):
        """åˆ›å»º3Dæ•£ç‚¹å›¾"""
        fig = go.Figure(data=[go.Scatter3d(
            x=x, y=y, z=z,
            mode='markers',
            marker=dict(
                size=5,
                color=color,
                colorscale='Viridis',
                opacity=0.8,
                showscale=True
            )
        )])
        
        fig.update_layout(
            title=title,
            scene=dict(
                xaxis_title='Xè½´',
                yaxis_title='Yè½´',
                zaxis_title='Zè½´'
            )
        )
        
        return fig
    
    def create_animated_plot(self, df, x_col, y_col, time_col, 
                           color_col=None, title="åŠ¨ç”»å›¾è¡¨"):
        """åˆ›å»ºåŠ¨ç”»å›¾è¡¨"""
        fig = px.scatter(df, x=x_col, y=y_col, 
                        animation_frame=time_col,
                        color=color_col,
                        title=title,
                        range_x=[df[x_col].min()*0.9, df[x_col].max()*1.1],
                        range_y=[df[y_col].min()*0.9, df[y_col].max()*1.1])
        
        fig.update_layout(
            xaxis_title=x_col,
            yaxis_title=y_col
        )
        
        return fig

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    dates = pd.date_range('2024-01-01', periods=100, freq='D')
    
    dashboard_data = {
        'dates': dates,
        'values1': np.cumsum(np.random.randn(100)) + 100,
        'values2': np.cumsum(np.random.randn(100)) * 0.1 + 10,
        'distribution': np.random.normal(0, 1, 1000),
        'x_scatter': np.random.randn(200),
        'y_scatter': np.random.randn(200),
        'colors': np.random.randn(200),
        'heatmap_data': np.random.randn(10, 10)
    }
    
    # åˆ›å»ºäº¤äº’å¼å¯è§†åŒ–å¯¹è±¡
    interactive_viz = InteractiveVisualization()
    
    # åˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿
    dashboard_fig = interactive_viz.create_interactive_dashboard(dashboard_data)
    dashboard_fig.show()
    
    # åˆ›å»º3Dæ•£ç‚¹å›¾
    x = np.random.randn(500)
    y = np.random.randn(500)
    z = np.random.randn(500)
    color = x + y + z
    
    scatter_3d_fig = interactive_viz.create_3d_scatter(x, y, z, color, "3Dæ•°æ®åˆ†å¸ƒ")
    scatter_3d_fig.show()
```

## ğŸ“‹ å¯è§†åŒ–æœ€ä½³å®è·µ

### 1. é¢œè‰²é€‰æ‹©æŒ‡å—

- **å®šæ€§æ•°æ®**: ä½¿ç”¨ä¸åŒè‰²ç›¸çš„é¢œè‰²
- **å®šé‡æ•°æ®**: ä½¿ç”¨å•ä¸€è‰²ç›¸çš„æ¸å˜
- **å¯¹æ¯”æ•°æ®**: ä½¿ç”¨äº’è¡¥è‰²
- **æ—¶é—´åºåˆ—**: ä½¿ç”¨è¿ç»­çš„é¢œè‰²æ˜ å°„

### 2. å›¾è¡¨ç±»å‹é€‰æ‹©

- **åˆ†å¸ƒ**: ç›´æ–¹å›¾ã€å¯†åº¦å›¾ã€ç®±çº¿å›¾
- **å…³ç³»**: æ•£ç‚¹å›¾ã€ç›¸å…³æ€§çŸ©é˜µ
- **æ¯”è¾ƒ**: æ¡å½¢å›¾ã€é›·è¾¾å›¾
- **è¶‹åŠ¿**: æŠ˜çº¿å›¾ã€é¢ç§¯å›¾
- **ç»„æˆ**: é¥¼å›¾ã€å †å å›¾

### 3. äº¤äº’è®¾è®¡åŸåˆ™

- **æ¸è¿›å¼æŠ«éœ²**: ä»æ¦‚è§ˆåˆ°ç»†èŠ‚
- **ç›´æ¥æ“ä½œ**: ç‚¹å‡»ã€æ‹–æ‹½ã€ç¼©æ”¾
- **å³æ—¶åé¦ˆ**: å®æ—¶æ›´æ–°å’Œå“åº”
- **ä¸Šä¸‹æ–‡ä¿æŒ**: ä¿æŒç”¨æˆ·çš„æ“ä½œçŠ¶æ€

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **æ•°æ®é‡‡æ ·**: å¤§æ•°æ®é›†ä½¿ç”¨é‡‡æ ·æ˜¾ç¤º
- **å»¶è¿ŸåŠ è½½**: æŒ‰éœ€åŠ è½½è¯¦ç»†æ•°æ®
- **ç¼“å­˜ç­–ç•¥**: ç¼“å­˜è®¡ç®—ç»“æœ
- **æ¸²æŸ“ä¼˜åŒ–**: ä½¿ç”¨Canvasæˆ–WebGL

è¿™äº›å¯è§†åŒ–ç¤ºä¾‹å’Œæœ€ä½³å®è·µä¸ºæ•™ç¨‹æä¾›äº†å…¨é¢çš„æ•°æ®å±•ç¤ºè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©è¯»è€…åˆ›å»ºä¸“ä¸šã€ç¾è§‚ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„æ•°æ®å›¾è¡¨ã€‚