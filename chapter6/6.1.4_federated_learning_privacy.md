# 6.1.4 联邦学习与隐私保护

在数据隐私日益重要的今天，联邦学习作为一种分布式机器学习范式，允许多个参与方在不共享原始数据的情况下协作训练模型。本节将深入探讨联邦学习的核心技术和隐私保护机制。

## 📚 技术概述

联邦学习（Federated Learning）是一种机器学习设置，其中多个参与者（如移动设备、医院、银行）在本地数据上训练模型，只共享模型参数而不共享原始数据。

### 核心特点
- **数据本地化**：数据始终保留在本地设备上
- **模型聚合**：只传输和聚合模型参数
- **隐私保护**：原始数据不离开本地环境
- **分布式训练**：支持大规模分布式学习

## 🏗️ 联邦学习架构

### 1. 基础联邦学习框架

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from typing import List, Dict, Tuple, Optional
import copy
import random
from collections import OrderedDict
import matplotlib.pyplot as plt

class FederatedClient:
    """联邦学习客户端"""
    
    def __init__(self, client_id: str, model: nn.Module, train_data: DataLoader, 
                 learning_rate: float = 0.01, device: str = 'cpu'):
        self.client_id = client_id
        self.model = model.to(device)
        self.train_data = train_data
        self.device = device
        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        
        # 训练统计
        self.training_history = []
        self.data_size = len(train_data.dataset)
        
    def local_train(self, epochs: int = 1) -> Dict[str, float]:
        """本地训练"""
        print(f"🔄 客户端 {self.client_id} 开始本地训练 ({epochs} epochs)")
        
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for epoch in range(epochs):
            epoch_loss = 0
            epoch_correct = 0
            epoch_total = 0
            
            for batch_idx, (data, target) in enumerate(self.train_data):
                data, target = data.to(self.device), target.to(self.device)
                
                self.optimizer.zero_grad()
                output = self.model(data)
                loss = self.criterion(output, target)
                loss.backward()
                self.optimizer.step()
                
                epoch_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                epoch_correct += pred.eq(target.view_as(pred)).sum().item()
                epoch_total += target.size(0)
            
            total_loss += epoch_loss
            correct += epoch_correct
            total += epoch_total
        
        avg_loss = total_loss / (len(self.train_data) * epochs)
        accuracy = 100. * correct / total
        
        training_stats = {
            'loss': avg_loss,
            'accuracy': accuracy,
            'data_size': self.data_size
        }
        
        self.training_history.append(training_stats)
        
        print(f"   客户端 {self.client_id} 训练完成: Loss={avg_loss:.4f}, Acc={accuracy:.2f}%")
        
        return training_stats
    
    def get_model_parameters(self) -> OrderedDict:
        """获取模型参数"""
        return copy.deepcopy(self.model.state_dict())
    
    def set_model_parameters(self, parameters: OrderedDict):
        """设置模型参数"""
        self.model.load_state_dict(parameters)
    
    def evaluate(self, test_data: DataLoader) -> Dict[str, float]:
        """评估模型"""
        self.model.eval()
        test_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_data:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                test_loss += self.criterion(output, target).item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        avg_loss = test_loss / len(test_data)
        accuracy = 100. * correct / total
        
        return {'loss': avg_loss, 'accuracy': accuracy}

class FederatedServer:
    """联邦学习服务器"""
    
    def __init__(self, global_model: nn.Module, device: str = 'cpu'):
        self.global_model = global_model.to(device)
        self.device = device
        self.clients = {}
        self.round_history = []
        
    def register_client(self, client: FederatedClient):
        """注册客户端"""
        self.clients[client.client_id] = client
        print(f"📱 客户端 {client.client_id} 已注册 (数据量: {client.data_size})")
    
    def select_clients(self, fraction: float = 1.0, min_clients: int = 1) -> List[str]:
        """选择参与训练的客户端"""
        available_clients = list(self.clients.keys())
        num_clients = max(min_clients, int(len(available_clients) * fraction))
        selected_clients = random.sample(available_clients, num_clients)
        
        print(f"🎯 选择 {len(selected_clients)}/{len(available_clients)} 个客户端参与训练")
        return selected_clients
    
    def federated_averaging(self, client_parameters: List[Tuple[str, OrderedDict]]) -> OrderedDict:
        """联邦平均算法 (FedAvg)"""
        print("🔄 执行联邦平均聚合...")
        
        # 计算权重（基于数据量）
        total_data_size = sum(self.clients[client_id].data_size 
                             for client_id, _ in client_parameters)
        
        # 初始化聚合参数
        aggregated_params = OrderedDict()
        
        # 获取参数结构
        first_params = client_parameters[0][1]
        for key in first_params.keys():
            aggregated_params[key] = torch.zeros_like(first_params[key])
        
        # 加权平均
        for client_id, params in client_parameters:
            client_weight = self.clients[client_id].data_size / total_data_size
            
            for key in params.keys():
                aggregated_params[key] += client_weight * params[key]
        
        print(f"   聚合完成，参与客户端: {[client_id for client_id, _ in client_parameters]}")
        
        return aggregated_params
    
    def federated_round(self, selected_clients: List[str], local_epochs: int = 1) -> Dict[str, any]:
        """执行一轮联邦学习"""
        print(f"\n🚀 开始联邦学习轮次")
        
        # 1. 分发全局模型
        global_params = self.global_model.state_dict()
        for client_id in selected_clients:
            self.clients[client_id].set_model_parameters(global_params)
        
        # 2. 本地训练
        client_parameters = []
        client_stats = {}
        
        for client_id in selected_clients:
            client = self.clients[client_id]
            training_stats = client.local_train(epochs=local_epochs)
            client_parameters.append((client_id, client.get_model_parameters()))
            client_stats[client_id] = training_stats
        
        # 3. 聚合模型
        aggregated_params = self.federated_averaging(client_parameters)
        self.global_model.load_state_dict(aggregated_params)
        
        # 4. 统计信息
        round_stats = {
            'participating_clients': selected_clients,
            'client_stats': client_stats,
            'total_data_size': sum(self.clients[client_id].data_size for client_id in selected_clients)
        }
        
        self.round_history.append(round_stats)
        
        return round_stats
    
    def evaluate_global_model(self, test_data: DataLoader) -> Dict[str, float]:
        """评估全局模型"""
        self.global_model.eval()
        test_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_data:
                data, target = data.to(self.device), target.to(self.device)
                output = self.global_model(data)
                test_loss += nn.CrossEntropyLoss()(output, target).item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        avg_loss = test_loss / len(test_data)
        accuracy = 100. * correct / total
        
        return {'loss': avg_loss, 'accuracy': accuracy}
    
    def run_federated_learning(self, num_rounds: int, client_fraction: float = 1.0, 
                             local_epochs: int = 1, test_data: Optional[DataLoader] = None) -> List[Dict[str, any]]:
        """运行联邦学习"""
        print(f"🎯 开始联邦学习训练")
        print(f"   轮次数: {num_rounds}")
        print(f"   客户端参与比例: {client_fraction:.1%}")
        print(f"   本地训练轮数: {local_epochs}")
        print("=" * 60)
        
        training_history = []
        
        for round_num in range(num_rounds):
            print(f"\n📍 联邦学习轮次 {round_num + 1}/{num_rounds}")
            
            # 选择客户端
            selected_clients = self.select_clients(fraction=client_fraction)
            
            # 执行联邦轮次
            round_stats = self.federated_round(selected_clients, local_epochs)
            
            # 评估全局模型
            if test_data is not None:
                global_performance = self.evaluate_global_model(test_data)
                round_stats['global_performance'] = global_performance
                
                print(f"   全局模型性能: Loss={global_performance['loss']:.4f}, "
                      f"Acc={global_performance['accuracy']:.2f}%")
            
            training_history.append(round_stats)
        
        print(f"\n🎉 联邦学习训练完成！")
        return training_history
```

### 2. 差分隐私保护

差分隐私是一种数学框架，用于量化和限制数据分析对个人隐私的影响。

```python
import torch
import numpy as np
from typing import Union, Tuple

class DifferentialPrivacyMechanism:
    """差分隐私机制"""
    
    def __init__(self, epsilon: float = 1.0, delta: float = 1e-5, sensitivity: float = 1.0):
        """
        初始化差分隐私机制
        
        Args:
            epsilon: 隐私预算，越小隐私保护越强
            delta: 失败概率
            sensitivity: 全局敏感度
        """
        self.epsilon = epsilon
        self.delta = delta
        self.sensitivity = sensitivity
    
    def laplace_mechanism(self, true_value: Union[float, torch.Tensor]) -> Union[float, torch.Tensor]:
        """拉普拉斯机制"""
        scale = self.sensitivity / self.epsilon
        
        if isinstance(true_value, torch.Tensor):
            noise = torch.from_numpy(
                np.random.laplace(0, scale, true_value.shape)
            ).float()
            return true_value + noise
        else:
            noise = np.random.laplace(0, scale)
            return true_value + noise
    
    def gaussian_mechanism(self, true_value: Union[float, torch.Tensor]) -> Union[float, torch.Tensor]:
        """高斯机制"""
        # 计算高斯噪声的标准差
        sigma = np.sqrt(2 * np.log(1.25 / self.delta)) * self.sensitivity / self.epsilon
        
        if isinstance(true_value, torch.Tensor):
            noise = torch.normal(0, sigma, true_value.shape)
            return true_value + noise
        else:
            noise = np.random.normal(0, sigma)
            return true_value + noise
    
    def clip_gradients(self, gradients: torch.Tensor, max_norm: float) -> torch.Tensor:
        """梯度裁剪"""
        grad_norm = torch.norm(gradients)
        if grad_norm > max_norm:
            gradients = gradients * (max_norm / grad_norm)
        return gradients

class DPFederatedClient(FederatedClient):
    """支持差分隐私的联邦学习客户端"""
    
    def __init__(self, client_id: str, model: nn.Module, train_data: DataLoader,
                 learning_rate: float = 0.01, device: str = 'cpu',
                 dp_epsilon: float = 1.0, dp_delta: float = 1e-5, 
                 gradient_clip_norm: float = 1.0):
        super().__init__(client_id, model, train_data, learning_rate, device)
        
        self.dp_mechanism = DifferentialPrivacyMechanism(dp_epsilon, dp_delta)
        self.gradient_clip_norm = gradient_clip_norm
        
    def local_train_with_dp(self, epochs: int = 1) -> Dict[str, float]:
        """带差分隐私的本地训练"""
        print(f"🔒 客户端 {self.client_id} 开始差分隐私训练 ({epochs} epochs)")
        
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for epoch in range(epochs):
            for batch_idx, (data, target) in enumerate(self.train_data):
                data, target = data.to(self.device), target.to(self.device)
                
                self.optimizer.zero_grad()
                output = self.model(data)
                loss = self.criterion(output, target)
                loss.backward()
                
                # 梯度裁剪和添加噪声
                for param in self.model.parameters():
                    if param.grad is not None:
                        # 裁剪梯度
                        param.grad = self.dp_mechanism.clip_gradients(
                            param.grad, self.gradient_clip_norm
                        )
                        
                        # 添加差分隐私噪声
                        param.grad = self.dp_mechanism.gaussian_mechanism(param.grad)
                
                self.optimizer.step()
                
                total_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        avg_loss = total_loss / (len(self.train_data) * epochs)
        accuracy = 100. * correct / total
        
        training_stats = {
            'loss': avg_loss,
            'accuracy': accuracy,
            'data_size': self.data_size,
            'dp_epsilon': self.dp_mechanism.epsilon
        }
        
        print(f"   DP训练完成: Loss={avg_loss:.4f}, Acc={accuracy:.2f}%, ε={self.dp_mechanism.epsilon}")
        
        return training_stats
```

### 3. 安全聚合协议

安全聚合允许服务器计算客户端参数的聚合，而无法看到单个客户端的参数。

```python
import hashlib
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import os

class SecureAggregationProtocol:
    """安全聚合协议"""
    
    def __init__(self, num_clients: int, threshold: int = None):
        self.num_clients = num_clients
        self.threshold = threshold or (num_clients // 2 + 1)
        self.client_keys = {}
        self.encrypted_shares = {}
        
    def generate_client_keys(self) -> Dict[str, bytes]:
        """为每个客户端生成密钥"""
        print(f"🔐 为 {self.num_clients} 个客户端生成密钥")
        
        for i in range(self.num_clients):
            client_id = f"client_{i}"
            # 生成随机密钥
            key = Fernet.generate_key()
            self.client_keys[client_id] = key
        
        return self.client_keys
    
    def encrypt_parameters(self, client_id: str, parameters: OrderedDict) -> bytes:
        """加密客户端参数"""
        if client_id not in self.client_keys:
            raise ValueError(f"客户端 {client_id} 未注册")
        
        # 序列化参数
        param_bytes = self._serialize_parameters(parameters)
        
        # 加密
        fernet = Fernet(self.client_keys[client_id])
        encrypted_params = fernet.encrypt(param_bytes)
        
        return encrypted_params
    
    def create_secret_shares(self, client_id: str, parameters: OrderedDict) -> Dict[str, bytes]:
        """创建秘密分享"""
        print(f"🔀 为客户端 {client_id} 创建秘密分享")
        
        # 简化的秘密分享实现
        param_bytes = self._serialize_parameters(parameters)
        
        # 生成随机分享
        shares = {}
        total_share = torch.zeros_like(list(parameters.values())[0])
        
        for i in range(self.num_clients - 1):
            share_id = f"share_{i}"
            random_share = torch.randn_like(list(parameters.values())[0])
            shares[share_id] = self._serialize_tensor(random_share)
            total_share += random_share
        
        # 最后一个分享确保总和正确
        final_share = list(parameters.values())[0] - total_share
        shares[f"share_{self.num_clients-1}"] = self._serialize_tensor(final_share)
        
        return shares
    
    def secure_aggregate(self, encrypted_parameters: Dict[str, bytes]) -> OrderedDict:
        """安全聚合"""
        print(f"🔒 执行安全聚合，参与客户端: {len(encrypted_parameters)}")
        
        if len(encrypted_parameters) < self.threshold:
            raise ValueError(f"参与客户端数量 ({len(encrypted_parameters)}) 少于阈值 ({self.threshold})")
        
        # 解密并聚合
        aggregated_params = None
        total_weight = 0
        
        for client_id, encrypted_data in encrypted_parameters.items():
            if client_id in self.client_keys:
                # 解密
                fernet = Fernet(self.client_keys[client_id])
                decrypted_data = fernet.decrypt(encrypted_data)
                parameters = self._deserialize_parameters(decrypted_data)
                
                # 聚合
                if aggregated_params is None:
                    aggregated_params = OrderedDict()
                    for key, value in parameters.items():
                        aggregated_params[key] = value.clone()
                else:
                    for key, value in parameters.items():
                        aggregated_params[key] += value
                
                total_weight += 1
        
        # 平均化
        for key in aggregated_params.keys():
            aggregated_params[key] /= total_weight
        
        print(f"   安全聚合完成，聚合了 {total_weight} 个客户端的参数")
        
        return aggregated_params
    
    def _serialize_parameters(self, parameters: OrderedDict) -> bytes:
        """序列化参数"""
        import pickle
        return pickle.dumps(parameters)
    
    def _deserialize_parameters(self, data: bytes) -> OrderedDict:
        """反序列化参数"""
        import pickle
        return pickle.loads(data)
    
    def _serialize_tensor(self, tensor: torch.Tensor) -> bytes:
        """序列化张量"""
        import pickle
        return pickle.dumps(tensor)

class SecureFederatedServer(FederatedServer):
    """安全联邦学习服务器"""
    
    def __init__(self, global_model: nn.Module, device: str = 'cpu', 
                 use_secure_aggregation: bool = True):
        super().__init__(global_model, device)
        self.use_secure_aggregation = use_secure_aggregation
        self.secure_protocol = None
        
    def setup_secure_aggregation(self, threshold: int = None):
        """设置安全聚合"""
        if self.use_secure_aggregation:
            self.secure_protocol = SecureAggregationProtocol(
                num_clients=len(self.clients),
                threshold=threshold
            )
            client_keys = self.secure_protocol.generate_client_keys()
            
            # 分发密钥给客户端
            for client_id, key in client_keys.items():
                if client_id in self.clients:
                    print(f"🔑 为客户端 {client_id} 分发密钥")
    
    def secure_federated_round(self, selected_clients: List[str], local_epochs: int = 1) -> Dict[str, any]:
        """安全联邦学习轮次"""
        print(f"\n🔐 开始安全联邦学习轮次")
        
        # 1. 分发全局模型
        global_params = self.global_model.state_dict()
        for client_id in selected_clients:
            self.clients[client_id].set_model_parameters(global_params)
        
        # 2. 本地训练
        encrypted_parameters = {}
        client_stats = {}
        
        for client_id in selected_clients:
            client = self.clients[client_id]
            
            # 执行本地训练
            if hasattr(client, 'local_train_with_dp'):
                training_stats = client.local_train_with_dp(epochs=local_epochs)
            else:
                training_stats = client.local_train(epochs=local_epochs)
            
            # 加密参数
            if self.use_secure_aggregation and self.secure_protocol:
                client_params = client.get_model_parameters()
                encrypted_params = self.secure_protocol.encrypt_parameters(client_id, client_params)
                encrypted_parameters[client_id] = encrypted_params
            
            client_stats[client_id] = training_stats
        
        # 3. 安全聚合
        if self.use_secure_aggregation and self.secure_protocol:
            aggregated_params = self.secure_protocol.secure_aggregate(encrypted_parameters)
        else:
            # 回退到普通聚合
            client_parameters = [(client_id, self.clients[client_id].get_model_parameters()) 
                               for client_id in selected_clients]
            aggregated_params = self.federated_averaging(client_parameters)
        
        self.global_model.load_state_dict(aggregated_params)
        
        # 4. 统计信息
        round_stats = {
            'participating_clients': selected_clients,
            'client_stats': client_stats,
            'secure_aggregation': self.use_secure_aggregation,
            'total_data_size': sum(self.clients[client_id].data_size for client_id in selected_clients)
        }
        
        self.round_history.append(round_stats)
        
        return round_stats
```

### 4. 联邦学习攻击与防御

```python
class FederatedAttackDefense:
    """联邦学习攻击与防御机制"""
    
    def __init__(self, server: FederatedServer):
        self.server = server
        self.attack_history = []
        self.defense_mechanisms = []
    
    def byzantine_attack(self, malicious_clients: List[str], attack_strength: float = 2.0) -> Dict[str, any]:
        """拜占庭攻击模拟"""
        print(f"⚠️ 模拟拜占庭攻击，恶意客户端: {malicious_clients}")
        
        attack_info = {
            'attack_type': 'byzantine',
            'malicious_clients': malicious_clients,
            'attack_strength': attack_strength,
            'timestamp': torch.tensor(0)  # 简化时间戳
        }
        
        # 修改恶意客户端的模型参数
        for client_id in malicious_clients:
            if client_id in self.server.clients:
                client = self.server.clients[client_id]
                
                # 获取当前参数
                current_params = client.get_model_parameters()
                
                # 添加恶意扰动
                for key in current_params.keys():
                    noise = torch.randn_like(current_params[key]) * attack_strength
                    current_params[key] += noise
                
                # 设置被攻击的参数
                client.set_model_parameters(current_params)
        
        self.attack_history.append(attack_info)
        print(f"   拜占庭攻击已执行，影响 {len(malicious_clients)} 个客户端")
        
        return attack_info
    
    def model_poisoning_attack(self, target_client: str, poison_label: int, 
                             poison_ratio: float = 0.1) -> Dict[str, any]:
        """模型投毒攻击"""
        print(f"☠️ 对客户端 {target_client} 执行模型投毒攻击")
        
        if target_client not in self.server.clients:
            raise ValueError(f"客户端 {target_client} 不存在")
        
        client = self.server.clients[target_client]
        
        # 修改训练数据标签（简化实现）
        attack_info = {
            'attack_type': 'model_poisoning',
            'target_client': target_client,
            'poison_label': poison_label,
            'poison_ratio': poison_ratio
        }
        
        print(f"   投毒攻击已设置，目标标签: {poison_label}, 投毒比例: {poison_ratio:.1%}")
        
        self.attack_history.append(attack_info)
        return attack_info
    
    def robust_aggregation_defense(self, client_parameters: List[Tuple[str, OrderedDict]], 
                                 method: str = 'krum') -> OrderedDict:
        """鲁棒聚合防御"""
        print(f"🛡️ 应用鲁棒聚合防御: {method}")
        
        if method == 'krum':
            return self._krum_aggregation(client_parameters)
        elif method == 'trimmed_mean':
            return self._trimmed_mean_aggregation(client_parameters)
        elif method == 'median':
            return self._median_aggregation(client_parameters)
        else:
            raise ValueError(f"未知的鲁棒聚合方法: {method}")
    
    def _krum_aggregation(self, client_parameters: List[Tuple[str, OrderedDict]], 
                         num_byzantine: int = 1) -> OrderedDict:
        """Krum聚合算法"""
        print("   执行Krum聚合...")
        
        num_clients = len(client_parameters)
        if num_clients <= 2 * num_byzantine:
            print("   ⚠️ 客户端数量不足，回退到普通平均")
            return self.server.federated_averaging(client_parameters)
        
        # 计算客户端间的距离
        distances = {}
        
        for i, (client_id_i, params_i) in enumerate(client_parameters):
            total_distance = 0
            
            for j, (client_id_j, params_j) in enumerate(client_parameters):
                if i != j:
                    # 计算参数间的欧几里得距离
                    distance = 0
                    for key in params_i.keys():
                        diff = params_i[key] - params_j[key]
                        distance += torch.sum(diff ** 2).item()
                    
                    total_distance += np.sqrt(distance)
            
            distances[client_id_i] = total_distance
        
        # 选择距离最小的客户端（最不像拜占庭节点）
        selected_client = min(distances.keys(), key=lambda k: distances[k])
        
        print(f"   Krum选择客户端: {selected_client}")
        
        # 返回选中客户端的参数
        for client_id, params in client_parameters:
            if client_id == selected_client:
                return params
    
    def _trimmed_mean_aggregation(self, client_parameters: List[Tuple[str, OrderedDict]], 
                                trim_ratio: float = 0.2) -> OrderedDict:
        """修剪均值聚合"""
        print(f"   执行修剪均值聚合，修剪比例: {trim_ratio:.1%}")
        
        num_clients = len(client_parameters)
        num_trim = int(num_clients * trim_ratio)
        
        if num_trim >= num_clients // 2:
            print("   ⚠️ 修剪比例过高，回退到普通平均")
            return self.server.federated_averaging(client_parameters)
        
        # 获取参数结构
        first_params = client_parameters[0][1]
        aggregated_params = OrderedDict()
        
        for key in first_params.keys():
            # 收集所有客户端的该参数
            param_values = []
            for _, params in client_parameters:
                param_values.append(params[key])
            
            # 转换为张量进行计算
            param_tensor = torch.stack(param_values)
            
            # 计算修剪均值
            sorted_params, _ = torch.sort(param_tensor, dim=0)
            trimmed_params = sorted_params[num_trim:num_clients-num_trim]
            
            aggregated_params[key] = torch.mean(trimmed_params, dim=0)
        
        return aggregated_params
    
    def _median_aggregation(self, client_parameters: List[Tuple[str, OrderedDict]]) -> OrderedDict:
        """中位数聚合"""
        print("   执行中位数聚合...")
        
        # 获取参数结构
        first_params = client_parameters[0][1]
        aggregated_params = OrderedDict()
        
        for key in first_params.keys():
            # 收集所有客户端的该参数
            param_values = []
            for _, params in client_parameters:
                param_values.append(params[key])
            
            # 转换为张量并计算中位数
            param_tensor = torch.stack(param_values)
            aggregated_params[key] = torch.median(param_tensor, dim=0)[0]
        
        return aggregated_params
    
    def anomaly_detection(self, client_parameters: List[Tuple[str, OrderedDict]], 
                         threshold: float = 2.0) -> List[str]:
        """异常检测"""
        print(f"🔍 执行异常检测，阈值: {threshold}")
        
        # 计算参数的统计特征
        param_stats = {}
        
        # 获取所有参数的均值和标准差
        first_params = client_parameters[0][1]
        for key in first_params.keys():
            param_values = []
            for _, params in client_parameters:
                param_values.append(params[key].flatten())
            
            all_values = torch.cat(param_values)
            param_stats[key] = {
                'mean': torch.mean(all_values),
                'std': torch.std(all_values)
            }
        
        # 检测异常客户端
        anomalous_clients = []
        
        for client_id, params in client_parameters:
            anomaly_score = 0
            
            for key in params.keys():
                param_flat = params[key].flatten()
                mean_val = param_stats[key]['mean']
                std_val = param_stats[key]['std']
                
                # 计算Z分数
                z_scores = torch.abs((param_flat - mean_val) / (std_val + 1e-8))
                max_z_score = torch.max(z_scores).item()
                
                anomaly_score = max(anomaly_score, max_z_score)
            
            if anomaly_score > threshold:
                anomalous_clients.append(client_id)
                print(f"   检测到异常客户端: {client_id} (异常分数: {anomaly_score:.2f})")
        
        return anomalous_clients
```

## 🎯 Trae实践：隐私保护联邦学习系统

让我们在Trae中实现一个完整的隐私保护联邦学习系统：

```python
class PrivacyPreservingFederatedSystem:
    """隐私保护联邦学习系统"""
    
    def __init__(self, num_clients: int = 5, device: str = 'cpu'):
        self.num_clients = num_clients
        self.device = device
        self.clients = {}
        self.server = None
        self.attack_defense = None
        
        # 系统配置
        self.config = {
            'use_differential_privacy': True,
            'use_secure_aggregation': True,
            'use_robust_aggregation': True,
            'dp_epsilon': 1.0,
            'dp_delta': 1e-5,
            'gradient_clip_norm': 1.0
        }
    
    def setup_system(self, model_class, train_datasets: List[DataLoader]) -> Dict[str, any]:
        """设置联邦学习系统"""
        print(f"🏗️ 设置隐私保护联邦学习系统")
        print(f"   客户端数量: {self.num_clients}")
        print(f"   差分隐私: {self.config['use_differential_privacy']}")
        print(f"   安全聚合: {self.config['use_secure_aggregation']}")
        print(f"   鲁棒聚合: {self.config['use_robust_aggregation']}")
        print("=" * 60)
        
        # 1. 创建全局模型
        global_model = model_class()
        
        # 2. 创建服务器
        if self.config['use_secure_aggregation']:
            self.server = SecureFederatedServer(
                global_model=global_model,
                device=self.device,
                use_secure_aggregation=True
            )
        else:
            self.server = FederatedServer(
                global_model=global_model,
                device=self.device
            )
        
        # 3. 创建客户端
        for i in range(self.num_clients):
            client_id = f"client_{i}"
            client_model = model_class()
            
            if self.config['use_differential_privacy']:
                client = DPFederatedClient(
                    client_id=client_id,
                    model=client_model,
                    train_data=train_datasets[i],
                    device=self.device,
                    dp_epsilon=self.config['dp_epsilon'],
                    dp_delta=self.config['dp_delta'],
                    gradient_clip_norm=self.config['gradient_clip_norm']
                )
            else:
                client = FederatedClient(
                    client_id=client_id,
                    model=client_model,
                    train_data=train_datasets[i],
                    device=self.device
                )
            
            self.clients[client_id] = client
            self.server.register_client(client)
        
        # 4. 设置安全聚合
        if self.config['use_secure_aggregation']:
            self.server.setup_secure_aggregation()
        
        # 5. 设置攻击防御
        self.attack_defense = FederatedAttackDefense(self.server)
        
        setup_info = {
            'num_clients': self.num_clients,
            'global_model_params': sum(p.numel() for p in global_model.parameters()),
            'total_training_samples': sum(len(dataset.dataset) for dataset in train_datasets),
            'privacy_config': self.config
        }
        
        print(f"\n✅ 系统设置完成")
        print(f"   全局模型参数: {setup_info['global_model_params']:,}")
        print(f"   总训练样本: {setup_info['total_training_samples']:,}")
        
        return setup_info
    
    def run_federated_training(self, num_rounds: int = 10, test_data: DataLoader = None,
                             simulate_attacks: bool = False) -> Dict[str, any]:
        """运行联邦学习训练"""
        print(f"\n🚀 开始隐私保护联邦学习训练")
        print(f"   训练轮数: {num_rounds}")
        print(f"   模拟攻击: {simulate_attacks}")
        print("=" * 60)
        
        training_history = []
        
        for round_num in range(num_rounds):
            print(f"\n📍 联邦学习轮次 {round_num + 1}/{num_rounds}")
            
            # 模拟攻击（如果启用）
            if simulate_attacks and round_num % 3 == 0:  # 每3轮模拟一次攻击
                self._simulate_attacks(round_num)
            
            # 选择客户端
            selected_clients = self.server.select_clients(fraction=0.8)
            
            # 执行联邦轮次
            if hasattr(self.server, 'secure_federated_round'):
                round_stats = self.server.secure_federated_round(selected_clients, local_epochs=1)
            else:
                round_stats = self.server.federated_round(selected_clients, local_epochs=1)
            
            # 应用鲁棒聚合防御
            if self.config['use_robust_aggregation'] and simulate_attacks:
                self._apply_robust_defense(selected_clients)
            
            # 评估全局模型
            if test_data is not None:
                global_performance = self.server.evaluate_global_model(test_data)
                round_stats['global_performance'] = global_performance
                
                print(f"   全局模型性能: Loss={global_performance['loss']:.4f}, "
                      f"Acc={global_performance['accuracy']:.2f}%")
            
            # 隐私预算跟踪
            if self.config['use_differential_privacy']:
                total_epsilon = round_num * self.config['dp_epsilon']
                round_stats['cumulative_epsilon'] = total_epsilon
                print(f"   累计隐私预算 ε: {total_epsilon:.2f}")
            
            training_history.append(round_stats)
        
        print(f"\n🎉 隐私保护联邦学习训练完成！")
        
        return {
            'training_history': training_history,
            'final_model': self.server.global_model,
            'privacy_analysis': self._analyze_privacy_guarantees(),
            'security_analysis': self._analyze_security_measures()
        }
    
    def _simulate_attacks(self, round_num: int):
        """模拟攻击"""
        print(f"⚠️ 轮次 {round_num + 1}: 模拟攻击")
        
        # 随机选择恶意客户端
        malicious_clients = random.sample(list(self.clients.keys()), k=1)
        
        if round_num % 6 == 0:  # 拜占庭攻击
            self.attack_defense.byzantine_attack(malicious_clients, attack_strength=1.5)
        else:  # 模型投毒攻击
            self.attack_defense.model_poisoning_attack(
                target_client=malicious_clients[0],
                poison_label=random.randint(0, 9),
                poison_ratio=0.1
            )
    
    def _apply_robust_defense(self, selected_clients: List[str]):
        """应用鲁棒防御"""
        print("🛡️ 应用鲁棒防御机制")
        
        # 收集客户端参数
        client_parameters = []
        for client_id in selected_clients:
            params = self.clients[client_id].get_model_parameters()
            client_parameters.append((client_id, params))
        
        # 异常检测
        anomalous_clients = self.attack_defense.anomaly_detection(client_parameters)
        
        if anomalous_clients:
            print(f"   检测到异常客户端: {anomalous_clients}")
            
            # 移除异常客户端
            filtered_parameters = [(cid, params) for cid, params in client_parameters 
                                 if cid not in anomalous_clients]
            
            if len(filtered_parameters) >= 2:  # 确保有足够的客户端
                # 应用鲁棒聚合
                robust_params = self.attack_defense.robust_aggregation_defense(
                    filtered_parameters, method='trimmed_mean'
                )
                
                # 更新全局模型
                self.server.global_model.load_state_dict(robust_params)
                print(f"   已应用鲁棒聚合，使用 {len(filtered_parameters)} 个可信客户端")
    
    def _analyze_privacy_guarantees(self) -> Dict[str, any]:
        """分析隐私保障"""
        privacy_analysis = {
            'differential_privacy_enabled': self.config['use_differential_privacy'],
            'secure_aggregation_enabled': self.config['use_secure_aggregation']
        }
        
        if self.config['use_differential_privacy']:
            privacy_analysis.update({
                'epsilon': self.config['dp_epsilon'],
                'delta': self.config['dp_delta'],
                'privacy_level': 'strong' if self.config['dp_epsilon'] < 1.0 else 'moderate'
            })
        
        return privacy_analysis
    
    def _analyze_security_measures(self) -> Dict[str, any]:
        """分析安全措施"""
        security_analysis = {
            'attack_simulations': len(self.attack_defense.attack_history),
            'defense_mechanisms': [
                'robust_aggregation' if self.config['use_robust_aggregation'] else None,
                'secure_aggregation' if self.config['use_secure_aggregation'] else None,
                'differential_privacy' if self.config['use_differential_privacy'] else None
            ],
            'security_level': 'high'
        }
        
        # 过滤None值
        security_analysis['defense_mechanisms'] = [
            mechanism for mechanism in security_analysis['defense_mechanisms'] 
            if mechanism is not None
        ]
        
        return security_analysis

# 隐私保护联邦学习演示
if __name__ == "__main__":
    # 创建简单的神经网络模型
    class SimpleNN(nn.Module):
        def __init__(self, input_size=784, hidden_size=128, num_classes=10):
            super(SimpleNN, self).__init__()
            self.fc1 = nn.Linear(input_size, hidden_size)
            self.relu = nn.ReLU()
            self.fc2 = nn.Linear(hidden_size, num_classes)
        
        def forward(self, x):
            x = x.view(x.size(0), -1)
            x = self.fc1(x)
            x = self.relu(x)
            x = self.fc2(x)
            return x
    
    # 创建模拟数据集
    def create_federated_datasets(num_clients=5, samples_per_client=200):
        datasets = []
        for i in range(num_clients):
            # 为每个客户端创建不同分布的数据
            X = torch.randn(samples_per_client, 784) + i * 0.1  # 轻微的数据异质性
            y = torch.randint(0, 10, (samples_per_client,))
            
            dataset = TensorDataset(X, y)
            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
            datasets.append(dataloader)
        
        return datasets
    
    # 创建测试数据
    X_test = torch.randn(500, 784)
    y_test = torch.randint(0, 10, (500,))
    test_dataset = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # 创建联邦数据集
    federated_datasets = create_federated_datasets(num_clients=5)
    
    # 创建隐私保护联邦学习系统
    fl_system = PrivacyPreservingFederatedSystem(num_clients=5)
    
    # 设置系统
    setup_info = fl_system.setup_system(SimpleNN, federated_datasets)
    
    # 运行联邦学习训练
    results = fl_system.run_federated_training(
        num_rounds=8,
        test_data=test_loader,
        simulate_attacks=True
    )
    
    print("\n📊 训练结果总结:")
    print(f"   隐私分析: {results['privacy_analysis']}")
    print(f"   安全分析: {results['security_analysis']}")
    print("\n🎉 隐私保护联邦学习演示完成！")
```

## 小结

联邦学习与隐私保护技术为分布式机器学习提供了强大的解决方案。通过本节的学习，你应该掌握：

### 🎯 核心技术
1. **联邦学习架构**：客户端-服务器模式和参数聚合
2. **差分隐私**：数学化的隐私保护框架
3. **安全聚合**：保护单个客户端参数隐私
4. **攻击防御**：检测和防御恶意行为

### 💡 实践要点
1. **隐私预算管理**：合理分配和使用隐私预算
2. **安全性评估**：全面评估系统安全性
3. **性能平衡**：在隐私、安全和性能间找到平衡
4. **异质性处理**：应对客户端数据分布差异

### 🚀 应用场景
1. **医疗健康**：多医院协作训练诊断模型
2. **金融服务**：银行间风控模型协作
3. **移动设备**：手机键盘输入预测
4. **物联网**：边缘设备协作学习

联邦学习技术正在快速发展，掌握这些技术将帮助你在隐私敏感的场景中部署机器学习解决方案。在下一小节中，我们将探讨AI工程化最佳实践。