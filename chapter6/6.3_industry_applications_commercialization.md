# 6.3 äº§ä¸šåº”ç”¨ä¸å•†ä¸šåŒ–

éšç€AIæŠ€æœ¯çš„æˆç†Ÿï¼Œå¦‚ä½•å°†æŠ€æœ¯è½¬åŒ–ä¸ºå•†ä¸šä»·å€¼ï¼Œåœ¨å„ä¸ªå‚ç›´è¡Œä¸šä¸­å®ç°è§„æ¨¡åŒ–åº”ç”¨ï¼Œæˆä¸ºäº†AIä»ä¸šè€…å…³æ³¨çš„æ ¸å¿ƒé—®é¢˜ã€‚æœ¬èŠ‚å°†æ·±å…¥æ¢è®¨AIæŠ€æœ¯çš„äº§ä¸šåº”ç”¨æ¨¡å¼å’Œå•†ä¸šåŒ–è·¯å¾„ã€‚

## ğŸ­ å‚ç›´è¡Œä¸šåº”ç”¨

### 1. é‡‘èç§‘æŠ€ï¼ˆFinTechï¼‰

é‡‘èè¡Œä¸šæ˜¯AIåº”ç”¨æœ€ä¸ºæˆç†Ÿçš„é¢†åŸŸä¹‹ä¸€ï¼Œæ¶µç›–é£é™©æ§åˆ¶ã€æ™ºèƒ½æŠ•é¡¾ã€åæ¬ºè¯ˆç­‰å¤šä¸ªåœºæ™¯ã€‚

```python
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
from dataclasses import dataclass, asdict
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
from abc import ABC, abstractmethod
import warnings
warnings.filterwarnings('ignore')

@dataclass
class RiskProfile:
    """é£é™©ç”»åƒ"""
    user_id: str
    credit_score: float
    income_level: str
    debt_ratio: float
    payment_history: List[float]
    risk_level: str  # 'low', 'medium', 'high'
    risk_score: float
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class TransactionRecord:
    """äº¤æ˜“è®°å½•"""
    transaction_id: str
    user_id: str
    amount: float
    timestamp: datetime
    merchant_category: str
    location: str
    is_fraud: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        return result

class CreditRiskAssessment:
    """ä¿¡è´·é£é™©è¯„ä¼°ç³»ç»Ÿ"""
    
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        self.is_trained = False
        self.feature_importance = {}
        
    def prepare_features(self, user_data: Dict[str, Any]) -> np.ndarray:
        """ç‰¹å¾å·¥ç¨‹"""
        features = []
        
        # åŸºç¡€ç‰¹å¾
        features.extend([
            user_data.get('age', 0),
            user_data.get('income', 0),
            user_data.get('employment_years', 0),
            user_data.get('debt_ratio', 0),
            user_data.get('credit_history_length', 0)
        ])
        
        # è¡Œä¸ºç‰¹å¾
        payment_history = user_data.get('payment_history', [])
        if payment_history:
            features.extend([
                np.mean(payment_history),  # å¹³å‡è¿˜æ¬¾è¡¨ç°
                np.std(payment_history),   # è¿˜æ¬¾ç¨³å®šæ€§
                len([p for p in payment_history if p < 0.5]),  # é€¾æœŸæ¬¡æ•°
                payment_history[-1] if payment_history else 0  # æœ€è¿‘è¿˜æ¬¾è¡¨ç°
            ])
        else:
            features.extend([0, 0, 0, 0])
        
        # è´¦æˆ·ç‰¹å¾
        features.extend([
            user_data.get('account_balance', 0),
            user_data.get('monthly_transactions', 0),
            user_data.get('avg_transaction_amount', 0)
        ])
        
        return np.array(features).reshape(1, -1)
    
    def train(self, training_data: List[Dict[str, Any]], labels: List[int]):
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸ¯ è®­ç»ƒä¿¡è´·é£é™©è¯„ä¼°æ¨¡å‹...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = []
        for user_data in training_data:
            features = self.prepare_features(user_data)
            X.append(features.flatten())
        
        X = np.array(X)
        y = np.array(labels)
        
        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_scaled, y)
        self.is_trained = True
        
        # è®¡ç®—ç‰¹å¾é‡è¦æ€§
        feature_names = [
            'age', 'income', 'employment_years', 'debt_ratio', 'credit_history_length',
            'avg_payment', 'payment_stability', 'overdue_count', 'recent_payment',
            'account_balance', 'monthly_transactions', 'avg_transaction_amount'
        ]
        
        self.feature_importance = dict(zip(feature_names, self.model.feature_importances_))
        
        # è¯„ä¼°æ¨¡å‹
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
        y_pred = self.model.predict(X_test)
        y_prob = self.model.predict_proba(X_test)[:, 1]
        
        auc_score = roc_auc_score(y_test, y_prob)
        print(f"   æ¨¡å‹AUC: {auc_score:.4f}")
        print(f"   è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨ {len(training_data)} ä¸ªæ ·æœ¬")
    
    def assess_risk(self, user_data: Dict[str, Any]) -> RiskProfile:
        """è¯„ä¼°ç”¨æˆ·é£é™©"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        # å‡†å¤‡ç‰¹å¾
        features = self.prepare_features(user_data)
        features_scaled = self.scaler.transform(features)
        
        # é¢„æµ‹é£é™©
        risk_prob = self.model.predict_proba(features_scaled)[0, 1]
        risk_prediction = self.model.predict(features_scaled)[0]
        
        # ç¡®å®šé£é™©ç­‰çº§
        if risk_prob < 0.3:
            risk_level = 'low'
        elif risk_prob < 0.7:
            risk_level = 'medium'
        else:
            risk_level = 'high'
        
        # è®¡ç®—ä¿¡ç”¨åˆ†æ•° (300-850)
        credit_score = 850 - (risk_prob * 550)
        
        return RiskProfile(
            user_id=user_data.get('user_id', ''),
            credit_score=credit_score,
            income_level=self._categorize_income(user_data.get('income', 0)),
            debt_ratio=user_data.get('debt_ratio', 0),
            payment_history=user_data.get('payment_history', []),
            risk_level=risk_level,
            risk_score=risk_prob
        )
    
    def _categorize_income(self, income: float) -> str:
        """æ”¶å…¥åˆ†ç±»"""
        if income < 30000:
            return 'low'
        elif income < 80000:
            return 'medium'
        else:
            return 'high'
    
    def explain_decision(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """è§£é‡Šå†³ç­–"""
        risk_profile = self.assess_risk(user_data)
        
        # è·å–ç‰¹å¾å€¼
        features = self.prepare_features(user_data).flatten()
        feature_names = list(self.feature_importance.keys())
        
        # è®¡ç®—ç‰¹å¾è´¡çŒ®
        feature_contributions = []
        for i, (name, importance) in enumerate(self.feature_importance.items()):
            if i < len(features):
                contribution = features[i] * importance
                feature_contributions.append({
                    'feature': name,
                    'value': features[i],
                    'importance': importance,
                    'contribution': contribution
                })
        
        # æ’åºç‰¹å¾è´¡çŒ®
        feature_contributions.sort(key=lambda x: abs(x['contribution']), reverse=True)
        
        return {
            'risk_profile': risk_profile.to_dict(),
            'top_factors': feature_contributions[:5],
            'model_confidence': max(risk_profile.risk_score, 1 - risk_profile.risk_score)
        }

class FraudDetectionSystem:
    """åæ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.rule_engine = FraudRuleEngine()
        self.transaction_history = []
        self.user_profiles = {}
        self.is_trained = False
    
    def train(self, historical_transactions: List[TransactionRecord]):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        print("ğŸ” è®­ç»ƒåæ¬ºè¯ˆæ£€æµ‹æ¨¡å‹...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        features = []
        for transaction in historical_transactions:
            feature_vector = self._extract_features(transaction)
            features.append(feature_vector)
            
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            self._update_user_profile(transaction)
        
        X = np.array(features)
        
        # è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹
        self.anomaly_detector.fit(X)
        self.is_trained = True
        
        print(f"   è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨ {len(historical_transactions)} ç¬”äº¤æ˜“")
    
    def detect_fraud(self, transaction: TransactionRecord) -> Dict[str, Any]:
        """æ£€æµ‹æ¬ºè¯ˆäº¤æ˜“"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        # æå–ç‰¹å¾
        features = self._extract_features(transaction)
        
        # å¼‚å¸¸æ£€æµ‹
        anomaly_score = self.anomaly_detector.decision_function([features])[0]
        is_anomaly = self.anomaly_detector.predict([features])[0] == -1
        
        # è§„åˆ™å¼•æ“æ£€æµ‹
        rule_results = self.rule_engine.check_rules(transaction, self.user_profiles)
        
        # ç»¼åˆåˆ¤æ–­
        fraud_probability = self._calculate_fraud_probability(
            anomaly_score, rule_results
        )
        
        # æ›´æ–°ç”¨æˆ·ç”»åƒ
        self._update_user_profile(transaction)
        
        return {
            'transaction_id': transaction.transaction_id,
            'is_fraud_predicted': fraud_probability > 0.7,
            'fraud_probability': fraud_probability,
            'anomaly_score': anomaly_score,
            'rule_violations': rule_results['violations'],
            'risk_factors': rule_results['risk_factors'],
            'recommendation': self._get_recommendation(fraud_probability)
        }
    
    def _extract_features(self, transaction: TransactionRecord) -> List[float]:
        """æå–äº¤æ˜“ç‰¹å¾"""
        features = []
        
        # åŸºç¡€ç‰¹å¾
        features.extend([
            transaction.amount,
            transaction.timestamp.hour,  # äº¤æ˜“æ—¶é—´
            transaction.timestamp.weekday(),  # æ˜ŸæœŸå‡ 
        ])
        
        # ç”¨æˆ·å†å²ç‰¹å¾
        user_profile = self.user_profiles.get(transaction.user_id, {})
        features.extend([
            user_profile.get('avg_amount', 0),
            user_profile.get('transaction_count', 0),
            user_profile.get('unique_merchants', 0),
            user_profile.get('avg_daily_transactions', 0)
        ])
        
        # å•†æˆ·ç±»åˆ«ç¼–ç ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        merchant_categories = ['grocery', 'gas', 'restaurant', 'retail', 'online', 'other']
        category_encoding = [1 if transaction.merchant_category == cat else 0 
                           for cat in merchant_categories]
        features.extend(category_encoding)
        
        return features
    
    def _update_user_profile(self, transaction: TransactionRecord):
        """æ›´æ–°ç”¨æˆ·ç”»åƒ"""
        user_id = transaction.user_id
        
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = {
                'total_amount': 0,
                'transaction_count': 0,
                'merchants': set(),
                'locations': set(),
                'last_transaction': None,
                'daily_transactions': {}
            }
        
        profile = self.user_profiles[user_id]
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        profile['total_amount'] += transaction.amount
        profile['transaction_count'] += 1
        profile['merchants'].add(transaction.merchant_category)
        profile['locations'].add(transaction.location)
        profile['last_transaction'] = transaction.timestamp
        
        # æ›´æ–°æ—¥äº¤æ˜“ç»Ÿè®¡
        date_key = transaction.timestamp.date().isoformat()
        if date_key not in profile['daily_transactions']:
            profile['daily_transactions'][date_key] = 0
        profile['daily_transactions'][date_key] += 1
        
        # è®¡ç®—è¡ç”Ÿç‰¹å¾
        profile['avg_amount'] = profile['total_amount'] / profile['transaction_count']
        profile['unique_merchants'] = len(profile['merchants'])
        profile['unique_locations'] = len(profile['locations'])
        profile['avg_daily_transactions'] = np.mean(list(profile['daily_transactions'].values()))
    
    def _calculate_fraud_probability(self, anomaly_score: float, 
                                   rule_results: Dict[str, Any]) -> float:
        """è®¡ç®—æ¬ºè¯ˆæ¦‚ç‡"""
        # å¼‚å¸¸åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ (0-1)
        anomaly_prob = max(0, min(1, (0.5 - anomaly_score) / 0.5))
        
        # è§„åˆ™è¿åæƒé‡
        rule_weight = len(rule_results['violations']) * 0.2
        
        # ç»¼åˆæ¦‚ç‡
        fraud_prob = min(1.0, anomaly_prob + rule_weight)
        
        return fraud_prob
    
    def _get_recommendation(self, fraud_probability: float) -> str:
        """è·å–å¤„ç†å»ºè®®"""
        if fraud_probability > 0.9:
            return "ç«‹å³é˜»æ­¢äº¤æ˜“ï¼Œäººå·¥å®¡æ ¸"
        elif fraud_probability > 0.7:
            return "æš‚åœäº¤æ˜“ï¼Œè¦æ±‚é¢å¤–éªŒè¯"
        elif fraud_probability > 0.5:
            return "æ ‡è®°ä¸ºå¯ç–‘ï¼ŒåŠ å¼ºç›‘æ§"
        else:
            return "æ­£å¸¸å¤„ç†"

class FraudRuleEngine:
    """æ¬ºè¯ˆè§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.rules = [
            self._check_amount_threshold,
            self._check_frequency_anomaly,
            self._check_location_anomaly,
            self._check_time_anomaly,
            self._check_merchant_anomaly
        ]
    
    def check_rules(self, transaction: TransactionRecord, 
                   user_profiles: Dict[str, Dict]) -> Dict[str, Any]:
        """æ£€æŸ¥è§„åˆ™"""
        violations = []
        risk_factors = []
        
        user_profile = user_profiles.get(transaction.user_id, {})
        
        for rule in self.rules:
            result = rule(transaction, user_profile)
            if result['violated']:
                violations.append(result['rule_name'])
                risk_factors.append(result['description'])
        
        return {
            'violations': violations,
            'risk_factors': risk_factors,
            'total_violations': len(violations)
        }
    
    def _check_amount_threshold(self, transaction: TransactionRecord, 
                               user_profile: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥é‡‘é¢é˜ˆå€¼"""
        avg_amount = user_profile.get('avg_amount', 0)
        
        # å¦‚æœäº¤æ˜“é‡‘é¢è¶…è¿‡å†å²å¹³å‡çš„5å€
        threshold_multiplier = 5
        is_violated = (avg_amount > 0 and 
                      transaction.amount > avg_amount * threshold_multiplier)
        
        return {
            'rule_name': 'amount_threshold',
            'violated': is_violated,
            'description': f'äº¤æ˜“é‡‘é¢ {transaction.amount} è¶…è¿‡å†å²å¹³å‡ {avg_amount:.2f} çš„ {threshold_multiplier} å€'
        }
    
    def _check_frequency_anomaly(self, transaction: TransactionRecord, 
                                user_profile: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥é¢‘ç‡å¼‚å¸¸"""
        avg_daily = user_profile.get('avg_daily_transactions', 0)
        
        # è·å–ä»Šæ—¥äº¤æ˜“æ¬¡æ•°
        today = transaction.timestamp.date().isoformat()
        daily_transactions = user_profile.get('daily_transactions', {})
        today_count = daily_transactions.get(today, 0)
        
        # å¦‚æœä»Šæ—¥äº¤æ˜“æ¬¡æ•°è¶…è¿‡å†å²å¹³å‡çš„3å€
        threshold_multiplier = 3
        is_violated = (avg_daily > 0 and 
                      today_count > avg_daily * threshold_multiplier)
        
        return {
            'rule_name': 'frequency_anomaly',
            'violated': is_violated,
            'description': f'ä»Šæ—¥äº¤æ˜“æ¬¡æ•° {today_count} è¶…è¿‡å†å²å¹³å‡ {avg_daily:.1f} çš„ {threshold_multiplier} å€'
        }
    
    def _check_location_anomaly(self, transaction: TransactionRecord, 
                               user_profile: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥åœ°ç‚¹å¼‚å¸¸"""
        known_locations = user_profile.get('locations', set())
        
        # å¦‚æœæ˜¯æ–°åœ°ç‚¹ä¸”ç”¨æˆ·æœ‰å†å²è®°å½•
        is_violated = (len(known_locations) > 0 and 
                      transaction.location not in known_locations)
        
        return {
            'rule_name': 'location_anomaly',
            'violated': is_violated,
            'description': f'åœ¨æ–°åœ°ç‚¹ {transaction.location} è¿›è¡Œäº¤æ˜“'
        }
    
    def _check_time_anomaly(self, transaction: TransactionRecord, 
                           user_profile: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¶é—´å¼‚å¸¸"""
        # æ·±å¤œäº¤æ˜“ (23:00 - 6:00)
        hour = transaction.timestamp.hour
        is_violated = hour >= 23 or hour <= 6
        
        return {
            'rule_name': 'time_anomaly',
            'violated': is_violated,
            'description': f'åœ¨å¼‚å¸¸æ—¶é—´ {hour}:00 è¿›è¡Œäº¤æ˜“'
        }
    
    def _check_merchant_anomaly(self, transaction: TransactionRecord, 
                               user_profile: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥å•†æˆ·å¼‚å¸¸"""
        known_merchants = user_profile.get('merchants', set())
        
        # å¦‚æœæ˜¯æ–°å•†æˆ·ç±»åˆ«ä¸”ç”¨æˆ·æœ‰å†å²è®°å½•
        is_violated = (len(known_merchants) > 0 and 
                      transaction.merchant_category not in known_merchants)
        
        return {
            'rule_name': 'merchant_anomaly',
            'violated': is_violated,
            'description': f'åœ¨æ–°å•†æˆ·ç±»åˆ« {transaction.merchant_category} è¿›è¡Œäº¤æ˜“'
        }

class IntelligentInvestmentAdvisor:
    """æ™ºèƒ½æŠ•é¡¾ç³»ç»Ÿ"""
    
    def __init__(self):
        self.risk_models = {
            'conservative': {'stocks': 0.2, 'bonds': 0.6, 'cash': 0.2},
            'moderate': {'stocks': 0.5, 'bonds': 0.4, 'cash': 0.1},
            'aggressive': {'stocks': 0.8, 'bonds': 0.15, 'cash': 0.05}
        }
        self.market_data = {}
        self.user_portfolios = {}
    
    def assess_risk_tolerance(self, user_data: Dict[str, Any]) -> str:
        """è¯„ä¼°é£é™©æ‰¿å—èƒ½åŠ›"""
        score = 0
        
        # å¹´é¾„å› ç´ 
        age = user_data.get('age', 30)
        if age < 30:
            score += 3
        elif age < 50:
            score += 2
        else:
            score += 1
        
        # æ”¶å…¥å› ç´ 
        income = user_data.get('income', 50000)
        if income > 100000:
            score += 3
        elif income > 50000:
            score += 2
        else:
            score += 1
        
        # æŠ•èµ„ç»éªŒ
        experience = user_data.get('investment_experience', 'beginner')
        if experience == 'expert':
            score += 3
        elif experience == 'intermediate':
            score += 2
        else:
            score += 1
        
        # æŠ•èµ„ç›®æ ‡
        goal = user_data.get('investment_goal', 'growth')
        if goal == 'aggressive_growth':
            score += 3
        elif goal == 'growth':
            score += 2
        else:
            score += 1
        
        # ç¡®å®šé£é™©ç­‰çº§
        if score >= 10:
            return 'aggressive'
        elif score >= 7:
            return 'moderate'
        else:
            return 'conservative'
    
    def generate_portfolio_recommendation(self, user_id: str, 
                                        user_data: Dict[str, Any], 
                                        investment_amount: float) -> Dict[str, Any]:
        """ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®"""
        print(f"ğŸ’¼ ä¸ºç”¨æˆ· {user_id} ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®...")
        
        # è¯„ä¼°é£é™©æ‰¿å—èƒ½åŠ›
        risk_tolerance = self.assess_risk_tolerance(user_data)
        
        # è·å–èµ„äº§é…ç½®æ¨¡å‹
        allocation_model = self.risk_models[risk_tolerance]
        
        # è®¡ç®—å…·ä½“æŠ•èµ„é‡‘é¢
        portfolio = {}
        for asset_class, percentage in allocation_model.items():
            portfolio[asset_class] = {
                'percentage': percentage,
                'amount': investment_amount * percentage,
                'recommended_products': self._get_recommended_products(asset_class)
            }
        
        # ç”ŸæˆæŠ•èµ„å»ºè®®
        recommendation = {
            'user_id': user_id,
            'risk_tolerance': risk_tolerance,
            'total_investment': investment_amount,
            'portfolio_allocation': portfolio,
            'expected_return': self._calculate_expected_return(allocation_model),
            'risk_level': self._calculate_risk_level(allocation_model),
            'rebalancing_frequency': self._get_rebalancing_frequency(risk_tolerance),
            'investment_strategy': self._get_investment_strategy(risk_tolerance)
        }
        
        # ä¿å­˜ç”¨æˆ·æŠ•èµ„ç»„åˆ
        self.user_portfolios[user_id] = recommendation
        
        print(f"   é£é™©æ‰¿å—èƒ½åŠ›: {risk_tolerance}")
        print(f"   é¢„æœŸå¹´åŒ–æ”¶ç›Š: {recommendation['expected_return']:.2%}")
        
        return recommendation
    
    def _get_recommended_products(self, asset_class: str) -> List[str]:
        """è·å–æ¨èäº§å“"""
        products = {
            'stocks': ['æ²ªæ·±300ETF', 'ä¸­è¯500ETF', 'åˆ›ä¸šæ¿ETF', 'ç§‘æŠ€é¾™å¤´ETF'],
            'bonds': ['å›½å€ºETF', 'ä¼ä¸šå€ºETF', 'å¯è½¬å€ºETF', 'é«˜ç­‰çº§ä¿¡ç”¨å€º'],
            'cash': ['è´§å¸åŸºé‡‘', 'é“¶è¡Œç†è´¢', 'å®šæœŸå­˜æ¬¾', 'å›½å€ºé€†å›è´­']
        }
        return products.get(asset_class, [])
    
    def _calculate_expected_return(self, allocation_model: Dict[str, float]) -> float:
        """è®¡ç®—é¢„æœŸæ”¶ç›Šç‡"""
        expected_returns = {
            'stocks': 0.08,  # 8%å¹´åŒ–æ”¶ç›Š
            'bonds': 0.04,   # 4%å¹´åŒ–æ”¶ç›Š
            'cash': 0.02     # 2%å¹´åŒ–æ”¶ç›Š
        }
        
        total_return = 0
        for asset_class, percentage in allocation_model.items():
            total_return += percentage * expected_returns.get(asset_class, 0)
        
        return total_return
    
    def _calculate_risk_level(self, allocation_model: Dict[str, float]) -> float:
        """è®¡ç®—é£é™©æ°´å¹³"""
        risk_levels = {
            'stocks': 0.15,  # 15%æ³¢åŠ¨ç‡
            'bonds': 0.05,   # 5%æ³¢åŠ¨ç‡
            'cash': 0.01     # 1%æ³¢åŠ¨ç‡
        }
        
        total_risk = 0
        for asset_class, percentage in allocation_model.items():
            total_risk += (percentage ** 2) * (risk_levels.get(asset_class, 0) ** 2)
        
        return total_risk ** 0.5
    
    def _get_rebalancing_frequency(self, risk_tolerance: str) -> str:
        """è·å–å†å¹³è¡¡é¢‘ç‡"""
        frequencies = {
            'conservative': 'åŠå¹´ä¸€æ¬¡',
            'moderate': 'å­£åº¦ä¸€æ¬¡',
            'aggressive': 'æœˆåº¦ä¸€æ¬¡'
        }
        return frequencies.get(risk_tolerance, 'å­£åº¦ä¸€æ¬¡')
    
    def _get_investment_strategy(self, risk_tolerance: str) -> str:
        """è·å–æŠ•èµ„ç­–ç•¥"""
        strategies = {
            'conservative': 'ç¨³å¥ä¿å€¼ï¼Œæ³¨é‡èµ„æœ¬å®‰å…¨ï¼Œè¿½æ±‚ç¨³å®šæ”¶ç›Š',
            'moderate': 'å¹³è¡¡å¢é•¿ï¼Œåœ¨æ§åˆ¶é£é™©çš„å‰æä¸‹è¿½æ±‚åˆç†æ”¶ç›Š',
            'aggressive': 'ç§¯æå¢é•¿ï¼Œæ‰¿æ‹…è¾ƒé«˜é£é™©ä»¥è¿½æ±‚æ›´é«˜æ”¶ç›Š'
        }
        return strategies.get(risk_tolerance, 'å¹³è¡¡å¢é•¿')
    
    def monitor_portfolio_performance(self, user_id: str) -> Dict[str, Any]:
        """ç›‘æ§æŠ•èµ„ç»„åˆè¡¨ç°"""
        if user_id not in self.user_portfolios:
            return {'error': 'ç”¨æˆ·æŠ•èµ„ç»„åˆä¸å­˜åœ¨'}
        
        portfolio = self.user_portfolios[user_id]
        
        # æ¨¡æ‹Ÿå¸‚åœºè¡¨ç°
        current_performance = {
            'stocks': np.random.normal(0.08, 0.15),  # æ¨¡æ‹Ÿè‚¡ç¥¨æ”¶ç›Š
            'bonds': np.random.normal(0.04, 0.05),   # æ¨¡æ‹Ÿå€ºåˆ¸æ”¶ç›Š
            'cash': np.random.normal(0.02, 0.01)     # æ¨¡æ‹Ÿç°é‡‘æ”¶ç›Š
        }
        
        # è®¡ç®—ç»„åˆè¡¨ç°
        total_return = 0
        asset_performance = {}
        
        for asset_class, allocation in portfolio['portfolio_allocation'].items():
            asset_return = current_performance.get(asset_class, 0)
            weighted_return = allocation['percentage'] * asset_return
            total_return += weighted_return
            
            asset_performance[asset_class] = {
                'return': asset_return,
                'weighted_return': weighted_return,
                'current_value': allocation['amount'] * (1 + asset_return)
            }
        
        return {
            'user_id': user_id,
            'portfolio_return': total_return,
            'asset_performance': asset_performance,
            'total_value': portfolio['total_investment'] * (1 + total_return),
            'benchmark_comparison': total_return - 0.05,  # ä¸5%åŸºå‡†æ¯”è¾ƒ
            'rebalancing_needed': abs(total_return) > 0.1  # å¦‚æœåç¦»è¶…è¿‡10%éœ€è¦å†å¹³è¡¡
        }

# æ¼”ç¤ºä»£ç 
if __name__ == "__main__":
    print("ğŸ¦ é‡‘èç§‘æŠ€åº”ç”¨æ¼”ç¤º")
    print("=" * 50)
    
    # 1. ä¿¡è´·é£é™©è¯„ä¼°æ¼”ç¤º
    print("\nğŸ¯ 1. ä¿¡è´·é£é™©è¯„ä¼°ç³»ç»Ÿ")
    
    credit_system = CreditRiskAssessment()
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    training_data = []
    labels = []
    
    for i in range(1000):
        # ç”Ÿæˆæ¨¡æ‹Ÿç”¨æˆ·æ•°æ®
        user_data = {
            'user_id': f'user_{i}',
            'age': np.random.randint(18, 70),
            'income': np.random.normal(50000, 20000),
            'employment_years': np.random.randint(0, 30),
            'debt_ratio': np.random.uniform(0, 0.8),
            'credit_history_length': np.random.randint(0, 20),
            'payment_history': np.random.uniform(0, 1, 12).tolist(),
            'account_balance': np.random.normal(5000, 3000),
            'monthly_transactions': np.random.randint(5, 50),
            'avg_transaction_amount': np.random.normal(200, 100)
        }
        
        # ç”Ÿæˆæ ‡ç­¾ï¼ˆç®€åŒ–é€»è¾‘ï¼‰
        risk_factors = (
            (user_data['debt_ratio'] > 0.5) +
            (user_data['income'] < 30000) +
            (np.mean(user_data['payment_history']) < 0.7)
        )
        label = 1 if risk_factors >= 2 else 0
        
        training_data.append(user_data)
        labels.append(label)
    
    # è®­ç»ƒæ¨¡å‹
    credit_system.train(training_data, labels)
    
    # æµ‹è¯•é£é™©è¯„ä¼°
    test_user = {
        'user_id': 'test_user',
        'age': 35,
        'income': 60000,
        'employment_years': 8,
        'debt_ratio': 0.3,
        'credit_history_length': 10,
        'payment_history': [0.9, 0.8, 1.0, 0.7, 0.9, 0.8, 1.0, 0.9, 0.8, 0.9, 1.0, 0.8],
        'account_balance': 8000,
        'monthly_transactions': 25,
        'avg_transaction_amount': 150
    }
    
    risk_profile = credit_system.assess_risk(test_user)
    explanation = credit_system.explain_decision(test_user)
    
    print(f"   ç”¨æˆ·ä¿¡ç”¨åˆ†æ•°: {risk_profile.credit_score:.0f}")
    print(f"   é£é™©ç­‰çº§: {risk_profile.risk_level}")
    print(f"   é£é™©åˆ†æ•°: {risk_profile.risk_score:.3f}")
    print(f"   ä¸»è¦å½±å“å› ç´ : {explanation['top_factors'][0]['feature']}")
    
    # 2. åæ¬ºè¯ˆæ£€æµ‹æ¼”ç¤º
    print("\nğŸ” 2. åæ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ")
    
    fraud_system = FraudDetectionSystem()
    
    # ç”Ÿæˆå†å²äº¤æ˜“æ•°æ®
    historical_transactions = []
    for i in range(1000):
        transaction = TransactionRecord(
            transaction_id=f'txn_{i}',
            user_id=f'user_{i % 100}',  # 100ä¸ªç”¨æˆ·
            amount=np.random.lognormal(4, 1),  # å¯¹æ•°æ­£æ€åˆ†å¸ƒçš„é‡‘é¢
            timestamp=datetime.now() - timedelta(days=np.random.randint(0, 365)),
            merchant_category=np.random.choice(['grocery', 'gas', 'restaurant', 'retail', 'online']),
            location=np.random.choice(['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·']),
            is_fraud=np.random.random() < 0.05  # 5%çš„æ¬ºè¯ˆç‡
        )
        historical_transactions.append(transaction)
    
    # è®­ç»ƒæ¨¡å‹
    fraud_system.train(historical_transactions)
    
    # æµ‹è¯•æ¬ºè¯ˆæ£€æµ‹
    test_transaction = TransactionRecord(
        transaction_id='test_txn',
        user_id='user_1',
        amount=5000,  # å¼‚å¸¸å¤§é¢äº¤æ˜“
        timestamp=datetime.now().replace(hour=2),  # æ·±å¤œäº¤æ˜“
        merchant_category='online',
        location='æœªçŸ¥åŸå¸‚'  # æ–°åœ°ç‚¹
    )
    
    fraud_result = fraud_system.detect_fraud(test_transaction)
    
    print(f"   äº¤æ˜“ID: {fraud_result['transaction_id']}")
    print(f"   æ¬ºè¯ˆæ¦‚ç‡: {fraud_result['fraud_probability']:.3f}")
    print(f"   æ˜¯å¦é¢„æµ‹ä¸ºæ¬ºè¯ˆ: {'æ˜¯' if fraud_result['is_fraud_predicted'] else 'å¦'}")
    print(f"   å¤„ç†å»ºè®®: {fraud_result['recommendation']}")
    print(f"   é£é™©å› ç´ : {', '.join(fraud_result['risk_factors'][:2])}")
    
    # 3. æ™ºèƒ½æŠ•é¡¾æ¼”ç¤º
    print("\nğŸ’¼ 3. æ™ºèƒ½æŠ•é¡¾ç³»ç»Ÿ")
    
    advisor = IntelligentInvestmentAdvisor()
    
    # æµ‹è¯•ç”¨æˆ·
    investor_data = {
        'age': 30,
        'income': 80000,
        'investment_experience': 'intermediate',
        'investment_goal': 'growth',
        'risk_preference': 'moderate'
    }
    
    # ç”ŸæˆæŠ•èµ„å»ºè®®
    recommendation = advisor.generate_portfolio_recommendation(
        'investor_1', investor_data, 100000
    )
    
    print(f"   æŠ•èµ„é‡‘é¢: Â¥{recommendation['total_investment']:,.0f}")
    print(f"   é£é™©æ‰¿å—èƒ½åŠ›: {recommendation['risk_tolerance']}")
    print(f"   é¢„æœŸå¹´åŒ–æ”¶ç›Š: {recommendation['expected_return']:.2%}")
    print(f"   æŠ•èµ„ç­–ç•¥: {recommendation['investment_strategy']}")
    
    print("\n   èµ„äº§é…ç½®:")
    for asset_class, allocation in recommendation['portfolio_allocation'].items():
        print(f"     {asset_class}: {allocation['percentage']:.1%} (Â¥{allocation['amount']:,.0f})")
    
    # ç›‘æ§æŠ•èµ„ç»„åˆ
    performance = advisor.monitor_portfolio_performance('investor_1')
    print(f"\n   å½“å‰ç»„åˆæ”¶ç›Š: {performance['portfolio_return']:.2%}")
    print(f"   ç»„åˆæ€»ä»·å€¼: Â¥{performance['total_value']:,.0f}")
    print(f"   æ˜¯å¦éœ€è¦å†å¹³è¡¡: {'æ˜¯' if performance['rebalancing_needed'] else 'å¦'}")
    
    print("\nâœ… é‡‘èç§‘æŠ€åº”ç”¨æ¼”ç¤ºå®Œæˆ")

### 2. åŒ»ç–—å¥åº·ï¼ˆHealthTechï¼‰

åŒ»ç–—AIåœ¨ç–¾ç—…è¯Šæ–­ã€è¯ç‰©å‘ç°ã€ä¸ªæ€§åŒ–æ²»ç–—ç­‰æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚

**æ ¸å¿ƒåº”ç”¨åœºæ™¯ï¼š**
- **åŒ»å­¦å½±åƒè¯Šæ–­**ï¼šXå…‰ã€CTã€MRIå›¾åƒåˆ†æ
- **ä¸´åºŠå†³ç­–æ”¯æŒ**ï¼šè¾…åŠ©åŒ»ç”Ÿè¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆåˆ¶å®š
- **è¯ç‰©ç ”å‘**ï¼šåŠ é€Ÿæ–°è¯å‘ç°å’Œä¸´åºŠè¯•éªŒ
- **å¥åº·ç®¡ç†**ï¼šä¸ªæ€§åŒ–å¥åº·ç›‘æµ‹å’Œé¢„é˜²

**æŠ€æœ¯æŒ‘æˆ˜ï¼š**
- æ•°æ®éšç§å’Œå®‰å…¨
- ç›‘ç®¡åˆè§„è¦æ±‚
- åŒ»ç–—è´£ä»»ç•Œå®š
- ç®—æ³•å¯è§£é‡Šæ€§

### 3. æ™ºèƒ½åˆ¶é€ ï¼ˆIndustry 4.0ï¼‰

åˆ¶é€ ä¸šé€šè¿‡AIæŠ€æœ¯å®ç°æ™ºèƒ½åŒ–è½¬å‹ï¼Œæå‡æ•ˆç‡å’Œè´¨é‡ã€‚

**åº”ç”¨é¢†åŸŸï¼š**
- **é¢„æµ‹æ€§ç»´æŠ¤**ï¼šè®¾å¤‡æ•…éšœé¢„æµ‹å’Œç»´æŠ¤ä¼˜åŒ–
- **è´¨é‡æ£€æµ‹**ï¼šäº§å“ç¼ºé™·è‡ªåŠ¨è¯†åˆ«
- **ä¾›åº”é“¾ä¼˜åŒ–**ï¼šéœ€æ±‚é¢„æµ‹å’Œåº“å­˜ç®¡ç†
- **ç”Ÿäº§è°ƒåº¦**ï¼šæ™ºèƒ½æ’äº§å’Œèµ„æºé…ç½®

### 4. æ™ºæ…§é›¶å”®ï¼ˆRetailTechï¼‰

é›¶å”®è¡Œä¸šåˆ©ç”¨AIæŠ€æœ¯æå‡å®¢æˆ·ä½“éªŒå’Œè¿è¥æ•ˆç‡ã€‚

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- **ä¸ªæ€§åŒ–æ¨è**ï¼šå•†å“æ¨èå’Œè¥é”€
- **éœ€æ±‚é¢„æµ‹**ï¼šé”€é‡é¢„æµ‹å’Œè¡¥è´§ä¼˜åŒ–
- **ä»·æ ¼ä¼˜åŒ–**ï¼šåŠ¨æ€å®šä»·ç­–ç•¥
- **å®¢æˆ·æœåŠ¡**ï¼šæ™ºèƒ½å®¢æœå’Œå”®åæ”¯æŒ

## ğŸ’¼ å•†ä¸šæ¨¡å¼åˆ›æ–°

### 1. AIå³æœåŠ¡ï¼ˆAIaaSï¼‰

**æ¨¡å¼ç‰¹ç‚¹ï¼š**
- äº‘ç«¯AIèƒ½åŠ›æä¾›
- æŒ‰ä½¿ç”¨é‡ä»˜è´¹
- é™ä½æŠ€æœ¯é—¨æ§›
- å¿«é€Ÿéƒ¨ç½²åº”ç”¨

**å…¸å‹äº§å“ï¼š**
- è¯­éŸ³è¯†åˆ«API
- å›¾åƒè¯†åˆ«æœåŠ¡
- è‡ªç„¶è¯­è¨€å¤„ç†
- æœºå™¨å­¦ä¹ å¹³å°

### 2. æ•°æ®é©±åŠ¨çš„å•†ä¸šæ¨¡å¼

**æ ¸å¿ƒè¦ç´ ï¼š**
- æ•°æ®æ”¶é›†å’Œç§¯ç´¯
- æ•°æ®ä»·å€¼æŒ–æ˜
- æ•°æ®äº§å“åŒ–
- æ•°æ®å˜ç°ç­–ç•¥

**å®ç°è·¯å¾„ï¼š**
- å…è´¹æœåŠ¡è·å–æ•°æ®
- æ•°æ®åˆ†æäº§ç”Ÿæ´å¯Ÿ
- æ´å¯Ÿé©±åŠ¨äº§å“ä¼˜åŒ–
- æ•°æ®äº§å“å¯¹å¤–é”€å”®

### 3. å¹³å°ç”Ÿæ€æ¨¡å¼

**ç”Ÿæ€æ„å»ºï¼š**
- å¼€æ”¾AIèƒ½åŠ›
- å¸å¼•å¼€å‘è€…
- æ„å»ºåº”ç”¨ç”Ÿæ€
- å½¢æˆç½‘ç»œæ•ˆåº”

**æˆåŠŸè¦ç´ ï¼š**
- æŠ€æœ¯é¢†å…ˆæ€§
- å¼€å‘è€…å‹å¥½
- å•†ä¸šæ¨¡å¼æ¸…æ™°
- ç”Ÿæ€æ²»ç†å®Œå–„

## ğŸš€ åˆ›ä¸šä¸æŠ•èµ„æœºä¼š

### 1. AIåˆ›ä¸šæ–¹å‘

**å‚ç›´é¢†åŸŸAIï¼š**
- è¡Œä¸šä¸“ç”¨AIè§£å†³æ–¹æ¡ˆ
- æ·±åº¦è¡Œä¸šçŸ¥è¯†ç»“åˆ
- è§£å†³ç‰¹å®šä¸šåŠ¡ç—›ç‚¹
- å»ºç«‹è¡Œä¸šå£å’

**AIå·¥å…·å’Œå¹³å°ï¼š**
- é™ä½AIå¼€å‘é—¨æ§›
- æä¾›æ ‡å‡†åŒ–æœåŠ¡
- æ”¯æŒå¿«é€ŸåŸå‹å¼€å‘
- é¢å‘å¼€å‘è€…å¸‚åœº

**AI+ä¼ ç»Ÿè¡Œä¸šï¼š**
- ä¼ ç»Ÿè¡Œä¸šæ™ºèƒ½åŒ–æ”¹é€ 
- ç»“åˆè¡Œä¸šç»éªŒå’ŒAIæŠ€æœ¯
- æ¸è¿›å¼åˆ›æ–°è·¯å¾„
- å¸‚åœºæ¥å—åº¦è¾ƒé«˜

### 2. æŠ•èµ„è¶‹åŠ¿åˆ†æ

**æŠ€æœ¯æŠ•èµ„çƒ­ç‚¹ï¼š**
- å¤§æ¨¡å‹å’ŒAGI
- å¤šæ¨¡æ€AI
- è¾¹ç¼˜AI
- AIå®‰å…¨å’Œå¯ä¿¡AI

**åº”ç”¨æŠ•èµ„æœºä¼šï¼š**
- ä¼ä¸šçº§AIåº”ç”¨
- æ¶ˆè´¹çº§AIäº§å“
- AI+è¡Œä¸šè§£å†³æ–¹æ¡ˆ
- AIåŸºç¡€è®¾æ–½

### 3. æˆåŠŸå› ç´ åˆ†æ

**æŠ€æœ¯å› ç´ ï¼š**
- æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿
- æŠ€æœ¯å›¢é˜Ÿå®åŠ›
- æŒç»­åˆ›æ–°èƒ½åŠ›
- çŸ¥è¯†äº§æƒä¿æŠ¤

**å•†ä¸šå› ç´ ï¼š**
- å¸‚åœºéœ€æ±‚éªŒè¯
- å•†ä¸šæ¨¡å¼æ¸…æ™°
- å®¢æˆ·è·å–èƒ½åŠ›
- ç›ˆåˆ©æ¨¡å¼å¯è¡Œ

**å›¢é˜Ÿå› ç´ ï¼š**
- åˆ›å§‹å›¢é˜ŸèƒŒæ™¯
- è¡Œä¸šç»éªŒç§¯ç´¯
- æ‰§è¡Œèƒ½åŠ›å¼º
- å­¦ä¹ é€‚åº”èƒ½åŠ›

## ğŸ“Š å°ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **å‚ç›´åº”ç”¨**ï¼šAIåœ¨å„è¡Œä¸šçš„æ·±åº¦åº”ç”¨å’Œä»·å€¼åˆ›é€ 
2. **å•†ä¸šæ¨¡å¼**ï¼šä»æŠ€æœ¯åˆ°å•†ä¸šä»·å€¼çš„è½¬åŒ–è·¯å¾„
3. **åˆ›ä¸šæœºä¼š**ï¼šAIåˆ›ä¸šçš„æ–¹å‘é€‰æ‹©å’ŒæˆåŠŸè¦ç´ 
4. **æŠ•èµ„è¶‹åŠ¿**ï¼šAIæŠ•èµ„çš„çƒ­ç‚¹é¢†åŸŸå’Œåˆ¤æ–­æ ‡å‡†
5. **äº§ä¸šç”Ÿæ€**ï¼šAIäº§ä¸šé“¾çš„å®Œå–„å’Œç”Ÿæ€æ„å»º

### å®è·µå»ºè®®

1. **æ·±è€•å‚ç›´**ï¼šé€‰æ‹©ç‰¹å®šè¡Œä¸šæ·±å…¥ç†è§£ä¸šåŠ¡éœ€æ±‚
2. **æŠ€æœ¯ä¸ä¸šåŠ¡ç»“åˆ**ï¼šå¹³è¡¡æŠ€æœ¯å…ˆè¿›æ€§å’Œå•†ä¸šå¯è¡Œæ€§
3. **å¿«é€ŸéªŒè¯**ï¼šé€šè¿‡MVPå¿«é€ŸéªŒè¯å¸‚åœºéœ€æ±‚
4. **ç”Ÿæ€åˆä½œ**ï¼šä¸äº§ä¸šé“¾ä¸Šä¸‹æ¸¸å»ºç«‹åˆä½œå…³ç³»
5. **æŒç»­åˆ›æ–°**ï¼šä¿æŒæŠ€æœ¯é¢†å…ˆå’Œäº§å“è¿­ä»£

### å‘å±•è¶‹åŠ¿

1. **è¡Œä¸šAIåŒ–**ï¼šå„è¡Œä¸šAIåº”ç”¨çš„æ·±åº¦å’Œå¹¿åº¦æŒç»­æ‰©å±•
2. **å¹³å°åŒ–å‘å±•**ï¼šAIèƒ½åŠ›å¹³å°åŒ–ï¼Œé™ä½åº”ç”¨é—¨æ§›
3. **ç”Ÿæ€åŒ–ç«äº‰**ï¼šä»å•ç‚¹æŠ€æœ¯ç«äº‰è½¬å‘ç”Ÿæ€ç«äº‰
4. **æ ‡å‡†åŒ–è¿›ç¨‹**ï¼šAIåº”ç”¨æ ‡å‡†å’Œè§„èŒƒé€æ­¥å»ºç«‹
5. **å›½é™…åŒ–æœºé‡**ï¼šAIæŠ€æœ¯å’Œäº§å“çš„å…¨çƒåŒ–å‘å±•